/**
 * Import API Routes for IntelGraph
 *
 * Provides REST endpoints for:
 * - CSV file uploads and import jobs
 * - STIX bundle uploads and processing
 * - TAXII collection imports
 * - Import job management and monitoring
 * - Legacy validation endpoint
 */
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs').promises;
const CSVImportService = require('../services/CSVImportService');
const STIXImportService = require('../services/STIXImportService');
const { ensureAuthenticated, requireRole } = require('../middleware/auth');
const { writeAudit } = require('../utils/audit');
const router = express.Router();
// Configure multer for file uploads
const storage = multer.diskStorage({
    destination: async (req, file, cb) => {
        const uploadDir = path.join(process.cwd(), 'uploads', 'imports');
        try {
            await fs.mkdir(uploadDir, { recursive: true });
            cb(null, uploadDir);
        }
        catch (error) {
            cb(error);
        }
    },
    filename: (req, file, cb) => {
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const filename = `${timestamp}-${file.originalname}`;
        cb(null, filename);
    },
});
const upload = multer({
    storage,
    limits: {
        fileSize: 100 * 1024 * 1024, // 100MB limit
    },
    fileFilter: (req, file, cb) => {
        const allowedTypes = ['.csv', '.json', '.txt', '.parquet'];
        const ext = path.extname(file.originalname).toLowerCase();
        if (allowedTypes.includes(ext)) {
            cb(null, true);
        }
        else {
            cb(new Error(`Unsupported file type: ${ext}. Allowed: ${allowedTypes.join(', ')}`));
        }
    },
});
// Middleware
router.use(ensureAuthenticated);
router.use((req, res, next) => {
    if (!req.app.locals.csvImportService) {
        req.app.locals.csvImportService = new CSVImportService(req.app.locals.neo4jDriver, req.app.locals.pgClient, req.app.locals.io);
    }
    if (!req.app.locals.stixImportService) {
        req.app.locals.stixImportService = new STIXImportService(req.app.locals.neo4jDriver, req.app.locals.pgClient, req.app.locals.io);
    }
    next();
});
// ==============================================================================
// LEGACY ENDPOINT (preserved for backward compatibility)
// ==============================================================================
// Validate an import payload and preview the changes without applying
router.post('/validate', async (req, res) => {
    try {
        const payload = req.body;
        if (!payload || typeof payload !== 'object') {
            return res.status(400).json({ error: 'Invalid payload' });
        }
        // Minimal shape checks (placeholder for schema contracts)
        const nodes = Array.isArray(payload.nodes) ? payload.nodes : [];
        const edges = Array.isArray(payload.edges) ? payload.edges : [];
        const problems = [];
        for (const [i, n] of nodes.entries()) {
            if (!n.uuid && !n.id)
                problems.push({ type: 'node', index: i, issue: 'missing id/uuid' });
            if (!n.type)
                problems.push({ type: 'node', index: i, issue: 'missing type' });
        }
        for (const [i, e] of edges.entries()) {
            if (!e.source || !e.target)
                problems.push({ type: 'edge', index: i, issue: 'missing endpoints' });
            if (!e.type)
                problems.push({ type: 'edge', index: i, issue: 'missing type' });
        }
        const summary = {
            nodes: nodes.length,
            edges: edges.length,
            problems,
            canApply: problems.length === 0,
        };
        await writeAudit({
            userId: req.user?.id,
            actorRole: req.user?.role,
            sessionId: req.sessionId,
            action: 'IMPORT_VALIDATE',
            resourceType: 'Graph',
            resourceId: null,
            details: { counts: { nodes: nodes.length, edges: edges.length } },
            ip: req.ip,
            userAgent: req.get('User-Agent'),
        });
        return res.json({ summary });
    }
    catch (e) {
        return res.status(500).json({ error: e.message });
    }
});
// ==============================================================================
// CSV IMPORT ENDPOINTS
// ==============================================================================
/**
 * Upload and analyze CSV file structure
 */
router.post('/csv/analyze', upload.single('file'), async (req, res) => {
    try {
        if (!req.file) {
            return res.status(400).json({ error: 'No file uploaded' });
        }
        const ext = path.extname(req.file.path).toLowerCase();
        const sampleRows = [];
        let fields = [];
        let rowCount = 0;
        if (ext === '.parquet') {
            let parquet;
            try {
                parquet = require('parquetjs-lite');
            }
            catch (err) {
                return res.status(500).json({ error: 'Parquet support not installed' });
            }
            const reader = await parquet.ParquetReader.openFile(req.file.path);
            fields = Object.keys(reader.schema.fields);
            const cursor = reader.getCursor();
            let record;
            while ((record = await cursor.next()) && rowCount < 100) {
                if (rowCount < 5)
                    sampleRows.push(record);
                rowCount++;
            }
            while (await cursor.next()) {
                rowCount++;
            }
            await reader.close();
        }
        else {
            const csv = require('csv-parser');
            const fs = require('fs');
            const fieldSet = new Set();
            const stream = fs
                .createReadStream(req.file.path)
                .pipe(csv())
                .on('data', (row) => {
                if (rowCount < 100) {
                    Object.keys(row).forEach((key) => fieldSet.add(key));
                    if (rowCount < 5)
                        sampleRows.push(row);
                }
                rowCount++;
            });
            await new Promise((resolve, reject) => {
                stream.on('end', resolve);
                stream.on('error', reject);
            });
            fields = Array.from(fieldSet);
        }
        await writeAudit({
            userId: req.user?.id,
            action: 'FILE_ANALYZE',
            resourceType: 'Import',
            details: {
                filename: req.file.originalname,
                fields: fields.length,
                rows: rowCount,
            },
        });
        res.json({
            filename: req.file.originalname,
            filePath: req.file.path,
            fields,
            sampleRows,
            estimatedRows: rowCount,
            fileSize: req.file.size,
        });
    }
    catch (error) {
        res.status(500).json({ error: error.message });
    }
});
/**
 * Start CSV import job
 */
router.post('/csv/import', async (req, res) => {
    try {
        const { filePath, investigationId, mapping, dedupeKey } = req.body;
        if (!filePath || !mapping) {
            return res
                .status(400)
                .json({ error: 'filePath and mapping are required' });
        }
        const job = await req.app.locals.csvImportService.startImport({
            filePath,
            investigationId,
            mapping,
            dedupeKey,
            userId: req.user.id,
            tenantId: req.user.tenantId || 'default',
        });
        await writeAudit({
            userId: req.user?.id,
            action: 'CSV_IMPORT_START',
            resourceType: 'Import',
            resourceId: job.id,
            details: { investigationId, entityType: mapping.entityType },
        });
        res.json(job);
    }
    catch (error) {
        res.status(500).json({ error: error.message });
    }
});
/**
 * Get CSV import job status
 */
router.get('/csv/:jobId', async (req, res) => {
    try {
        const job = await req.app.locals.csvImportService.getJob(req.params.jobId);
        if (!job) {
            return res.status(404).json({ error: 'Job not found' });
        }
        res.json(job);
    }
    catch (error) {
        res.status(500).json({ error: error.message });
    }
});
/**
 * Resume CSV import job
 */
router.post('/csv/:jobId/resume', async (req, res) => {
    try {
        const job = await req.app.locals.csvImportService.resumeImport(req.params.jobId);
        await writeAudit({
            userId: req.user?.id,
            action: 'CSV_IMPORT_RESUME',
            resourceType: 'Import',
            resourceId: job.id,
            details: { investigationId: job.investigationId },
        });
        res.json(job);
    }
    catch (error) {
        res.status(400).json({ error: error.message });
    }
});
// ==============================================================================
// STIX IMPORT ENDPOINTS
// ==============================================================================
/**
 * Upload and start STIX bundle import
 */
router.post('/stix/bundle', upload.single('file'), async (req, res) => {
    try {
        if (!req.file) {
            return res.status(400).json({ error: 'No file uploaded' });
        }
        const { investigationId } = req.body;
        // Validate JSON structure
        const bundleContent = await fs.readFile(req.file.path, 'utf8');
        const bundle = JSON.parse(bundleContent);
        if (bundle.type !== 'bundle') {
            return res
                .status(400)
                .json({ error: 'Invalid STIX bundle: missing type "bundle"' });
        }
        const job = await req.app.locals.stixImportService.startStixBundleImport({
            bundlePath: req.file.path,
            investigationId,
            userId: req.user.id,
            tenantId: req.user.tenantId || 'default',
        });
        await writeAudit({
            userId: req.user?.id,
            action: 'STIX_BUNDLE_IMPORT_START',
            resourceType: 'Import',
            resourceId: job.id,
            details: { investigationId, objectCount: bundle.objects?.length || 0 },
        });
        res.json(job);
    }
    catch (error) {
        if (error instanceof SyntaxError) {
            res.status(400).json({ error: 'Invalid JSON format' });
        }
        else {
            res.status(500).json({ error: error.message });
        }
    }
});
/**
 * Start TAXII collection import
 */
router.post('/stix/taxii', async (req, res) => {
    try {
        const { taxiiUrl, collectionId, investigationId, auth, addedAfter, limit = 1000, } = req.body;
        if (!taxiiUrl || !collectionId) {
            return res
                .status(400)
                .json({ error: 'taxiiUrl and collectionId are required' });
        }
        const job = await req.app.locals.stixImportService.startTaxiiImport({
            taxiiUrl,
            collectionId,
            investigationId,
            auth,
            addedAfter,
            limit,
            userId: req.user.id,
            tenantId: req.user.tenantId || 'default',
        });
        await writeAudit({
            userId: req.user?.id,
            action: 'TAXII_IMPORT_START',
            resourceType: 'Import',
            resourceId: job.id,
            details: { investigationId, taxiiUrl, collectionId },
        });
        res.json(job);
    }
    catch (error) {
        res.status(500).json({ error: error.message });
    }
});
/**
 * Get STIX import job status
 */
router.get('/stix/:jobId', async (req, res) => {
    try {
        const job = await req.app.locals.stixImportService.getJob(req.params.jobId);
        if (!job) {
            return res.status(404).json({ error: 'Job not found' });
        }
        res.json(job);
    }
    catch (error) {
        res.status(500).json({ error: error.message });
    }
});
/**
 * Resume STIX TAXII import
 */
router.post('/stix/:jobId/resume', async (req, res) => {
    try {
        const job = await req.app.locals.stixImportService.resumeTaxiiImport(req.params.jobId);
        await writeAudit({
            userId: req.user?.id,
            action: 'TAXII_IMPORT_RESUME',
            resourceType: 'Import',
            resourceId: job.id,
            details: {
                investigationId: job.investigationId,
                taxiiUrl: job.taxiiUrl,
                collectionId: job.collectionId,
            },
        });
        res.json(job);
    }
    catch (error) {
        res.status(400).json({ error: error.message });
    }
});
// ==============================================================================
// GENERAL IMPORT ENDPOINTS
// ==============================================================================
/**
 * List all import jobs for an investigation
 */
router.get('/jobs/:investigationId', async (req, res) => {
    try {
        const { investigationId } = req.params;
        const { limit = 50 } = req.query;
        // Get both CSV and STIX jobs
        const csvJobs = await req.app.locals.csvImportService.listJobs(investigationId, limit);
        const stixJobs = await req.app.locals.stixImportService.listJobs(investigationId, limit);
        // Combine and sort by creation time
        const allJobs = [
            ...csvJobs.map((job) => ({ ...job, type: 'CSV' })),
            ...stixJobs.map((job) => ({ ...job, type: job.type || 'STIX' })),
        ].sort((a, b) => new Date(b.createdAt) - new Date(a.createdAt));
        res.json(allJobs);
    }
    catch (error) {
        res.status(500).json({ error: error.message });
    }
});
/**
 * Get suggested field mappings
 */
router.post('/mapping/suggest', async (req, res) => {
    try {
        const { fields, entityType = 'ENTITY' } = req.body;
        if (!fields || !Array.isArray(fields)) {
            return res.status(400).json({ error: 'fields array is required' });
        }
        const suggestions = {};
        // Basic field mapping suggestions
        const mappingRules = {
            name: ['name', 'title', 'label', 'entity_name', 'full_name'],
            description: ['description', 'desc', 'summary', 'notes', 'details'],
            firstName: ['first_name', 'fname', 'given_name'],
            lastName: ['last_name', 'lname', 'surname', 'family_name'],
            email: ['email', 'email_address', 'e_mail'],
            phone: ['phone', 'telephone', 'phone_number'],
            industry: ['industry', 'sector', 'business_type'],
            website: ['website', 'url', 'homepage', 'web_site'],
            address: ['address', 'street_address', 'location'],
            city: ['city', 'town', 'municipality'],
            country: ['country', 'nation'],
            latitude: ['lat', 'latitude', 'geo_lat'],
            longitude: ['lon', 'lng', 'longitude', 'geo_lon'],
            dateCreated: ['created', 'date_created', 'created_at', 'timestamp'],
            id: ['id', 'identifier', 'external_id', 'ref_id'],
            type: ['type', 'category', 'classification'],
        };
        for (const field of fields) {
            const lowerField = field.toLowerCase();
            for (const [targetField, patterns] of Object.entries(mappingRules)) {
                if (patterns.some((pattern) => lowerField.includes(pattern))) {
                    suggestions[field] = targetField;
                    break;
                }
            }
        }
        res.json({
            entityType,
            suggestions,
            recommendedDedupeKey: suggestions.name
                ? ['name']
                : suggestions.id
                    ? ['id']
                    : Object.keys(suggestions).slice(0, 2),
        });
    }
    catch (error) {
        res.status(500).json({ error: error.message });
    }
});
// Error handling middleware
router.use((error, req, res, next) => {
    if (error instanceof multer.MulterError) {
        if (error.code === 'LIMIT_FILE_SIZE') {
            return res
                .status(400)
                .json({ error: 'File too large. Maximum size is 100MB.' });
        }
    }
    console.error('Import API Error:', error);
    res.status(500).json({ error: 'Internal server error' });
});
module.exports = router;
//# sourceMappingURL=import.js.map