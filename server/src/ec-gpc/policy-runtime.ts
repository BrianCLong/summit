
import { PolicyGraph, ExecutionTrace, ExecutionStep, PolicyNode, Envelope } from './types.js';
import { v4 as uuidv4 } from 'uuid';
import { IntelGraphService, intelGraphService } from '../maestro/provenance/intel-graph.js';

export class PolicyRuntime {

  constructor() {}

  public async execute(policy: PolicyGraph, input: any): Promise<ExecutionTrace> {
    const traceId = uuidv4();
    const trace: ExecutionTrace = {
      traceId,
      policyId: policy.id,
      steps: [],
      status: 'running',
      totalCost: 0,
      totalDurationMs: 0
    };

    let currentNodeId: string | undefined = policy.entryNodeId;
    const context: Record<string, any> = { input };

    // Slack redistribution bucket
    let slackLatencyMs = 0;
    let slackCostUsd = 0;

    const startTime = Date.now();

    try {
      while (currentNodeId) {
        const node = policy.nodes.find(n => n.id === currentNodeId);
        if (!node) break;

        // Apply Envelope + Slack
        const effectiveEnvelope: Envelope = {
          ...node.envelope,
          latencyMs: node.envelope.latencyMs + slackLatencyMs,
          costUsd: node.envelope.costUsd + slackCostUsd
        };

        const stepResult = await this.executeNode(node, context, effectiveEnvelope);

        // Update Context
        context[node.id] = stepResult.output;

        // Update Trace
        trace.steps.push(stepResult);
        trace.totalCost += stepResult.metrics.costUsd;
        trace.totalDurationMs += stepResult.metrics.latencyMs;

        // Log to IntelGraph (Provenance)
        await this.logProvenance(traceId, node, stepResult);

        // Calculate Slack generated by this step
        if (stepResult.status === 'success') {
          slackLatencyMs += Math.max(0, effectiveEnvelope.latencyMs - stepResult.metrics.latencyMs);
          slackCostUsd += Math.max(0, effectiveEnvelope.costUsd - stepResult.metrics.costUsd);
        }

        // Handle Flow Control
        if (stepResult.status === 'success') {
          currentNodeId = node.next && node.next.length > 0 ? node.next[0] : undefined;
        } else if (stepResult.status === 'fallback' && node.onViolation) {
          currentNodeId = node.onViolation.nodeId;
          console.log(`Fallback triggered from ${node.id} to ${currentNodeId}`);
        } else {
          throw new Error(`Execution failed at node ${node.id}: ${stepResult.error}`);
        }
      }

      trace.status = 'completed';
    } catch (err: any) {
      trace.status = 'failed';
      console.error(err);
    }

    return trace;
  }

  private async executeNode(node: PolicyNode, context: any, envelope: Envelope): Promise<ExecutionStep> {
    const start = Date.now();

    // Resolve inputs
    // In a real implementation, we'd resolve JSONPath/variable references here.
    const effectiveInput = { ...node.inputs, ...context.input };

    try {
      // Mock Execution Logic
      // In real implementation, this delegates to Asset Registry / Summit
      // TODO: Connect to real Summit Asset Registry for production
      const result = await this.simulateAssetCall(node, effectiveInput, envelope);

      const duration = Date.now() - start;
      const metrics = {
        latencyMs: duration,
        costUsd: 0.001, // Mock
        tokensIn: 100,
        tokensOut: 50
      };

      // Strict Envelope Enforcement
      if (metrics.latencyMs > envelope.latencyMs) {
        // In Phase 1, we log a violation but can optionally trigger fallback.
        // For demonstration of the "Method", we should treat this as a fallback trigger.
        console.warn(`[EC-GPC] Envelope Violation at ${node.id}: ${metrics.latencyMs}ms > ${envelope.latencyMs}ms`);

        if (node.onViolation) {
          throw new Error('Timeout'); // Triggers fallback block below
        }
        // If no fallback defined, we proceed but mark violation in future iterations
      }

      return {
        nodeId: node.id,
        status: 'success',
        startedAt: new Date(start),
        completedAt: new Date(),
        metrics,
        output: result
      };

    } catch (error: any) {
      // Check if it's an envelope violation
      if (error.message === 'Timeout' || error.message === 'BudgetExceeded') {
        return {
          nodeId: node.id,
          status: 'fallback',
          startedAt: new Date(start),
          completedAt: new Date(),
          metrics: { latencyMs: Date.now() - start, costUsd: 0, tokensIn: 0, tokensOut: 0 },
          error: error.message
        };
      }
      throw error;
    }
  }

  private async simulateAssetCall(node: PolicyNode, input: any, envelope: Envelope): Promise<any> {
    // Simulation: Sleep to mimic latency
    const simLatency = Math.min(envelope.latencyMs * 0.5, 100); // Usually succeeds

    await new Promise(resolve => setTimeout(resolve, simLatency));

    // Basic Mock Responses
    if (node.opType === 'LLM_CALL') {
      return { text: `Processed by ${node.assetRef}: ${JSON.stringify(input)}` };
    } else if (node.opType === 'RETRIEVE') {
      return { documents: ['doc1', 'doc2'] };
    } else if (node.opType === 'CACHE_GET') {
      // Random miss for testing fallbacks?
      // For now, assume hit
      return { hit: true, value: 'cached_response' };
    }
    return { status: 'ok' };
  }

  private async logProvenance(traceId: string, node: PolicyNode, step: ExecutionStep) {
     try {
       await intelGraphService.pushEvidence({
         id: uuidv4(),
         runId: traceId, // reusing traceId as runId for simplicity in Phase 1
         artifactType: 'EC_GPC_TRACE_STEP',
         hash: uuidv4(), // Mock hash
         timestamp: new Date().toISOString(),
         metadata: {
            nodeId: node.id,
            opType: node.opType,
            metrics: step.metrics,
            status: step.status
         }
       });
     } catch (e) {
       console.error("Failed to log provenance:", e);
       // Non-blocking for now
     }
  }
}
