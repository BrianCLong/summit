[tool.poetry]
name = "intelgraph-ml"
version = "0.2.0"
description = "IntelGraph AI/ML microservice"
authors = ["IntelGraph Team <dev@intelgraph.com>"]
license = "MIT"

[tool.poetry.dependencies]
python = "^3.12"
fastapi = "^0.115.0"
uvicorn = "^0.30.0"
pydantic = "^2.8.0"
python-jose = "^3.3.0"
redis = "^5.0.7"
celery = "^5.4.0"
numpy = "^2.0.0"
scikit-learn = "^1.5.1"
networkx = "^3.3"
torch = "^2.3.1"
torchvision = "^0.18.1"
torch-geometric = "^2.4.0"
torch-scatter = "^2.1.2"
torch-sparse = "^0.6.18"
torch-cluster = "^1.6.3"
# GPU acceleration and optimization
tensorrt = {version="^10.0.1", optional=true}
torch-tensorrt = {version="^2.3.0", optional=true}
# Model quantization
bitsandbytes = "^0.43.0"
# Distributed training
accelerate = "^0.32.1"
deepspeed = {version="^0.14.0", optional=true}
# Performance monitoring
pynvml = "^11.5.0"
httpx = "^0.27.0"
neo4j = "^5.23.0"
sentence-transformers = "^2.7.0"
langdetect = "^1.0.9"
transformers = "^4.34.1"
prometheus-client = "^0.20.0"
psutil = "^5.9.8"
psycopg2-binary = "^2.9.9"
# Optional â€” only used if USE_SPACY=true
spacy = {version="^3.7.5", optional=true}
# Optional community detection
python-louvain = {version="^0.16", optional=true}

[tool.poetry.extras]
spacy = ["spacy"]
community = ["python-louvain"]
gpu = ["tensorrt", "torch-tensorrt", "deepspeed"]
full = ["spacy", "python-louvain", "tensorrt", "torch-tensorrt", "deepspeed"]

[tool.poetry.group.dev.dependencies]
pytest = "^8.3.1"
pytest-asyncio = "^0.23.8"
pytest-cov = "^4.1.0"
pytest-mock = "^3.11.1"
httpx = "^0.27.0"
coverage = "^7.3.0"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
