# MLOps Auto-Retraining Pipeline
# Kubeflow Pipeline for automated model retraining with concept drift detection

apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: threat-detection-retraining
  namespace: intelgraph-ml
  labels:
    component: mlops
    version: v2.0.0
spec:
  entrypoint: retraining-pipeline
  serviceAccountName: mlops-pipeline
  
  # Volume claims for model artifacts
  volumeClaimTemplates:
  - metadata:
      name: model-artifacts
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 20Gi
  
  templates:
  # Main pipeline orchestration
  - name: retraining-pipeline
    dag:
      tasks:
      - name: drift-detection
        template: concept-drift-detection
        
      - name: data-validation
        template: validate-training-data
        depends: "drift-detection.Succeeded"
        
      - name: feature-engineering
        template: feature-engineering
        depends: "data-validation.Succeeded"
        
      - name: parallel-model-training
        template: parallel-model-training
        depends: "feature-engineering.Succeeded"
        
      - name: model-evaluation
        template: evaluate-models
        depends: "parallel-model-training.Succeeded"
        
      - name: champion-challenger
        template: champion-challenger-test
        depends: "model-evaluation.Succeeded"
        
      - name: model-deployment
        template: deploy-best-model
        depends: "champion-challenger.Succeeded"
        
      - name: performance-monitoring
        template: setup-monitoring
        depends: "model-deployment.Succeeded"

  # Concept drift detection
  - name: concept-drift-detection
    container:
      image: intelgraph/ml-drift-detector:v2.0.0
      command: [python]
      args: 
      - /app/drift_detector.py
      - --window-days=7
      - --threshold=0.1
      - --metrics-endpoint=prometheus:9090
      env:
      - name: MLFLOW_TRACKING_URI
        value: "http://mlflow-server:5000"
      - name: FEATURE_STORE_URI
        value: "redis://redis-cluster:6379"
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"
    outputs:
      parameters:
      - name: drift-detected
        valueFrom:
          path: /tmp/drift_detected.txt
      - name: drift-score
        valueFrom:
          path: /tmp/drift_score.txt

  # Data validation and preparation
  - name: validate-training-data
    container:
      image: intelgraph/data-validator:v2.0.0
      command: [python]
      args:
      - /app/validate_data.py
      - --data-source=timescaledb
      - --validation-suite=threat_detection
      - --lookback-days=30
      env:
      - name: POSTGRES_URL
        valueFrom:
          secretKeyRef:
            name: database-secrets
            key: timescaledb-url
      - name: GREAT_EXPECTATIONS_CONFIG
        value: "/config/data_validation.yaml"
      volumeMounts:
      - name: model-artifacts
        mountPath: /artifacts
    outputs:
      parameters:
      - name: data-quality-score
        valueFrom:
          path: /artifacts/data_quality.json
      artifacts:
      - name: validated-dataset
        path: /artifacts/validated_dataset.parquet

  # Feature engineering pipeline
  - name: feature-engineering
    container:
      image: intelgraph/feature-engineer:v2.0.0
      command: [python]
      args:
      - /app/feature_pipeline.py
      - --input=/artifacts/validated_dataset.parquet
      - --output=/artifacts/feature_store
      - --feature-config=/config/features.yaml
      env:
      - name: FEAST_REPO_PATH
        value: "/config/feast"
      volumeMounts:
      - name: model-artifacts
        mountPath: /artifacts
      resources:
        requests:
          memory: "4Gi"
          cpu: "2"
        limits:
          memory: "8Gi"
          cpu: "4"
    inputs:
      artifacts:
      - name: dataset
        path: /artifacts/validated_dataset.parquet
        from: "{{tasks.data-validation.outputs.artifacts.validated-dataset}}"
    outputs:
      artifacts:
      - name: feature-store
        path: /artifacts/feature_store

  # Parallel model training (ensemble approach)
  - name: parallel-model-training
    parallelism: 4
    container:
      image: intelgraph/model-trainer:v2.0.0
      command: [python]
      args:
      - /app/train_model.py
      - --model-type={{item}}
      - --features=/artifacts/feature_store
      - --output=/artifacts/models/{{item}}
      - --config=/config/training_config.yaml
      env:
      - name: CUDA_VISIBLE_DEVICES
        value: "{{workflow.parameters.gpu-id}}"
      - name: MLFLOW_EXPERIMENT_NAME
        value: "threat-detection-retraining-{{workflow.creationTimestamp}}"
      volumeMounts:
      - name: model-artifacts
        mountPath: /artifacts
      resources:
        requests:
          memory: "8Gi"
          cpu: "4"
          nvidia.com/gpu: 1
        limits:
          memory: "16Gi"
          cpu: "8"
          nvidia.com/gpu: 1
    withItems:
    - "network-behavior"
    - "process-behavior" 
    - "temporal-anomaly"
    - "graph-anomaly"
    inputs:
      artifacts:
      - name: features
        path: /artifacts/feature_store
        from: "{{tasks.feature-engineering.outputs.artifacts.feature-store}}"
    outputs:
      artifacts:
      - name: trained-model
        path: /artifacts/models/{{item}}

  # Model evaluation and comparison
  - name: evaluate-models
    container:
      image: intelgraph/model-evaluator:v2.0.0
      command: [python]
      args:
      - /app/evaluate_models.py
      - --models-dir=/artifacts/models
      - --test-data=/artifacts/test_set.parquet
      - --metrics-output=/artifacts/evaluation_results.json
      env:
      - name: MLFLOW_TRACKING_URI
        value: "http://mlflow-server:5000"
      volumeMounts:
      - name: model-artifacts
        mountPath: /artifacts
      resources:
        requests:
          memory: "4Gi"
          cpu: "2"
        limits:
          memory: "8Gi"
          cpu: "4"
    outputs:
      parameters:
      - name: best-model
        valueFrom:
          path: /artifacts/best_model.txt
      - name: performance-metrics
        valueFrom:
          path: /artifacts/evaluation_results.json
      artifacts:
      - name: model-comparison
        path: /artifacts/model_comparison_report.html

  # Champion vs Challenger testing
  - name: champion-challenger-test
    container:
      image: intelgraph/champion-challenger:v2.0.0
      command: [python]
      args:
      - /app/champion_challenger.py
      - --champion-model={{workflow.parameters.current-model}}
      - --challenger-model={{tasks.evaluate-models.outputs.parameters.best-model}}
      - --test-traffic-percentage=10
      - --duration-minutes=60
      - --success-threshold=0.05
      env:
      - name: KUBERNETES_NAMESPACE
        value: "intelgraph-ml"
      - name: ISTIO_GATEWAY
        value: "intelgraph-gateway"
      volumeMounts:
      - name: model-artifacts
        mountPath: /artifacts
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
    outputs:
      parameters:
      - name: challenger-wins
        valueFrom:
          path: /artifacts/challenger_result.txt
      - name: performance-improvement
        valueFrom:
          path: /artifacts/improvement.txt

  # Deploy winning model
  - name: deploy-best-model
    container:
      image: intelgraph/model-deployer:v2.0.0
      command: [python]
      args:
      - /app/deploy_model.py
      - --model-path=/artifacts/models/{{tasks.evaluate-models.outputs.parameters.best-model}}
      - --deployment-target=production
      - --rollout-strategy=canary
      - --traffic-split=5
      env:
      - name: KUBERNETES_NAMESPACE
        value: "intelgraph"
      - name: MODEL_REGISTRY_URL
        value: "http://mlflow-server:5000"
      - name: SELDON_CORE_ENABLED
        value: "true"
      volumeMounts:
      - name: model-artifacts
        mountPath: /artifacts
      resources:
        requests:
          memory: "1Gi"
          cpu: "0.5"
    outputs:
      parameters:
      - name: deployment-id
        valueFrom:
          path: /artifacts/deployment_id.txt
      - name: model-endpoint
        valueFrom:
          path: /artifacts/model_endpoint.txt

  # Set up monitoring for deployed model
  - name: setup-monitoring
    container:
      image: intelgraph/monitoring-setup:v2.0.0
      command: [python]
      args:
      - /app/setup_monitoring.py
      - --deployment-id={{tasks.deploy-best-model.outputs.parameters.deployment-id}}
      - --model-endpoint={{tasks.deploy-best-model.outputs.parameters.model-endpoint}}
      - --monitoring-config=/config/monitoring.yaml
      env:
      - name: PROMETHEUS_URL
        value: "http://prometheus:9090"
      - name: GRAFANA_URL
        value: "http://grafana:3000"
      - name: ALERT_MANAGER_URL
        value: "http://alertmanager:9093"
      resources:
        requests:
          memory: "512Mi"
          cpu: "0.25"

---
# Scheduled workflow for regular retraining
apiVersion: argoproj.io/v1alpha1
kind: CronWorkflow
metadata:
  name: scheduled-threat-model-retraining
  namespace: intelgraph-ml
spec:
  schedule: "0 2 * * 0"  # Weekly on Sunday at 2 AM
  timezone: "America/New_York"
  workflowSpec:
    entrypoint: retraining-pipeline
    workflowTemplateRef:
      name: threat-detection-retraining
    arguments:
      parameters:
      - name: current-model
        value: "threat-detection-v1.0.0"
      - name: gpu-id
        value: "0"

---
# Feature store configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: threat-detection-features
  namespace: intelgraph-ml
data:
  features.yaml: |
    feature_views:
    - name: network_features
      entities:
      - indicator_id
      features:
      - src_ip_reputation
      - dst_ip_reputation
      - port_number
      - protocol_type
      - packet_count
      - byte_count
      - connection_duration
      ttl: 7d
      
    - name: process_features
      entities:
      - indicator_id
      features:
      - process_name
      - command_line_entropy
      - parent_process
      - execution_count
      - is_system_process
      - has_base64_encoding
      ttl: 7d
      
    - name: temporal_features
      entities:
      - indicator_id
      features:
      - hour_of_day
      - day_of_week
      - is_weekend
      - is_business_hours
      - execution_frequency
      ttl: 7d
      
    - name: graph_features
      entities:
      - indicator_id
      features:
      - node_centrality
      - community_size
      - shortest_path_to_bad
      - clustering_coefficient
      ttl: 7d

---
# Model training configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: training-config
  namespace: intelgraph-ml
data:
  training_config.yaml: |
    models:
      network-behavior:
        type: "isolation_forest"
        hyperparameters:
          contamination: 0.1
          n_estimators: 100
          random_state: 42
        features:
        - network_features.*
        
      process-behavior:
        type: "transformer_classifier"
        hyperparameters:
          model_name: "distilbert-base-uncased"
          num_labels: 2
          learning_rate: 2e-5
          num_train_epochs: 3
        features:
        - process_features.*
        
      temporal-anomaly:
        type: "lstm_autoencoder"
        hyperparameters:
          sequence_length: 24
          hidden_size: 128
          num_layers: 2
          dropout: 0.1
        features:
        - temporal_features.*
        
      graph-anomaly:
        type: "graph_neural_network"
        hyperparameters:
          num_layers: 3
          hidden_channels: 64
          dropout: 0.2
          learning_rate: 0.01
        features:
        - graph_features.*
        
    training:
      validation_split: 0.2
      test_split: 0.1
      cross_validation_folds: 5
      early_stopping_patience: 10
      metrics:
      - accuracy
      - precision
      - recall
      - f1_score
      - roc_auc
      
    drift_detection:
      window_size: 1000
      reference_window_size: 5000
      drift_threshold: 0.1
      statistical_tests:
      - kolmogorov_smirnov
      - population_stability_index
      - jensen_shannon_divergence

---
# Monitoring and alerting configuration
apiVersion: v1
kind: ConfigMap
metadata:
  name: ml-monitoring-config
  namespace: intelgraph-ml
data:
  monitoring.yaml: |
    metrics:
      model_performance:
      - name: "threat_detection_accuracy"
        description: "Model accuracy on validation set"
        type: "gauge"
        threshold: 0.85
        
      - name: "threat_detection_latency_p95"
        description: "95th percentile prediction latency"
        type: "histogram"
        threshold: 100  # milliseconds
        
      - name: "concept_drift_score"
        description: "Statistical drift score"
        type: "gauge"
        threshold: 0.1
        
      - name: "false_positive_rate"
        description: "False positive rate"
        type: "gauge"
        threshold: 0.05
        
      - name: "model_feature_importance_drift"
        description: "Change in feature importance"
        type: "gauge"
        threshold: 0.2
        
    alerts:
    - alert: ModelAccuracyDegraded
      expr: threat_detection_accuracy < 0.85
      for: 5m
      labels:
        severity: warning
        component: ml-model
      annotations:
        summary: "Threat detection model accuracy below threshold"
        description: "Model accuracy {{ $value }} is below 85% threshold"
        
    - alert: ModelLatencyHigh
      expr: histogram_quantile(0.95, threat_detection_latency_p95) > 100
      for: 2m
      labels:
        severity: critical
        component: ml-model
      annotations:
        summary: "High model prediction latency"
        description: "95th percentile latency {{ $value }}ms exceeds 100ms"
        
    - alert: ConceptDriftDetected
      expr: concept_drift_score > 0.1
      for: 1m
      labels:
        severity: warning
        component: ml-model
      annotations:
        summary: "Concept drift detected in threat model"
        description: "Drift score {{ $value }} indicates model retraining needed"
        
    dashboards:
    - name: "ML Model Performance"
      panels:
      - title: "Model Accuracy Over Time"
        type: "graph"
        query: "threat_detection_accuracy"
        
      - title: "Prediction Latency Distribution"
        type: "heatmap"
        query: "threat_detection_latency_p95"
        
      - title: "Concept Drift Score"
        type: "stat"
        query: "concept_drift_score"
        
      - title: "Feature Importance Heatmap"
        type: "heatmap"
        query: "model_feature_importance"
        
      - title: "Confusion Matrix"
        type: "table"
        query: "threat_detection_confusion_matrix"