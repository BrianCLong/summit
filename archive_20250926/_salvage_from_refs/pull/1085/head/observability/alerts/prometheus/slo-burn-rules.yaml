# Prometheus recording + alerting rules for SLO error-budget burn
# NOTE: Replace metric names/labels to match your exporters.

groups:
  - name: slo-burn
    interval: 30s
    rules:
      # Define error ratio over rolling windows for each expert/tier
      - record: slo:error_ratio:rate5m
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[5m]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[5m])))

      - record: slo:error_ratio:rate30m
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[30m]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[30m])))

      - record: slo:error_ratio:rate1h
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[1h]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[1h])))

      - record: slo:error_ratio:rate6h
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[6h]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[6h])))

  - name: slo-burn-alerts
    interval: 30s
    rules:
      # Fast burn (page) — 2% budget in 1h or 5% in 6h equivalent
      - alert: SLOErrorBudgetBurnFast
        expr: |
          (slo:error_ratio:rate5m > on(expert, tenant_tier) group_left slo:target_error_ratio)
          and
          (slo:error_ratio:rate1h > on(expert, tenant_tier) group_left slo:target_error_ratio)
        for: 10m
        labels:
          severity: page
        annotations:
          summary: "Fast SLO burn for {{ $labels.expert }} ({{ $labels.tenant_tier }})"
          description: |
            Error ratio breaching target over 5m and 1h. Investigate acute incidents, rollbacks, or hot tenants.

      # Slow burn (ticket) — 1% budget in 24h equivalent
      - alert: SLOErrorBudgetBurnSlow
        expr: |
          (slo:error_ratio:rate30m > on(expert, tenant_tier) group_left slo:target_error_ratio)
          and
          (slo:error_ratio:rate6h > on(expert, tenant_tier) group_left slo:target_error_ratio)
        for: 2h
        labels:
          severity: ticket
        annotations:
          summary: "Slow SLO burn for {{ $labels.expert }} ({{ $labels.tenant_tier }})"
          description: |
            Sustained burn above target. Plan remediation; consider feature freeze for affected scope.

  - name: slo-targets
    rules:
      # Target error ratios per expert/tier derived from SLOs
      # For example, rag_retrieval with 99% SLO => target_error_ratio=0.01
      # Provision these as static metrics via the pushgateway or sidecar exporter if desired.
      # This is a placeholder vector to enable rule wiring; replace with your target source.
      - record: slo:target_error_ratio
        expr: |
          0.01
        labels:
          expert: "rag_retrieval"
          tenant_tier: "gold"

