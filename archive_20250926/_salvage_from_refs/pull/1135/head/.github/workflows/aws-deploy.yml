name: Deploy to AWS Free Tier
# Zero-cost production deployment using AWS Always-Free services
# Enhanced power with t4g.small + CloudFront + comprehensive monitoring

on:
  push:
    branches: [main]
    paths:
      - 'server/**'
      - 'conductor-ui/**'
      - 'deploy/aws/**'
      - '.github/workflows/aws-deploy.yml'

  pull_request:
    branches: [main]
    paths:
      - 'server/**'
      - 'conductor-ui/**'
      - 'deploy/aws/**'

  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'staging'
        type: choice
        options:
          - staging
          - production

      force_rebuild:
        description: 'Force rebuild of infrastructure'
        required: false
        default: false
        type: boolean

      skip_tests:
        description: 'Skip test execution'
        required: false
        default: false
        type: boolean

env:
  AWS_REGION: us-east-1
  NODE_VERSION: '18'
  DOCKER_BUILDKIT: 1
  COSIGN_EXPERIMENTAL: 1

jobs:
  # Pre-flight checks and validation
  preflight:
    name: Pre-flight Validation
    runs-on: ubuntu-latest
    outputs:
      should-deploy: ${{ steps.changes.outputs.should-deploy }}
      image-tag: ${{ steps.meta.outputs.tags }}
      image-digest: ${{ steps.meta.outputs.digest }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Check for changes
        id: changes
        run: |
          if [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
          elif [[ "${{ github.event_name }}" == "push" ]]; then
            echo "should-deploy=true" >> $GITHUB_OUTPUT
          else
            echo "should-deploy=false" >> $GITHUB_OUTPUT
          fi

      - name: Generate image metadata
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ghcr.io/${{ github.repository }}/maestro
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Validate AWS configuration
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          # Validate AWS credentials are present
          if [[ -z "$AWS_ACCESS_KEY_ID" || -z "$AWS_SECRET_ACCESS_KEY" ]]; then
            echo "❌ AWS credentials not configured"
            exit 1
          fi
          echo "✅ AWS credentials configured"

      - name: Security scan
        if: ${{ !inputs.skip_tests }}
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

      - name: Upload security scan results
        if: ${{ !inputs.skip_tests }}
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: 'trivy-results.sarif'

  # Build and test Maestro application
  build-test:
    name: Build & Test Maestro
    runs-on: ubuntu-latest
    needs: preflight
    if: needs.preflight.outputs.should-deploy == 'true'
    outputs:
      image-digest: ${{ steps.build.outputs.digest }}
      image-ref: ${{ steps.build.outputs.imageid }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: |
            server/package-lock.json
            conductor-ui/package-lock.json

      - name: Install dependencies
        run: |
          cd server && npm ci
          cd ../conductor-ui && npm ci

      - name: Run tests
        if: ${{ !inputs.skip_tests }}
        run: |
          cd server
          npm run test:unit
          npm run test:integration
          npm run lint
          npm run typecheck

      - name: Build application
        run: |
          cd server && npm run build
          cd ../conductor-ui && npm run build

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        id: build
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./deploy/aws/Dockerfile
          platforms: linux/arm64,linux/amd64
          push: true
          tags: ${{ needs.preflight.outputs.image-tag }}
          labels: |
            org.opencontainers.image.source=${{ github.server_url }}/${{ github.repository }}
            org.opencontainers.image.revision=${{ github.sha }}
            org.opencontainers.image.created=${{ github.event.head_commit.timestamp }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          sbom: true
          provenance: true
          annotations: |
            org.opencontainers.image.title=Maestro Conductor
            org.opencontainers.image.description=IntelGraph Maestro Conductor - AI-Augmented Intelligence Analysis Platform
            org.opencontainers.image.vendor=IntelGraph

      - name: Install Cosign
        uses: sigstore/cosign-installer@v3

      - name: Sign container image
        run: |
          cosign sign --yes ${{ steps.build.outputs.imageid }}

      - name: Verify image signature
        run: |
          cosign verify --certificate-oidc-issuer https://token.actions.githubusercontent.com \
            --certificate-identity-regexp 'https://github\.com/${{ github.repository }}/' \
            ${{ steps.build.outputs.imageid }}

      - name: Run container security scan
        uses: aquasecurity/trivy-action@master
        with:
          image-ref: ${{ steps.build.outputs.imageid }}
          format: 'json'
          output: 'trivy-image-results.json'

      - name: Upload image scan results
        uses: actions/upload-artifact@v4
        with:
          name: trivy-image-scan
          path: trivy-image-results.json

  # Deploy to staging environment
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [preflight, build-test]
    if: needs.preflight.outputs.should-deploy == 'true' && (github.ref == 'refs/heads/main' || inputs.environment == 'staging')
    environment:
      name: staging
      url: https://staging.${{ vars.ROOT_DOMAIN }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl and helm
        run: |
          # Install kubectl
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl

          # Install helm
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

          # Install k6 for load testing
          sudo apt-get update && sudo apt-get install -y gnupg
          curl -s https://dl.k6.io/key.gpg | sudo apt-key add -
          echo "deb https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update && sudo apt-get install -y k6

      - name: Setup kubeconfig
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBECONFIG_STAGING }}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config
          kubectl cluster-info

      - name: Check/Create AWS infrastructure
        if: inputs.force_rebuild == true || github.event_name == 'workflow_dispatch'
        env:
          ROOT_DOMAIN: ${{ vars.ROOT_DOMAIN || 'intelgraph.io' }}
          INSTANCE_TYPE: ${{ vars.INSTANCE_TYPE || 't4g.small' }}
          KEY_NAME: ${{ vars.AWS_KEY_NAME || 'maestro-keypair' }}
        run: |
          # Check if infrastructure exists
          INSTANCE_ID=$(aws ec2 describe-instances \
            --filters "Name=tag:Name,Values=maestro-conductor" "Name=instance-state-name,Values=running" \
            --query 'Reservations[0].Instances[0].InstanceId' \
            --output text 2>/dev/null || echo "None")

          if [[ "$INSTANCE_ID" == "None" ]] || [[ "${{ inputs.force_rebuild }}" == "true" ]]; then
            echo "🚀 Creating AWS infrastructure..."
            chmod +x deploy/aws/zero-cost-production-setup.sh
            deploy/aws/zero-cost-production-setup.sh
          else
            echo "✅ Infrastructure exists: $INSTANCE_ID"
          fi

      - name: Deploy monitoring stack
        run: |
          echo "📊 Deploying enhanced monitoring..."
          kubectl apply -f deploy/aws/enhanced-monitoring.yaml
          kubectl rollout status deployment/prometheus -n monitoring --timeout=300s
          kubectl rollout status deployment/grafana -n monitoring --timeout=300s

      - name: Deploy security hardening
        run: |
          echo "🔒 Applying security hardening..."
          kubectl apply -f deploy/aws/security-hardening.yaml

          # Wait for Gatekeeper to be ready
          kubectl wait --for=condition=Ready pods -l gatekeeper.sh/operation=webhook -n gatekeeper-system --timeout=300s || true

      - name: Deploy Maestro to staging
        env:
          IMAGE_REF: ${{ needs.build-test.outputs.image-ref }}
          ENVIRONMENT: staging
        run: |
          echo "🎭 Deploying Maestro to staging..."

          # Create staging namespace if it doesn't exist
          kubectl create namespace maestro-staging --dry-run=client -o yaml | kubectl apply -f -

          # Apply resource quotas and limits
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: ResourceQuota
          metadata:
            name: staging-quota
            namespace: maestro-staging
          spec:
            hard:
              requests.cpu: "1"
              requests.memory: 2Gi
              limits.cpu: "2"
              limits.memory: 4Gi
              pods: "10"
          ---
          apiVersion: v1
          kind: LimitRange
          metadata:
            name: staging-limits
            namespace: maestro-staging
          spec:
            limits:
            - type: Container
              default:
                cpu: "500m"
                memory: "512Mi"
              defaultRequest:
                cpu: "100m"
                memory: "128Mi"
          EOF

          # Deploy using Helm
          helm upgrade --install maestro-staging ./charts/maestro \
            --namespace maestro-staging \
            --set image.repository=ghcr.io/${{ github.repository }}/maestro \
            --set image.tag=${{ github.sha }} \
            --set image.digest=${{ needs.build-test.outputs.image-digest }} \
            --set environment=staging \
            --set ingress.enabled=true \
            --set ingress.hosts[0].host=staging.${{ vars.ROOT_DOMAIN }} \
            --set ingress.hosts[0].paths[0].path="/" \
            --set ingress.hosts[0].paths[0].pathType=Prefix \
            --set resources.requests.cpu=100m \
            --set resources.requests.memory=256Mi \
            --set resources.limits.cpu=500m \
            --set resources.limits.memory=512Mi \
            --set autoscaling.enabled=true \
            --set autoscaling.minReplicas=1 \
            --set autoscaling.maxReplicas=3 \
            --wait --timeout=600s

      - name: Run smoke tests
        run: |
          echo "🧪 Running smoke tests..."

          # Wait for deployment to be ready
          kubectl rollout status deployment/maestro-staging -n maestro-staging --timeout=300s

          # Get service endpoint
          STAGING_URL="https://staging.${{ vars.ROOT_DOMAIN }}"

          # Basic health check
          for i in {1..30}; do
            if curl -f -s "$STAGING_URL/healthz" > /dev/null; then
              echo "✅ Health check passed"
              break
            fi
            echo "Waiting for service to be ready... ($i/30)"
            sleep 10
          done

          # Load test
          cat > /tmp/load-test.js <<'EOF'
          import http from 'k6/http';
          import { check, sleep } from 'k6';
          import { Rate } from 'k6/metrics';

          export let errorRate = new Rate('errors');
          export let options = {
            stages: [
              { duration: '1m', target: 5 },
              { duration: '2m', target: 5 },
              { duration: '1m', target: 0 },
            ],
            thresholds: {
              'http_req_duration': ['p(95)<3000'],
              'errors': ['rate<0.05'],
            }
          };

          export default function() {
            let response = http.get(__ENV.TARGET_URL + '/healthz');
            let result = check(response, {
              'status is 200': (r) => r.status === 200,
              'response time OK': (r) => r.timings.duration < 3000,
            });
            errorRate.add(!result);
            sleep(1);
          }
          EOF

          k6 run --env TARGET_URL="$STAGING_URL" /tmp/load-test.js

      - name: Update deployment status
        if: always()
        run: |
          if [[ "${{ job.status }}" == "success" ]]; then
            echo "✅ Staging deployment successful"
            echo "🌍 Staging URL: https://staging.${{ vars.ROOT_DOMAIN }}"
          else
            echo "❌ Staging deployment failed"
            # Get pod logs for debugging
            kubectl logs -l app=maestro -n maestro-staging --tail=100 || true
          fi

  # Deploy to production environment
  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: [preflight, build-test, deploy-staging]
    if: needs.preflight.outputs.should-deploy == 'true' && (startsWith(github.ref, 'refs/tags/prod-') || inputs.environment == 'production')
    environment:
      name: production
      url: https://maestro.${{ vars.ROOT_DOMAIN }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install tools
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install kubectl /usr/local/bin/kubectl
          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

          # Install Argo Rollouts CLI
          curl -LO https://github.com/argoproj/argo-rollouts/releases/latest/download/kubectl-argo-rollouts-linux-amd64
          chmod +x kubectl-argo-rollouts-linux-amd64
          sudo mv kubectl-argo-rollouts-linux-amd64 /usr/local/bin/kubectl-argo-rollouts

      - name: Setup kubeconfig
        run: |
          mkdir -p ~/.kube
          echo "${{ secrets.KUBECONFIG_PRODUCTION }}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config

      - name: Deploy Maestro to production with canary
        env:
          IMAGE_REF: ${{ needs.build-test.outputs.image-ref }}
        run: |
          echo "🚀 Deploying Maestro to production with canary rollout..."

          # Create production namespace
          kubectl create namespace maestro-prod --dry-run=client -o yaml | kubectl apply -f -

          # Apply production resource quotas
          kubectl apply -f - <<EOF
          apiVersion: v1
          kind: ResourceQuota
          metadata:
            name: production-quota
            namespace: maestro-prod
          spec:
            hard:
              requests.cpu: "2"
              requests.memory: 4Gi
              limits.cpu: "4"
              limits.memory: 8Gi
              pods: "20"
          EOF

          # Deploy with canary strategy
          helm upgrade --install maestro-prod ./charts/maestro \
            --namespace maestro-prod \
            --set image.repository=ghcr.io/${{ github.repository }}/maestro \
            --set image.tag=${{ github.sha }} \
            --set image.digest=${{ needs.build-test.outputs.image-digest }} \
            --set environment=production \
            --set strategy.type=Rollout \
            --set rollout.enabled=true \
            --set rollout.strategy.canary.steps[0].setWeight=10 \
            --set rollout.strategy.canary.steps[1].pause.duration=60 \
            --set rollout.strategy.canary.steps[2].setWeight=25 \
            --set rollout.strategy.canary.steps[3].pause.duration=60 \
            --set rollout.strategy.canary.steps[4].setWeight=50 \
            --set rollout.strategy.canary.steps[5].pause.duration=120 \
            --set rollout.strategy.canary.steps[6].setWeight=75 \
            --set rollout.strategy.canary.steps[7].pause.duration=60 \
            --set resources.requests.cpu=200m \
            --set resources.requests.memory=512Mi \
            --set resources.limits.cpu=1000m \
            --set resources.limits.memory=1Gi \
            --set autoscaling.enabled=true \
            --set autoscaling.minReplicas=2 \
            --set autoscaling.maxReplicas=10 \
            --wait --timeout=300s

      - name: Monitor canary rollout
        timeout-minutes: 20
        run: |
          echo "👁️ Monitoring canary rollout..."

          # Wait for rollout to start
          sleep 30

          # Monitor rollout progress
          kubectl argo rollouts get rollout maestro-prod -n maestro-prod --watch &
          WATCH_PID=$!

          # Wait for rollout to complete or timeout
          for i in {1..60}; do
            STATUS=$(kubectl argo rollouts status maestro-prod -n maestro-prod --timeout=10s 2>/dev/null || echo "PROGRESSING")
            if [[ "$STATUS" =~ "Healthy" ]]; then
              echo "✅ Canary rollout completed successfully"
              kill $WATCH_PID 2>/dev/null || true
              break
            elif [[ "$STATUS" =~ "Degraded" ]]; then
              echo "❌ Canary rollout failed"
              kubectl argo rollouts abort maestro-prod -n maestro-prod
              kill $WATCH_PID 2>/dev/null || true
              exit 1
            fi
            echo "Rollout status: $STATUS ($i/60)"
            sleep 20
          done

      - name: Production smoke test
        run: |
          echo "🔍 Running production smoke tests..."

          PROD_URL="https://maestro.${{ vars.ROOT_DOMAIN }}"

          # Wait for service to be ready
          for i in {1..30}; do
            if curl -f -s "$PROD_URL/healthz" > /dev/null; then
              echo "✅ Production health check passed"
              break
            fi
            sleep 10
          done

          # Test key endpoints
          curl -f "$PROD_URL/healthz" || exit 1
          curl -f "$PROD_URL/readyz" || exit 1
          curl -f "$PROD_URL/metrics" | grep -q "maestro_" || exit 1

          echo "✅ Production deployment verified"

      - name: Update CloudFront cache
        run: |
          # Invalidate CloudFront cache for new deployment
          DISTRIBUTION_ID=$(aws cloudfront list-distributions \
            --query "DistributionList.Items[?Aliases.Items[0]=='maestro.${{ vars.ROOT_DOMAIN }}'].Id" \
            --output text)

          if [[ -n "$DISTRIBUTION_ID" && "$DISTRIBUTION_ID" != "None" ]]; then
            echo "♻️ Invalidating CloudFront cache..."
            aws cloudfront create-invalidation \
              --distribution-id "$DISTRIBUTION_ID" \
              --paths "/*" > /dev/null
            echo "✅ Cache invalidation initiated"
          fi

  # Post-deployment validation and reporting
  post-deployment:
    name: Post-Deployment Validation
    runs-on: ubuntu-latest
    needs: [deploy-staging, deploy-production]
    if: always() && (needs.deploy-staging.result == 'success' || needs.deploy-production.result == 'success')
    steps:
      - name: Setup kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          sudo install kubectl /usr/local/bin/kubectl
          mkdir -p ~/.kube
          echo "${{ secrets.KUBECONFIG_PRODUCTION }}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config

      - name: Generate deployment report
        run: |
          echo "# Deployment Report" > deployment-report.md
          echo "" >> deployment-report.md
          echo "**Deployment Time:** $(date)" >> deployment-report.md
          echo "**Git Commit:** ${{ github.sha }}" >> deployment-report.md
          echo "**Image:** ${{ needs.build-test.outputs.image-ref }}" >> deployment-report.md
          echo "" >> deployment-report.md

          if [[ "${{ needs.deploy-staging.result }}" == "success" ]]; then
            echo "✅ **Staging:** https://staging.${{ vars.ROOT_DOMAIN }}" >> deployment-report.md
          fi

          if [[ "${{ needs.deploy-production.result }}" == "success" ]]; then
            echo "✅ **Production:** https://maestro.${{ vars.ROOT_DOMAIN }}" >> deployment-report.md
          fi

          echo "" >> deployment-report.md
          echo "## Resource Usage" >> deployment-report.md

          # Get resource usage
          kubectl top pods -A --sort-by=cpu 2>/dev/null || echo "Resource metrics unavailable" >> deployment-report.md

          echo "" >> deployment-report.md
          echo "## Security Status" >> deployment-report.md

          # Check Gatekeeper violations
          VIOLATIONS=$(kubectl get constraints -o json 2>/dev/null | jq -r '.items[].status.totalViolations // 0' | awk '{sum+=$1} END {print sum}')
          echo "**Policy Violations:** ${VIOLATIONS:-0}" >> deployment-report.md

          # Check Falco alerts (if available)
          FALCO_PODS=$(kubectl get pods -n security-system -l app=falco --no-headers 2>/dev/null | wc -l)
          echo "**Security Monitoring:** ${FALCO_PODS} Falco instances running" >> deployment-report.md

      - name: Upload deployment report
        uses: actions/upload-artifact@v4
        with:
          name: deployment-report
          path: deployment-report.md

      - name: Notify deployment success
        if: needs.deploy-production.result == 'success'
        run: |
          echo "🎉 Production deployment successful!"
          echo "🌍 Maestro is live at: https://maestro.${{ vars.ROOT_DOMAIN }}"
          echo "📊 Monitoring: kubectl port-forward svc/grafana 3000:3000 -n monitoring"
