Category,Platform,Type,Key Orchestration,Model Routing,Tool/Connectors,HITL,EvalOps,Observability,Guardrails/Policy,Deployment,License,Notable Strengths,Sources
Agent orchestration (OSS),LangGraph,Library + Platform,"Stateful graphs, control over agent loops, persistence",Framework-level (plug any model),"LangChain ecosystem, Python/JS SDKs",Patterns for HITL via nodes/checkpoints,Integrations with eval tools,LangGraph Platform monitoring,Policies via app; integrates with guardrails,Self-host / LangGraph Platform,OSS + commercial,De-facto standard for stateful agent graphs,https://langchain-ai.github.io/langgraph/;https://docs.langchain.com/langgraph-platform;https://www.langchain.com/langgraph
Agent framework,LlamaIndex,Library + hosted,"Agents, tools, memory; advanced RAG pipelines",Multi-provider via adapters,"Connectors to DBs, vector stores, tools",HITL in workflows/tutorials,Integrations incl. TruLens/Ragas,Tracing via integrations,Policy via guardrails integrations,Library + hosted options,OSS + commercial,Strong data/knowledge tools; flexible agents,https://docs.llamaindex.ai/en/stable/use_cases/agents/;https://docs.llamaindex.ai/en/stable/understanding/agent/
Multi-agent framework,AutoGen,Library (Microsoft),"Event-driven multi-agent chats, tool use & code execution",Provider-agnostic,Tools/functions; human-in-the-loop agent,Built-in human participation modes,Research examples & integrations,Logging hooks; SDK tracing,Policy via app & guardrails,Self-host (library),OSS (MIT),Well-documented multi-agent patterns,https://microsoft.github.io/autogen/stable//index.html;https://microsoft.github.io/autogen/0.2/docs/Use-Cases/agent_chat/;https://github.com/microsoft/autogen
Agent framework,CrewAI,Library + SaaS,Crew of specialized agents with planning/execution,Provider-agnostic,"Tools integrations (search, code, etc.)",HITL approval flows common,Partner evals; patterns,Runtime logs & dashboards,Policy via tool permissions,Library + Enterprise,OSS + commercial,Popular multi-agent automation with simple APIs,https://docs.crewai.com/;https://github.com/crewAIInc/crewAI;https://www.crewai.com/
Cloud agent service,Vertex AI Agent Builder,Managed service,"Multi-agent experiences, ADK, Agent Engine",Across Google & external providers,"Agent Garden tools, Google services",Approvals/task routing,Built-in eval/monitoring (Foundry),Agent Engine monitoring,Content safety & governance,Google Cloud,Commercial,Enterprise-grade multi-agent tooling with ADK,https://cloud.google.com/vertex-ai/generative-ai/docs/agent-builder/overview;https://cloud.google.com/products/agent-builder;https://codelabs.developers.google.com/devsite/codelabs/building-ai-agents-vertexai
Cloud agent service,Amazon Bedrock Agents,Managed service,"Agent builder, action groups, KBs, orchestration",Multi-model providers on Bedrock,"AWS services, API actions, KBs",HITL patterns via workflows,Guardrails & evals options,CloudWatch metrics/logs,Amazon Guardrails & policies,AWS,Commercial,"Tight AWS integration, tool/action groups",https://docs.aws.amazon.com/bedrock/latest/userguide/agents-how.html;https://docs.aws.amazon.com/bedrock/latest/userguide/agents.html;https://aws.amazon.com/bedrock/agents/
Cloud agent service,Azure AI Agent Service (Foundry),Managed service,Host/orchestrate agents; tool use; governance,Azure/OpenAI/HuggingFace etc.,Azure services & search; SDKs,HITL templates/preview,Evaluation & monitoring in Foundry,"Tracing, monitoring",Trustworthy AI & content safety,Azure,Commercial,Strong governance + enterprise security,https://learn.microsoft.com/en-us/azure/ai-foundry/;https://learn.microsoft.com/en-us/rest/api/aifoundry/aiagents/;https://learn.microsoft.com/en-us/python/api/overview/azure/ai-agents-readme
Cloud/Platform,Databricks Mosaic AI Agent Framework,Managed + OSS,Build/deploy agents with tools and RAG; notebooks,Provider-agnostic,Databricks data/tools; LangGraph supported,HITL via workflows,Built-in evals & notebooks,Model Serving metrics,Unity governance & policies,Databricks,Commercial,Tight lakehouse integration; evals & serving,https://docs.databricks.com/aws/en/generative-ai/agent-framework/agent-tool;https://docs.databricks.com/aws/en/generative-ai/tutorials/agent-framework-notebook
Gateway / Router,LiteLLM Proxy,Gateway (self-host/SaaS),"Load-balancing, routing, retries, fallbacks","Yes, across multiple providers","Admin UI, budgets, rate limits",—,Usage analytics; budgets,Plugin-based guardrails incl. Lakera,Self-host/SaaS,OSS + commercial,Popular OpenAI-compatible gateway with budgets,https://docs.litellm.ai/docs/simple_proxy;https://docs.litellm.ai/docs/routing;https://docs.litellm.ai/docs/,
Gateway / Router,OpenRouter,Unified API (SaaS),Unified endpoint across many models; fallbacks,"Yes, hundreds of models",SDKs and OpenAI-compatible API,—,Usage metrics,—,SaaS,Commercial,Large model catalog; easy routing/fallbacks,https://openrouter.ai/docs/quickstart;https://openrouter.ai/docs/api-reference/overview,
Gateway / Control plane,Portkey,Gateway + observability,"Centralized gateway, caching, retries, cost control",Multi-provider,SDKs; plug-in gateway,—,Analytics & debugging,Guardrails via policies,Self-host/SaaS,OSS + commercial,Strong control-plane features + OSS gateway,https://portkey.ai/docs/product/ai-gateway;https://portkey.ai/docs/guides/getting-started/getting-started-with-ai-gateway,
Gateway + Observability,Helicone,Gateway + logging,Unified API with logging & replay,Multi-provider via proxy,"Helpers, SDKs",—,Detailed logs/traces,—,SaaS/OSS,OSS + commercial,Simple drop-in logging/gateway,https://docs.helicone.ai/getting-started/platform-overview;https://docs.helicone.ai/guides/cookbooks/manual-logger-streaming,
Observability & Evals,W&B Weave,Framework + SaaS,Experimentation and deployment workflows,Provider-agnostic,W&B SDKs; LangChain integrations,Annotation loops,Evaluations & datasets,"Tracing, cost, dashboards",Policies via eval gates,Cloud/Self-host,Commercial,Production-grade MLOps lineage for LLM apps,https://weave-docs.wandb.ai/;https://docs.wandb.ai/;https://wandb.ai/site/weave/
Observability & Evals (OSS),Arize Phoenix,Open-source + cloud,"Troubleshooting, evaluation, experiment mgmt",Provider-agnostic,"SDKs, integrations",Annotation/UI review,"Evals, A/B, datasets",Rich tracing & dashboards,—,Self-host/SaaS,OSS + commercial,Deep observability designed for LLMs/agents,https://arize.com/docs/phoenix;https://arize.com/docs/phoenix/user-guide
Eval framework (OSS),TruLens,Library + UI,Programmatic feedback functions; agent evals,—,Integrations (LangChain/LlamaIndex),Supports human feedback,Feedback-based evals; RAG triad,Traces; dashboards,—,Library + SaaS,OSS + commercial,Battle-tested eval primitives & tracing,https://www.trulens.org/;https://docs.llamaindex.ai/en/stable/community/integrations/trulens/;https://github.com/truera/trulens
Safety/Guardrails,Lakera Guard,SaaS + SDK,Screening APIs for threats & policy,—,SDKs; LangChain/LiteLLM integrations,Security review loops,Red teaming & detectors,Reports & logs,"LLM firewall, policies",Cloud/Self-host,Commercial,Enterprise-grade LLM safety controls,https://docs.lakera.ai/;https://docs.lakera.ai/docs/api/guard;https://docs.litellm.ai/docs/proxy/guardrails/lakera_ai
Guardrails toolkit,NVIDIA NeMo Guardrails,OSS + enterprise,Programmable guardrails via Colang,—,Backends & connectors,—,Evaluation tools,Security guidelines,Self-host/Enterprise,OSS + commercial,Rich programmable guardrails; GPU-native ecosystem,https://docs.nvidia.com/nemo/guardrails/latest/index.html;https://developer.nvidia.com/nemo-guardrails,
Agent/RAG framework (OSS),Haystack,Library + platform,"Pipelines, agents as tools, multi-agent comps",Provider-agnostic,"Connectors, retrievers, vector stores",HITL via tutorials,Eval & tracing integrations,Tracing/logging; Studio,Policies via app,Self-host/SaaS (deepset),OSS + commercial,Mature RAG + agents with production focus,https://docs.haystack.deepset.ai/docs/agents;https://haystack.deepset.ai/tutorials/45_creating_a_multi_agent_system
Tooling Protocol,Anthropic MCP,Open protocol,Standardized tool/context servers for agents,Provider-agnostic,MCP servers; integrations,—,—,Permissions & sandboxing patterns,Any,Open standard,Emerging standard for safe tool access & interoperability,https://docs.anthropic.com/en/docs/mcp;https://modelcontextprotocol.io/,
Agentic app platform (OSS/SaaS),Dify,Open-source platform + hosted,"Visual agent workflows, RAG, tools, pipelines",Multi-provider via connectors,App store + integrations,Built-in review/approval patterns,Basic evals; integrations,"Run logs, traces; integrations","Filters, moderation; integrate rails",Self-host/SaaS,OSS + commercial,Fast prototyping to prod; active OSS community,https://dify.ai/;https://github.com/langgenius/dify
Agent workspace,Dust,SaaS platform,Team agents connected to knowledge & tools; MCP support,Best-model selection (SaaS),MCP servers; enterprise tool integrations,Approvals in workspace context,Playground + iter loops,Agent session views,Workspace policies; MCP-secure tool access,Cloud (SaaS),Commercial,Enterprise-friendly agent workspace; MCP tool interop,https://dust.tt/;https://dust.tt/home/solutions/dust-platform
Low-code agent/RAG builder,FlowiseAI,Open-source builder,Drag-drop flows; LangChain agents node,Via provider nodes,Large set of nodes/connectors,Patterns via nodes/webhooks,Through partner tools,Basic tracing/logs,Via guardrail nodes,Self-host,OSS,Very fast prototyping; non-dev friendly,https://docs.flowiseai.com/integrations/langchain/agents
Agent framework (coding agents),Superagent,Open-source + cloud,"Agent orchestration, sandbox integration",Via providers,Developer toolchain integrations,Approval gates for automation,Partner evals,Runtime dashboards/logs,Runtime firewall/safety controls,Self-host/SaaS,OSS + commercial,Production-focused coding agents; safety-first posture,https://superagent.sh/;https://github.com/superagent-ai/superagent
Agent framework (Python),Griptape,Open-source + cloud,Agents/Tasks/Tools with policies and memory,Provider-agnostic,Tools SDK + RAG components,Hand-offs supported,Via integrations,Via integrations,Policy constructs; tool permissions,Self-host/Cloud,OSS + commercial cloud,Well-structured Python framework; tool safety,https://docs.griptape.ai/stable/;https://docs.griptape.ai/stable/griptape-framework/structures/agents/;https://github.com/griptape-ai/griptape
Enterprise agent service,IBM watsonx Orchestrate + watsonx.governance,Managed + governance suite,Business task agents & skills,Watsonx.ai models + connectors,IBM & SaaS integrations,Approvals & workflows,Governance metrics & validation,Governance dashboards,"Strong governance, explainability",IBM Cloud/Enterprise,Commercial,Governance-first agents; enterprise compliance,https://www.ibm.com/products/watsonx-orchestrate;https://www.ibm.com/products/watsonx-governance;https://www.ibm.com/docs/en/watsonx/w-and-w/2.0.0?topic=overview-watsonx
Vendor-specific agent platform,Salesforce Einstein Copilot Studio / Agentforce,SaaS (Salesforce),Copilots with actions/flows; CRM grounding,Salesforce model endpoints + partner models,"Salesforce apps, data, APIs",CRM approvals/hand-offs,Admin analytics; eval patterns,Audit logs & analytics,Enterprise data policies,Salesforce Cloud,Commercial,Deep CRM grounding & action execution,https://trailhead.salesforce.com/content/learn/modules/einstein-copilot-basics/get-started-with-einstein-copilot
Prompt/Eval/Deploy platform,Vellum,SaaS,Workflow/prompt experiments & deployment,Multi-model via connectors,SDKs & integrations,Review workflows,Quantitative evals & benchmarks,Monitoring & analytics,Policy/custom metrics via evals,Cloud,Commercial,Strong evaluations + prompt/version ops,https://docs.vellum.ai/product/getting-started/overview;https://www.vellum.ai/products/evaluation
Evals & Monitoring,Parea AI,SaaS + SDK,N/A,N/A,Python/TS SDKs,Human review support,Evaluation framework & metrics,Logging & dashboards,Via evaluators/policies,Cloud/self-host option,Commercial,Simple SDK-first evals + monitoring,https://docs.parea.ai/evaluation/overview;https://github.com/parea-ai/parea-sdk-py
Eval framework (OSS),Ragas,Open-source library,N/A,N/A,Python; agents/RAG examples,Human feedback integration,RAG/LLM metrics library,Via partners,Via evaluators,Library,OSS,Popular open metrics for RAG & agents,https://docs.ragas.io/en/stable/;https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/
Eval framework + UI,Confident AI (DeepEval),SaaS + OSS lib,N/A,N/A,SDK + integrations,UI review & datasets,DeepEval framework + dashboards,Traces & metrics,Eval-based gates,Cloud + library,OSS + commercial,End-to-end evals atop DeepEval,https://www.confident-ai.com/;https://www.confident-ai.com/docs;https://github.com/confident-ai/deepeval
Safety & eval (SaaS),Patronus AI,SaaS API,N/A,N/A,APIs; CrewAI integration,Review workflows,Safety/quality evals; testing suites,Dashboards,Toxicity/PII detectors,Cloud,Commercial,Production-grade safety evals for LLM/agents,https://www.patronus.ai/;https://docs.crewai.com/observability/patronus-evaluation
Gateway/Router (SaaS),Eden AI,Unified API,Provider aggregation & unified endpoints,Yes (multi-provider),OpenAI-compatible endpoints; monitoring,N/A,Basic usage analytics,Monitoring & reporting,N/A,SaaS,Commercial,One-API to many models; centralized billing,https://www.edenai.co/;https://www.edenai.co/technologies/generative-ai;https://www.edenai.co/post/how-to-build-an-app-with-a-multimodal-image-text-chat-endpoint-compatible-with-openai
Model endpoints/gateway,OctoAI,Hosted inference,Endpoint orchestration for many models,Multi-model endpoints,LangChain integrations,N/A,Usage metrics,Dashboards/metrics,Policies via platform,Cloud,Commercial,High-perf hosted endpoints; simple integration,https://python.langchain.com/docs/integrations/llms/octoai/;https://python.langchain.com/docs/integrations/chat/octoai/
Serving framework,BentoML,OSS + Cloud,Model serving microservices,Via app code/gateway,BentoCloud; SDKs,N/A,Monitoring integrations,Service metrics,Via app middleware,Self-host/Cloud,OSS + commercial,Mature serving stack; easy API packaging,https://docs.bentoml.com/;https://github.com/bentoml/BentoML
Serving (Kubernetes),KServe ModelMesh,OSS,Multi-model serving & routing,Yes (per-model routing),K8s/CRDs; object stores,N/A,Via monitoring stacks,K8s metrics/logs,K8s policies,Kubernetes,OSS (Apache-2.0),High-scale/high-density multi-model serving,https://kserve.github.io/website/latest/admin/modelmesh/;https://github.com/kserve/modelmesh
Serving (GPU-optimized),NVIDIA Triton Inference Server,OSS + Enterprise,"Ensembles, dynamic batching, multi-GPU",Dynamic instance mgmt,Multiple backends; custom backends,N/A,Prometheus/Grafana,Detailed metrics; profiling,Infra policies,On-prem/Cloud/K8s,OSS + Enterprise,"High-throughput, ensemble pipelines",https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html;https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/user_guide/architecture.html
Serving (distributed Python),Ray Serve,OSS,Composable deployments for inference/LLMs,Request routing across deployments,Python-native; integrates w/ frameworks,N/A,Via metrics/logging,Dashboards; Prometheus,Via app code,Self-host/K8s/Anyscale,OSS,Flexible microservice composition for inference,https://docs.ray.io/en/latest/serve/index.html;https://docs.ray.io/en/latest/serve/key-concepts.html
Guardrails framework,Guardrails AI,OSS + SaaS,Input/Output guards; structured outputs,N/A,Guard hub; SDKs,Human review hooks,Guard-based metrics,Logging integrations,Risk detection/mitigation,Library/SaaS,OSS + commercial,Rich catalog of risks/guards; schema validation,https://guardrailsai.com/docs/;https://github.com/guardrails-ai/guardrails
Testing & Security,Giskard,OSS + SaaS,N/A,N/A,SDK; CI; notebooks,Human testing workflows,LLM evaluation & vulnerability scans,Reports/dashboards,Security tests & scans,Self-host/SaaS,OSS + commercial,Automated LLM security testing + evals,https://docs.giskard.ai/;https://docs-hub.giskard.ai/start/glossary/testing_methodologies.html
Observability & Evals (SaaS),HoneyHive,SaaS,N/A,N/A,SDK + UI,"Human review, annotation","Automated evals, A/B, CI","Traces, session replays",Policies via eval gates,Cloud,Commercial,Agent/chain observability with CI eval loops,https://www.honeyhive.ai/;https://www.honeyhive.ai/evaluation;https://www.honeyhive.ai/observability
CLI eval/red-team,promptfoo,Open-source CLI + lib,N/A,N/A,"CLI, MCP server, providers",Human-in-the-loop scoring possible,"Automated tests, red teaming",Reports/artifacts,Assertions & scans,Local/CI/CD,OSS,Developer-friendly automated evals + red-team,https://www.promptfoo.dev/docs/usage/command-line/;https://www.promptfoo.dev/docs/intro/
Observability + Prompt Mgmt,Langfuse,OSS + Cloud,Prompt versioning/registry & experiments,Provider-agnostic,SDKs; OpenTelemetry; LangChain/LangGraph,Human annotation support,Evaluations & datasets,Deep traces/cost metrics,RBAC & protected labels,Self-host/SaaS,OSS + commercial,Strong tracing + prompt mgmt with OTEL support,https://langfuse.com/docs;https://langfuse.com/docs/tracing;https://langfuse.com/docs/prompts/get-started
