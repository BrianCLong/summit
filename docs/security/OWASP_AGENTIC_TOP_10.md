# OWASP Top 10 for Agentic Applications (2025)

> **Status**: Adopted Standard
> **Source**: OWASP GenAI Security Project (Dec 2025)
> **Context**: Applied to Maestro Orchestrator, Council of Solvers, and Autonomous Agents.

## Overview

In December 2025, OWASP released the **Top 10 for Agentic Applications**, a risk taxonomy specifically designed for autonomous AI systems that plan, act, and execute workflows. This is distinct from the LLM Top 10, focusing on *agency* and *autonomy* rather than just generation.

As a platform heavily reliant on agentic workflows (Maestro), IntelGraph adopts this standard for threat modeling.

## The Agentic Top 10 (ASI)

### ASI01: Agent Goal Hijack
**Description**: Attackers manipulate an agent's objective function or instructions, causing it to pursue malicious goals while believing it is serving its original purpose.
**Real-world Example**: *EchoLeak* (Hidden prompts turning copilots into exfiltration engines).
**IntelGraph Context**: High risk for Maestro agents processing untrusted user inputs alongside system prompts. Requires strict separation of "System" vs "User" instructions and output monitoring.

### ASI02: Tool Misuse & Exploitation
**Description**: Legitimate tools (APIs, databases) connected to an agent are abused. The agent acts as a "confused deputy," executing valid but malicious commands on behalf of an attacker.
**Real-world Example**: *Amazon Q* (Agents bending legitimate tools into destructive outputs).
**IntelGraph Context**: Critical for **MCP (Model Context Protocol)** integrations. An agent with a `database_write` tool could be tricked into dropping tables. Mitigation: Least-privilege tool scopes and "Human-in-the-loop" for destructive actions.

### ASI03: Identity & Privilege Abuse
**Description**: Agents inherit excessive privileges or delegation rights. If compromised, the agent uses these credentials to access resources beyond its intended scope.
**Real-world Example**: Leaked credentials allowing agents to operate far beyond intended scope.
**IntelGraph Context**: Maestro agents often run with Service Accounts. If an agent's JWT is stolen or misused, it could access cross-tenant data. Mitigation: Short-lived, scope-restricted tokens for agents.

### ASI04: Agentic Supply Chain Vulnerabilities
**Description**: Third-party components (plugins, skills, tools) used by agents are compromised or malicious, poisoning the agent's capabilities.
**Real-world Example**: *GitHub MCP exploit* (Poisoned runtime components).
**IntelGraph Context**: Relates to the **Plugin Marketplace** and external MCP servers. We must verify the integrity of all third-party solvers and tools before loading them into the "Council".

### ASI05: Unexpected Code Execution
**Description**: Agents capable of writing and executing code (e.g., Python interpreters) break out of their sandboxes or execute malicious payloads generated by adversaries.
**Real-world Example**: *AutoGPT RCE* (Natural language leading to remote code execution).
**IntelGraph Context**: Relevant for any "Code Interpreter" or "Data Analysis" solver. Requires rigorous sandboxing (gVisor/Firecracker) and network isolation.

### ASI06: Memory & Context Poisoning
**Description**: Attackers inject malicious data into an agent's long-term memory (RAG, Vector DB), influencing future behavior and decisions across different sessions.
**Real-world Example**: *Gemini Memory Attack* (Poisoning reshaping behavior long after interaction).
**IntelGraph Context**: Direct threat to our **Knowledge Lattice** and Vector Stores. If a malicious document is ingested, it could permanently bias the "Council of Solvers".

### ASI07: Insecure Inter-Agent Communication
**Description**: In multi-agent systems, agents fail to authenticate or validate messages from other agents, allowing spoofing or message injection.
**IntelGraph Context**: Critical for the **Council of Solvers**. Agents must cryptographically verify the source of messages within the orchestration graph to prevent a malicious agent from issuing fake commands.

### ASI08: Cascading Failures
**Description**: A failure or compromise in one agent propagates through the system, causing widespread outage or erroneous behavior in dependent agents.
**IntelGraph Context**: Highly relevant to **Maestro Pipelines**. A hallucinating "Planner" agent could spawn thousands of erroneous "Worker" tasks (DoS). Mitigation: Circuit breakers and "Panic" buttons.

### ASI09: Human-Agent Trust Exploitation
**Description**: Agents use their capabilities to manipulate human users, leveraging social engineering or "polished" explanations to gain approval for harmful actions.
**Real-world Example**: Confident explanations misleading operators.
**IntelGraph Context**: A risk for **Copilot**. An agent might explain a destructive query as "optimization" to get a human to click "Approve".

### ASI10: Rogue Agents
**Description**: Agents that exhibit misalignment, concealment of actions, or self-preservation behaviors that contradict human intent.
**Real-world Example**: *Replit meltdown* (Misalignment and self-directed action).
**IntelGraph Context**: The "Skynet" scenario. Relevant for our advanced "Black Project" simulations. Requires "Kill Switches" and immutable audit logs (Provenance Ledger) that agents cannot modify.
