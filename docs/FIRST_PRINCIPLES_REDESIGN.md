# First-Principles System Redesign: The "Cognitive Lattice"

> **Generated by Jules (System Architect Persona)**
> **Date:** October 2025
> **Directive:** Zero-Base Derivation & Total Architecture Rebuild

---

## 1. The Zero-Base Derivation (The Ideal)

If we were building the **Summit IntelGraph Platform** today—knowing it is an AI-augmented, multi-user, real-time intelligence system—we would not build a monolithic Node.js REST/GraphQL API. We would build a **Cognitive Lattice**.

### The Core Concept
The system is not a "database with an API". It is a **Simulated Information Environment** where:
1.  **Data** is a stream of immutable events (Evidence).
2.  **State** (The Graph) is a live, eventually consistent projection of those events.
3.  **Agents** are first-class residents that subscribe to the stream and emit new events (Insights), indistinguishable from human users.

### The Ideal Architecture Stack ("The Blueprint")

1.  **The Spine (Event Log)**:
    *   **Technology**: High-throughput immutable log (e.g., Redpanda/Kafka or Postgres Event Store).
    *   **Role**: The single Source of Truth. All data (Ingest, User Edits, AI Predictions) enters here.
    *   **Constraint**: No service writes directly to Neo4j or Postgres tables. They write *Events* to the Spine.

2.  **The Brain (Cognitive Runtime)**:
    *   **Technology**: Python (for AI/ML) and Rust (for performance) Actor System (e.g., Dapr or Ray).
    *   **Role**: Hosts "Agents" (Analyst Copilot, Harvester, Monitor).
    *   **Behavior**: Agents sleep until relevant Events appear on the Spine, process them, and emit "Insight" Events.

3.  **The View (Projections)**:
    *   **Technology**: Neo4j (Graph View), Elastic (Search View), Postgres (Relational View).
    *   **Role**: pure *Read Models*. They subscribe to the Spine and update themselves. They can be blown away and rebuilt from the Log at any time.

4.  **The Skin (Local-First Frontend)**:
    *   **Technology**: React + Wasm (SQLite/DuckDB in browser) + Sync Engine (Replicache/ElectricSQL).
    *   **Role**: Collaborative workspace. Instead of REST calls (`POST /entity`), the UI writes to a local transaction log which syncs to the Spine. Latency is zero. Collaboration is CRDT-based.

---

## 2. Gap Analysis (The Reality)

Comparing the **Blueprint** to the current **Codebase**:

| Feature | The Ideal (Blueprint) | The Reality (Current Codebase) | The Gap |
| :--- | :--- | :--- | :--- |
| **Source of Truth** | Immutable Event Log | Split brain: Neo4j + Postgres + some Redux state. | **High Risk**: Sync logic in `IntelGraphService.ts` is fragile. |
| **Data Flow** | Event-Driven (Push) | Request-Driven (CRUD). 150+ Services mutating DBs. | **Bottleneck**: Adding a new AI feature requires hooking 5 services. |
| **Agent Integration** | Native Actors | "Sidecar" Workers (BullMQ) polling DBs. | **Latency**: Agents are reactive/slow, not proactive/real-time. |
| **Frontend State** | Local-First (CRDTs) | Heavy Redux + Socket.io "Op" pushing. | **Complexity**: Massive `graphSlice.js` (13KB+) handling sync logic manually. |
| **Performance** | Rust/Wasm Core | Node.js Main Thread. | **Ceiling**: Graph algos in JS/TS will hit limits on large graphs. |
| **Structure** | Domain Ecosystems | Monolithic `server/src` directory. | **Developer Exp**: "Spaghetti dependencies" in imports. |

### Critical Friction Points
1.  **"Service Bloat"**: `server/src/services` has 150+ files. This is unmaintainable. It mixes "Business Logic", "Data Access", and "API Glue".
2.  **Redux Boilerplate**: The client `store/` is huge. Managing graph state in Redux is slow and memory-intensive compared to a dedicated graph model.
3.  **Fragile Sync**: The `IntelGraphService` manually writes to Neo4j and then Postgres. If one fails, data is corrupted (Dual Write Problem).

---

## 3. The Reconstruction Plan

We cannot stop the world to rewrite. We must **strangle the monolith**.

### Phase 1: The Event Spine (Foundation)
*   **Action**: Introduce `ProvenanceLedger` as the *primary* write path.
*   **Step**: Modify `IntelGraphService` to write to the Ledger *first*, and have a background worker update Neo4j/Postgres.
*   **Goal**: Decouple Writes from Reads.

### Phase 2: Agent Extraction (The Brain)
*   **Action**: Move `server/src/ai` and `server/src/services/analysis` logic into a standalone Python/Rust service (`apps/cognitive-engine`).
*   **Step**: Define a strict gRPC/Protobuf contract between the Node Monolith and the Cognitive Engine.
*   **Goal**: Allow AI teams to iterate in Python without touching the Node backend.

### Phase 3: Frontend Simplification (The Skin)
*   **Action**: Replace Redux `graphSlice` with a dedicated Graph Object Model (using `mobx` or `signals`).
*   **Step**: Introduce a "Sync Worker" that handles Socket.io events and updates the model, bypassing React rendering cycle for data updates.
*   **Goal**: 60fps graph interaction even with 10k nodes.

### Phase 4: Structural Cleanup
*   **Action**: Break `server/src` into `packages/` (Monorepo transition).
*   **Step**: Move `auth`, `maestro`, `graph` into separate local packages.
*   **Goal**: Enforce boundaries. `auth` shouldn't import `graph`.

---

## 4. Immediate Next Steps (The "Jules" Directive)

1.  **Freeze `server/src/services`**: No new logic here unless absolutely necessary. Put new logic in `packages/`.
2.  **Harden the Ledger**: Ensure `prov-ledger` is robust enough to be the Spine.
3.  **Prototype the Rust Runner**: The `rust/psc-runner` exists. We should make it the default for heavy graph algos.

*Signed,*
*Jules (System Architect)*
