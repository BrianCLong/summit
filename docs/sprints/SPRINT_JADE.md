# DIRECTORATE J ∑ READY

[Mode: **JADE** | Classification: **INTERNAL / NEED-TO-KNOW** | Retention: **30 days unless promoted to program record**]

## A) Exec Thesis (Sprint North Star)

* **Sprint Goal (2 weeks):** convert “strategy intent” into an **option-portfolio + measurable control plane** so we can move first, measure impact, and roll back safely.
* **Decisive idea:** run **six parallel workstreams** with one shared spine: *initiative map → priority bets → controls/telemetry → narrative cover → policy surface → scorecard/tripwires*.
* **Next best action (today):** lock a **single Sprint Objective + 3 Sprint Metrics**, then ship **v1 artifacts** that make Week 3 execution unblocked.
* **Definition of Done (DoD-J):** COA chosen, scorecard live, owners assigned, rollback criteria written, evidence/assumptions logged.

---

## B) Next Sprint Across Workstreams (2-week plan)

### Shared Sprint Objective (applies to all workstreams)

**Deliver “Strategy-to-Execution Kit v1”**: a small set of auditable artifacts that enable fast execution with bounded risk.

### Shared Sprint Metrics (pick 3 and track daily)

1. % of priority decisions unblocked (target: **>80%** by Sprint end)
2. Lead-time from question → decision (target: **<48h** median)
3. Risk coverage for top 5 threats (target: **>70% control-mapped**)

---

# Workstream 1 — [JADE] Strategic Foresight & Portfolio Design

**Outcome:** clear map of the initiative space + scenario signposts + option portfolio.

**Sprint Backlog**

* **JS-1: Initiative Space Map v1**

  * Deliverable: 1-page map of *choke points, standards, incentives, coalitions, architecture moves*.
  * Acceptance: each node has (a) leverage rationale, (b) owner, (c) measurable indicator.
* **JS-2: Scenario Set v1 (P10/P50/P90)**

  * Deliverable: 2×2 (or 3-scenario) with signposts + early warnings.
  * Acceptance: 5 signposts, 10 early-warning indicators, review cadence.
* **JS-3: Option Portfolio v1**

  * Deliverable: 6–10 options, ranked by **option value**, reversibility, and systemic leverage.
  * Acceptance: each option has cost band, dependencies, rollback trigger.

**Dependencies:** inputs from Policy (surface constraints) + JINX (threat reality check).
**Decision Gate (end of sprint):** choose **Top 2 options** to execute next sprint.

---

# Workstream 2 — [JAVELIN] Competitive / GTM & Ecosystem Moves

**Outcome:** moat-building moves that shrink adversary options and grow ours.

**Sprint Backlog**

* **JV-1: Moat Hypotheses v1 (3–5)**

  * Examples: standards influence, switching costs, distribution leverage, compliance capital.
  * Acceptance: each has falsifiable test + leading indicator.
* **JV-2: Partner/Coalition Target List v1**

  * Deliverable: 15 targets grouped by incentive alignment + outreach narrative.
  * Acceptance: top 5 have a “first meeting ask” + mutual value exchange.
* **JV-3: Packaging/Pricing Guardrails v1**

  * Deliverable: constraints + experiment matrix (no need to finalize pricing).
  * Acceptance: includes risk checks (brand, legal, channel conflict).

**Dependencies:** Narrative (message discipline) + Policy (claims allowed).
**Decision Gate:** pick **1 ecosystem wedge** to operationalize.

---

# Workstream 3 — [JURY] Policy / Legal / Standards Strategy

**Outcome:** create compliant “lanes” and influence points before execution begins.

**Sprint Backlog**

* **JU-1: Regulatory & Standards Surface Scan v1**

  * Deliverable: jurisdictions/standards bodies/obligations map.
  * Acceptance: “what we must do” vs “what we can shape” clearly separated.
* **JU-2: Comment/Engagement Playbook v1**

  * Deliverable: draft positions + coalition posture + timeline.
  * Acceptance: 3 positions, each with (a) benefit framing, (b) risk, (c) fallback language.
* **JU-3: Claim-Safe Language Guide v1**

  * Deliverable: approved phrases + prohibited claims + review workflow.
  * Acceptance: integrated into Narrative kit and Sales/Comms workflow.

**Dependencies:** Foresight scenarios + GTM intents.
**Decision Gate:** approve **what we can say/do** next sprint without re-review.

---

# Workstream 4 — [JINX] Adversary Emulation & Control Coverage

**Outcome:** threat-driven plan with mapped controls + telemetry that proves risk reduction.

**Sprint Backlog**

* **JX-1: Campaign Tree v1 (synthetic)**

  * Deliverable: top 3 adversary campaigns and ATT&CK-style chains (defensive mapping only).
  * Acceptance: each step mapped to **existing controls** or a gap with owner.
* **JX-2: Coverage Map + Telemetry Requirements v1**

  * Deliverable: control coverage matrix + logging/alerting priorities.
  * Acceptance: top 10 telemetry events + “minimum viable detection” checklist.
* **JX-3: Tabletop Exercise v1**

  * Deliverable: 90-minute tabletop with roles, injects, success criteria.
  * Acceptance: produces 10 action items with severity + due dates.

**Dependencies:** Measurement (scorecard integration).
**Decision Gate:** approve **top 5 control investments** for next sprint.

---

# Workstream 5 — [JIGSAW] Narrative Defense & Comms Readiness

**Outcome:** pre-bunk + response kit so execution doesn’t get derailed by info ops or confusion.

**Sprint Backlog**

* **JG-1: Claim–Evidence–Warrant Table v1**

  * Deliverable: 10 key claims with evidence and allowed phrasing.
  * Acceptance: aligns with JU-3 (claim-safe guide).
* **JG-2: Crisis Comms “First 2 Hours” Kit v1**

  * Deliverable: holding statements, escalation tree, media hygiene checklist.
  * Acceptance: can be executed by an on-call person without guessing.
* **JG-3: Channel Hygiene & Amplification SOP v1**

  * Deliverable: do/don’t rules, monitoring plan, and response tiers.
  * Acceptance: integrates tripwires (what triggers comms action).

**Dependencies:** Policy (allowed claims) + JINX (likely attack narratives).
**Decision Gate:** approve **final message house** for next sprint launches.

---

# Workstream 6 — [JANUS] Measurement, Ops Cadence, and Proof-Carrying Strategy

**Outcome:** an audit-ready spine: metrics, tripwires, decision logs, and rollback paths.

**Sprint Backlog**

* **JN-1: Scorecard v1 (KPIs/KRIs + owners)**

  * Deliverable: 1 dashboard + 1 page describing metric definitions.
  * Acceptance: every metric has source-of-truth + update cadence.
* **JN-2: Tripwire & Rollback Playbook v1**

  * Deliverable: thresholds that trigger pause/rollback for each top option.
  * Acceptance: includes “stop-loss,” comms trigger, and re-approval workflow.
* **JN-3: Provenance Manifest Template v1**

  * Deliverable: simple log format for decisions, assumptions, evidence.
  * Acceptance: used in sprint review; stored in a single system.

**Dependencies:** everything else feeds the scorecard.
**Decision Gate:** go/no-go readiness check for Week 3 execution.

---

## Sprint Cadence (practical schedule)

**Day 1–2:** lock objective/metrics, stand up scorecard skeleton, draft initiative map, start surface scan
**Day 3–5:** option portfolio draft + threat campaign tree + claim-safe guide v1
**Day 6:** mid-sprint decision checkpoint (kill/merge low-value tasks)
**Day 7–9:** tabletop exercise + partner targets + crisis kit + coverage/telemetry mapping
**Day 10:** integrate: one “Strategy-to-Execution Kit v1” package + final decision gates

---

## C) COAs (Good / Better / Best)

### GOOD — “Artifact-First v1”

* **Do:** produce all v1 artifacts with minimal validation.
* **Impact:** fast alignment; medium confidence.
* **Effort:** low–medium.
* **Risk:** paper strategy; weak grounding.
* **Gate:** tabletop + 1 partner call required to “graduate” to v2.

### BETTER — “Artifact + 2 Experiments”

* **Do:** everything in GOOD + run **two falsifying experiments** (one GTM wedge test, one control/telemetry test).
* **Impact:** high; reduces wrong bets early.
* **Effort:** medium.
* **Risk:** scope creep.
* **Gate:** experiments must finish by Day 9.

### BEST — “War-Game + Coalition Pre-Commit”

* **Do:** BETTER + run **mini wargame** (2 COAs) + secure **one coalition/partner pre-commit** in writing.
* **Impact:** very high; initiative shaping begins immediately.
* **Effort:** high.
* **Risk:** coordination overhead.
* **Gate:** only choose if you have a strong operator lead and tight calendars.

---

## D) Scorecard & Tripwires (v1 template you can use immediately)

**KPIs**

* Option portfolio velocity: options evaluated/week (target: **6–10**)
* Decision latency: median time to decision (target: **<48h**)
* Execution readiness: % options with rollback criteria (target: **100%**)

**KRIs**

* Unmonitored critical events (target: **0**)
* Policy violations / claim breaches (target: **0**)
* Reputation shock indicators (monitor: spikes in negative mentions, press inquiries)

**Tripwires (examples)**

* Any KRI breach → **pause launch**, escalate to JU + JG, rollback within 24h
* Detection coverage <50% for a top campaign → **do not expand exposure**
* Partner asks for unsupported claims → **freeze outbound**, issue claim-safe alternatives

---

## E) Evidence & Proof-Carrying Strategy (PCS)

**Assumptions (explicit)**

* You want a sprint plan that is **mission-agnostic but immediately executable**.
* You can staff at least **one owner per workstream** (some can be dual-hatted).
* You value **reversibility** and **auditability** as first-class constraints.

**Confidence:** Medium (because mission context, org size, and domain constraints weren’t provided).
**Falsification paths (what would invalidate this plan quickly):**

* If your actual bottleneck is **engineering throughput**, we should compress to 3 workstreams and ship code.
* If your environment is **highly regulated**, Policy must lead and cadence changes.
* If you’re in an active incident, JINX + JIGSAW become primary immediately.

**Residual unknowns (not blocking v1):**

* Mission domain (product, security, geopolitical, enterprise GTM, etc.)
* Team size/capacity and tooling
* Jurisdictions and compliance obligations
