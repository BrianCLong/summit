# Performance Runbook

## Purpose
How to execute, observe, and tune the performance test suite for golden journeys.

## Running Tests
- **Smoke/Baseline:** `k6 run k6/golden-baseline.js --summary-export perf/results/k6-baseline-summary.json`.
- **Stress (nightly):** `k6 run k6/golden-stress.js --summary-export perf/results/k6-stress-summary.json`.
- **Spike:** `k6 run k6/golden-spike.js --summary-export perf/results/k6-spike-summary.json`.
- **Soak (stage release gate):** `K6_SOAK_DURATION_MINUTES=180 k6 run k6/golden-soak.js`.
- Use `K6_DURATION_FACTOR=0.25` for local dry-runs.

## Data & Safety
- All tests use `tenant=test-perf` and send `x-perf: true` headers.
- Seed fixtures for `test-perf` only; never point to production datasets.

## Interpreting Results
- Threshold breaches fail CI. Inspect `perf/results/*summary.json` and the PR comment generated by `.ci/scripts/perf/pr_comment_summary.py`.
- Headroom <20% at target RPS blocks merges. Use `tools/perf-predict/main.py headroom --journey GP-001 --metrics <file>` to quantify.

## Autoscaling Tuning
- Web HPA: adjust `web.hpa.cpuTarget` and `web.hpa.queueDepthTarget` Helm values. Behavior tuned via stabilization windows in `deploy/helm/intelgraph/templates/hpa/web-hpa.yaml`.
- Event consumers: adjust Kafka lag thresholds in `deploy/helm/intelgraph/templates/hpa/consumer-keda.yaml`.
- Prefer scale-up policies that double replicas quickly but slow scale-down; ensure readiness gates and preStop hooks are enabled in deployments.

## Profiling
- Enable stage-only profiling using `PY_SPY_ENABLE=1` or `NODE_OPTIONS=--cpu-prof`. Capture flamegraphs during baseline runs and upload alongside k6 artifacts.

## Dashboards & Alerts
- Grafana dashboards: `perf-overview` for RPS/latency/headroom/burn; `hpa-behavior` for scaling signals.
- Alerts to configure: threshold breaches, HPA flapping (rapid replica oscillation), zero headroom (<0.2), and failed k6 runs.

## Incident Response
1. Pause scale-down if replicas are thrashing.
2. Check queue depth and Kafka lag; scale consumers manually if needed.
3. Capture profiles and trace samples; create issues for top offenders.
4. Use `tools/perf-predict/main.py capacity --service <svc> --target-rps <rps>` for quick sizing until automated controllers converge.
