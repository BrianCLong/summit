apiVersion: batch/v1
kind: CronJob
metadata:
  name: redis-backup
  namespace: database
  labels:
    app.kubernetes.io/name: redis-backup
    app.kubernetes.io/component: backup
    app.kubernetes.io/part-of: intelgraph
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  timeZone: "UTC"
  successfulJobsHistoryLimit: 7
  failedJobsHistoryLimit: 3
  concurrencyPolicy: Forbid
  startingDeadlineSeconds: 300
  jobTemplate:
    spec:
      activeDeadlineSeconds: 1800  # 30 minute timeout
      backoffLimit: 2
      template:
        metadata:
          labels:
            app.kubernetes.io/name: redis-backup
            app.kubernetes.io/component: backup
        spec:
          restartPolicy: Never
          securityContext:
            runAsNonRoot: true
            runAsUser: 65532
            runAsGroup: 65532
            fsGroup: 65532
          serviceAccountName: redis-backup
          containers:
          - name: redis-backup
            image: redis:6.2-alpine
            imagePullPolicy: IfNotPresent
            command:
            - /bin/sh
            - -c
            - |
              set -euo pipefail
              
              # Configuration
              BACKUP_NAME="redis-backup-$(date +%Y%m%d-%H%M%S)"
              BACKUP_DIR="/backups/${BACKUP_NAME}"
              RETENTION_DAYS=7  # Shorter retention for Redis due to cache nature
              
              echo "Starting Redis backup: ${BACKUP_NAME}"
              
              # Create backup directory
              mkdir -p "${BACKUP_DIR}"
              
              # Test Redis connection
              echo "Testing Redis connection..."
              redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} ping
              
              # Get Redis info for backup metadata
              REDIS_VERSION=$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} info server | grep redis_version | cut -d: -f2 | tr -d '\r')
              DB_COUNT=$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} info keyspace | grep -c "^db" || echo "0")
              MEMORY_USAGE=$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} info memory | grep used_memory_human | cut -d: -f2 | tr -d '\r')
              
              # Create RDB snapshot via BGSAVE
              echo "Creating RDB snapshot..."
              redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} BGSAVE
              
              # Wait for background save to complete
              echo "Waiting for BGSAVE to complete..."
              while [ "$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} LASTSAVE)" = "$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} LASTSAVE)" ]; do
                if redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} info persistence | grep -q "rdb_bgsave_in_progress:0"; then
                  break
                fi
                sleep 5
              done
              
              # Get key statistics for all databases
              echo "Collecting key statistics..."
              for db in $(seq 0 15); do
                KEY_COUNT=$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n ${db} DBSIZE 2>/dev/null || echo "0")
                if [ "${KEY_COUNT}" -gt "0" ]; then
                  echo "Database ${db}: ${KEY_COUNT} keys" >> "${BACKUP_DIR}/key_stats.txt"
                  
                  # Sample key types and TTLs
                  redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n ${db} --scan --count 100 | head -20 | while read key; do
                    KEY_TYPE=$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n ${db} TYPE "$key" 2>/dev/null || echo "unknown")
                    KEY_TTL=$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n ${db} TTL "$key" 2>/dev/null || echo "-1")
                    echo "DB${db} ${key}: type=${KEY_TYPE}, ttl=${KEY_TTL}" >> "${BACKUP_DIR}/sample_keys.txt"
                  done
                fi
              done
              
              # Export configuration
              echo "Backing up Redis configuration..."
              redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} CONFIG GET "*" > "${BACKUP_DIR}/redis.conf"
              
              # Create logical backup of critical keys (non-cache data)
              echo "Creating logical backup of critical keys..."
              
              # Export session data (if using Redis for sessions)
              redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n 0 --scan --pattern "session:*" | \
                xargs -I {} redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n 0 DUMP {} | \
                gzip > "${BACKUP_DIR}/sessions_dump.gz" 2>/dev/null || echo "No sessions found"
              
              # Export user authentication tokens
              redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n 1 --scan --pattern "auth:*" | \
                xargs -I {} redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n 1 DUMP {} | \
                gzip > "${BACKUP_DIR}/auth_tokens_dump.gz" 2>/dev/null || echo "No auth tokens found"
              
              # Export application state (non-transient data)
              redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n 2 --scan --pattern "state:*" | \
                xargs -I {} redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} -n 2 DUMP {} | \
                gzip > "${BACKUP_DIR}/app_state_dump.gz" 2>/dev/null || echo "No app state found"
              
              # Create backup manifest
              cat > "${BACKUP_DIR}/backup-manifest.json" << EOF
              {
                "backup_name": "${BACKUP_NAME}",
                "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
                "redis_version": "${REDIS_VERSION}",
                "backup_type": "rdb_snapshot + logical",
                "database_count": ${DB_COUNT},
                "memory_usage": "${MEMORY_USAGE}",
                "backup_size_bytes": $(du -sb "${BACKUP_DIR}" | cut -f1),
                "retention_policy": "${RETENTION_DAYS} days",
                "includes_config": true,
                "backup_method": "BGSAVE + selective dump"
              }
              EOF
              
              # Create a simple RDB file copy (if accessible)
              # Note: In production, this would require access to Redis data directory
              # For now, we'll create a timestamp file as placeholder
              echo "RDB snapshot completed at $(date -u +%Y-%m-%dT%H:%M:%SZ)" > "${BACKUP_DIR}/rdb_snapshot.info"
              
              # Compress backup for storage efficiency
              echo "Compressing backup..."
              tar -czf "${BACKUP_DIR}.tar.gz" -C "/backups" "${BACKUP_NAME}"
              rm -rf "${BACKUP_DIR}"
              
              # Upload to S3 with encryption
              echo "Uploading to S3..."
              aws s3 cp "${BACKUP_DIR}.tar.gz" \
                "s3://${BACKUP_BUCKET}/redis/$(date +%Y/%m/%d)/${BACKUP_NAME}.tar.gz" \
                --server-side-encryption AES256 \
                --storage-class STANDARD_IA \
                --metadata backup-type=redis,memory-usage=${MEMORY_USAGE},timestamp=$(date +%s)
              
              # Cross-region replication
              echo "Replicating to DR region..."
              aws s3 cp "s3://${BACKUP_BUCKET}/redis/$(date +%Y/%m/%d)/${BACKUP_NAME}.tar.gz" \
                "s3://${DR_BACKUP_BUCKET}/redis/$(date +%Y/%m/%d)/${BACKUP_NAME}.tar.gz" \
                --source-region ${AWS_REGION} \
                --region ${DR_AWS_REGION}
              
              # Cleanup local backup
              rm -f "${BACKUP_DIR}.tar.gz"
              
              # Store current Redis state for comparison
              CURRENT_STATE=$(redis-cli -h ${REDIS_HOST} -p ${REDIS_PORT} info stats | grep -E "(total_commands_processed|total_connections_received|keyspace_hits|keyspace_misses)")
              aws s3 cp - "s3://${BACKUP_BUCKET}/redis/state/$(date +%Y/%m/%d)/${BACKUP_NAME}-state.txt" << EOF
              ${CURRENT_STATE}
              backup_timestamp=$(date -u +%Y-%m-%dT%H:%M:%SZ)
              EOF
              
              # Cleanup old backups (shorter retention for Redis)
              echo "Cleaning up old backups..."
              aws s3 ls "s3://${BACKUP_BUCKET}/redis/" --recursive | \
                awk '{if($1 < "'$(date -d "${RETENTION_DAYS} days ago" +%Y-%m-%d)'") print $4}' | \
                xargs -r -I {} aws s3 rm "s3://${BACKUP_BUCKET}/{}"
              
              # Send success notification
              curl -X POST "${SLACK_WEBHOOK_URL}" \
                -H 'Content-Type: application/json' \
                -d "{\"text\":\"âœ… Redis backup completed successfully: ${BACKUP_NAME}\\nMemory Usage: ${MEMORY_USAGE}\\nDatabases: ${DB_COUNT}\"}" || true
              
              echo "Redis backup completed successfully: ${BACKUP_NAME}"
              
            env:
            - name: REDIS_HOST
              value: "redis.database"
            - name: REDIS_PORT
              value: "6379"
            - name: BACKUP_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: backup-config
                  key: backup-bucket
            - name: DR_BACKUP_BUCKET
              valueFrom:
                configMapKeyRef:
                  name: backup-config
                  key: dr-backup-bucket
            - name: AWS_REGION
              valueFrom:
                configMapKeyRef:
                  name: backup-config
                  key: aws-region
            - name: DR_AWS_REGION
              valueFrom:
                configMapKeyRef:
                  name: backup-config
                  key: dr-aws-region
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: backup-secrets
                  key: slack-webhook-url
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: backup-secrets
                  key: aws-access-key-id
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: backup-secrets
                  key: aws-secret-access-key
            resources:
              requests:
                memory: "256Mi"
                cpu: "100m"
              limits:
                memory: "1Gi"
                cpu: "500m"
            volumeMounts:
            - name: backup-storage
              mountPath: /backups
            - name: tmp-volume
              mountPath: /tmp
          volumes:
          - name: backup-storage
            emptyDir:
              sizeLimit: 5Gi
          - name: tmp-volume
            emptyDir:
              sizeLimit: 1Gi
          tolerations:
          - key: "backup-workload"
            operator: "Equal"
            value: "true"
            effect: "NoSchedule"
          nodeSelector:
            node-type: "backup-optimized"
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: redis-backup
  namespace: database
  labels:
    app.kubernetes.io/name: redis-backup
    app.kubernetes.io/component: backup
  annotations:
    eks.amazonaws.com/role-arn: "arn:aws:iam::123456789012:role/redis-backup-role"
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: database
  name: redis-backup
rules:
- apiGroups: [""]
  resources: ["pods", "services"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["secrets", "configmaps"]
  verbs: ["get"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: redis-backup
  namespace: database
subjects:
- kind: ServiceAccount
  name: redis-backup
  namespace: database
roleRef:
  kind: Role
  name: redis-backup
  apiGroup: rbac.authorization.k8s.io