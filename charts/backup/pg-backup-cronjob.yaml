# Maestro Conductor v24.3.0 - PostgreSQL Backup CronJob
# Epic E14: DR & Failover - PITR setup with scheduled snapshots

apiVersion: batch/v1
kind: CronJob
metadata:
  name: maestro-pg-backup
  labels:
    app: maestro-conductor
    component: pg-backup
    version: v24.3.0
spec:
  schedule: '*/5 * * * *' # Every 5 minutes for RPO â‰¤ 5m
  concurrencyPolicy: Forbid
  failedJobsHistoryLimit: 3
  successfulJobsHistoryLimit: 10
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: maestro-conductor
            component: pg-backup-job
        spec:
          restartPolicy: Never
          containers:
            - name: pg-backup
              image: postgres:15
              env:
                - name: PGHOST
                  value: 'maestro-pg-primary'
                - name: PGPORT
                  value: '5432'
                - name: PGDATABASE
                  value: 'maestro'
                - name: PGUSER
                  valueFrom:
                    secretKeyRef:
                      name: maestro-pg-secret
                      key: username
                - name: PGPASSWORD
                  valueFrom:
                    secretKeyRef:
                      name: maestro-pg-secret
                      key: password
                - name: AWS_ACCESS_KEY_ID
                  valueFrom:
                    secretKeyRef:
                      name: maestro-backup-secret
                      key: aws_access_key_id
                - name: AWS_SECRET_ACCESS_KEY
                  valueFrom:
                    secretKeyRef:
                      name: maestro-backup-secret
                      key: aws_secret_access_key
                - name: AWS_DEFAULT_REGION
                  value: 'us-east-1'
                - name: S3_BUCKET
                  value: 'maestro-backups-primary'
                - name: BACKUP_RETENTION_DAYS
                  value: '30'
              command:
                - /bin/bash
                - -c
                - |
                  set -euo pipefail

                  # Install AWS CLI
                  apt-get update && apt-get install -y awscli gzip

                  # Generate timestamp
                  TIMESTAMP=$(date +%Y%m%d_%H%M%S)
                  REGION=${CURRENT_REGION:-us-east-1}
                  BACKUP_FILE="pg_backup_${REGION}_${TIMESTAMP}.sql.gz"
                  WAL_FILE="pg_wal_${REGION}_${TIMESTAMP}.tar.gz"

                  echo "Starting PostgreSQL backup at $(date)"
                  echo "Backup file: ${BACKUP_FILE}"

                  # Create database dump with PITR consistency
                  pg_dump --verbose --format=custom --compress=9 \
                    --no-password --clean --if-exists \
                    --exclude-table-data='logs' \
                    --exclude-table-data='audit_trail' \
                    maestro | gzip > "/tmp/${BACKUP_FILE}"

                  # Backup WAL files for PITR
                  pg_receivewal -D /tmp/wal_backup --synchronous -v
                  tar -czf "/tmp/${WAL_FILE}" -C /tmp wal_backup/

                  # Upload to S3 with region-specific path
                  aws s3 cp "/tmp/${BACKUP_FILE}" "s3://${S3_BUCKET}/postgresql/${REGION}/dumps/${BACKUP_FILE}"
                  aws s3 cp "/tmp/${WAL_FILE}" "s3://${S3_BUCKET}/postgresql/${REGION}/wal/${WAL_FILE}"

                  # Create manifest for restore procedures
                  cat > "/tmp/backup_manifest_${TIMESTAMP}.json" << EOF
                  {
                    "timestamp": "${TIMESTAMP}",
                    "region": "${REGION}",
                    "type": "postgresql",
                    "files": {
                      "dump": "${BACKUP_FILE}",
                      "wal": "${WAL_FILE}"
                    },
                    "metadata": {
                      "pg_version": "$(psql -t -c 'SELECT version()')",
                      "database_size": "$(psql -t -c \"SELECT pg_size_pretty(pg_database_size('maestro'))\")",
                      "backup_method": "pg_dump+pg_receivewal",
                      "retention_days": ${BACKUP_RETENTION_DAYS}
                    },
                    "checksums": {
                      "dump_sha256": "$(sha256sum /tmp/${BACKUP_FILE} | cut -d' ' -f1)",
                      "wal_sha256": "$(sha256sum /tmp/${WAL_FILE} | cut -d' ' -f1)"
                    }
                  }
                  EOF

                  aws s3 cp "/tmp/backup_manifest_${TIMESTAMP}.json" \
                    "s3://${S3_BUCKET}/postgresql/${REGION}/manifests/backup_manifest_${TIMESTAMP}.json"

                  # Update latest backup pointer
                  echo "${TIMESTAMP}" | aws s3 cp - "s3://${S3_BUCKET}/postgresql/${REGION}/LATEST"

                  # Cleanup old backups based on retention
                  aws s3 ls "s3://${S3_BUCKET}/postgresql/${REGION}/dumps/" | \
                    awk '{print $4}' | sort | head -n -${BACKUP_RETENTION_DAYS} | \
                    while read backup; do
                      if [ -n "$backup" ]; then
                        echo "Deleting old backup: $backup"
                        aws s3 rm "s3://${S3_BUCKET}/postgresql/${REGION}/dumps/${backup}"
                      fi
                    done

                  # Cleanup old WAL files
                  aws s3 ls "s3://${S3_BUCKET}/postgresql/${REGION}/wal/" | \
                    awk '{print $4}' | sort | head -n -${BACKUP_RETENTION_DAYS} | \
                    while read walfile; do
                      if [ -n "$walfile" ]; then
                        aws s3 rm "s3://${S3_BUCKET}/postgresql/${REGION}/wal/${walfile}"
                      fi
                    done

                  # Cleanup old manifests
                  aws s3 ls "s3://${S3_BUCKET}/postgresql/${REGION}/manifests/" | \
                    awk '{print $4}' | sort | head -n -${BACKUP_RETENTION_DAYS} | \
                    while read manifest; do
                      if [ -n "$manifest" ]; then
                        aws s3 rm "s3://${S3_BUCKET}/postgresql/${REGION}/manifests/${manifest}"
                      fi
                    done

                  echo "PostgreSQL backup completed successfully at $(date)"
                  echo "Files uploaded:"
                  echo "  - s3://${S3_BUCKET}/postgresql/${REGION}/dumps/${BACKUP_FILE}"
                  echo "  - s3://${S3_BUCKET}/postgresql/${REGION}/wal/${WAL_FILE}"
                  echo "  - s3://${S3_BUCKET}/postgresql/${REGION}/manifests/backup_manifest_${TIMESTAMP}.json"

              resources:
                requests:
                  memory: '512Mi'
                  cpu: '200m'
                limits:
                  memory: '2Gi'
                  cpu: '1000m'

              volumeMounts:
                - name: backup-temp
                  mountPath: /tmp

          volumes:
            - name: backup-temp
              emptyDir:
                sizeLimit: 10Gi
