apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: maestro-slo-rules
spec:
  groups:
    - name: slo-burn
      rules:
        # GraphQL Request metrics
        - record: job:graphql_requests:rate5m
          expr: sum by (job)(rate(http_requests_total{job="maestro-conductor-v24"}[5m]))
        - record: job:graphql_errors:rate5m
          expr: sum by (job)(rate(http_requests_total{job="maestro-conductor-v24",code=~"5..|4.."}[5m]))
        - record: job:graphql_error_ratio:5m
          expr: job:graphql_errors:rate5m / job:graphql_requests:rate5m

        # GraphQL Read latency SLO (p95 ≤ 350ms)
        - record: job:graphql_read_latency_p95:5m
          expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="maestro-conductor-v24",operation="read"}[5m]))
        - record: job:graphql_read_slo_breach:5m
          expr: job:graphql_read_latency_p95:5m > 0.35

        # GraphQL Write latency SLO (p95 ≤ 700ms)
        - record: job:graphql_write_latency_p95:5m
          expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket{job="maestro-conductor-v24",operation="write"}[5m]))
        - record: job:graphql_write_slo_breach:5m
          expr: job:graphql_write_latency_p95:5m > 0.7

        # Subscription fanout SLO (p95 ≤ 250ms)
        - record: job:subscription_fanout_p95:5m
          expr: histogram_quantile(0.95, rate(subscription_fanout_latency_ms_bucket[5m]))
        - record: job:subscription_slo_breach:5m
          expr: job:subscription_fanout_p95:5m > 250

        # Availability SLO (99.9%)
        - alert: GraphQLAvailabilitySLOBreach
          expr: job:graphql_error_ratio:5m > (1 - 0.999) * 14 # 14x budget burn
          for: 2m
          labels:
            {
              severity: critical,
              slo: graphql-availability,
              objective: '99.9%',
            }
          annotations:
            summary: 'GraphQL availability SLO breach (fast burn)'
            description: 'GraphQL error rate {{ $value | humanizePercentage }} exceeds SLO budget burn rate'
            runbook_url: https://runbooks.maestro.dev/slo-graphql-availability.md

        # Read Latency SLO
        - alert: GraphQLReadLatencySLOBreach
          expr: job:graphql_read_slo_breach:5m
          for: 5m
          labels:
            {
              severity: warning,
              slo: graphql-read-latency,
              objective: 'p95-350ms',
            }
          annotations:
            summary: 'GraphQL read latency SLO breach'
            description: 'GraphQL read p95 latency {{ $value | humanizeDuration }} exceeds 350ms SLO'
            runbook_url: https://runbooks.maestro.dev/slo-graphql-read-latency.md

        # Write Latency SLO
        - alert: GraphQLWriteLatencySLOBreach
          expr: job:graphql_write_slo_breach:5m
          for: 5m
          labels:
            {
              severity: warning,
              slo: graphql-write-latency,
              objective: 'p95-700ms',
            }
          annotations:
            summary: 'GraphQL write latency SLO breach'
            description: 'GraphQL write p95 latency {{ $value | humanizeDuration }} exceeds 700ms SLO'
            runbook_url: https://runbooks.maestro.dev/slo-graphql-write-latency.md

        # Subscription Fanout SLO
        - alert: SubscriptionFanoutSLOBreach
          expr: job:subscription_slo_breach:5m
          for: 5m
          labels:
            {
              severity: warning,
              slo: subscription-fanout,
              objective: 'p95-250ms',
            }
          annotations:
            summary: 'Subscription fanout latency SLO breach'
            description: 'Subscription fanout p95 latency {{ $value }}ms exceeds 250ms SLO'
            runbook_url: https://runbooks.maestro.dev/slo-subscription-fanout.md

        - alert: BlackboxProbeFailing
          expr: probe_success == 0
          for: 1m
          labels: { severity: critical }
          annotations:
            summary: 'Blackbox probe failed for {{ $labels.instance }}'
            description: 'Probe to {{ $labels.__param_target }} is failing. Check target availability and Blackbox Exporter logs.'
            runbook_url: https://…/runbooks/probe-failing.md

        - alert: BlackboxProbeTTFBHigh
          expr: histogram_quantile(0.95, probe_duration_seconds_bucket{phase="resolve"}) > 0.5 # Adjust threshold as needed
          for: 5m
          labels: { severity: warning }
          annotations:
            summary: 'High TTFB for blackbox probe {{ $labels.instance }}'
            description: 'Time to first byte for {{ $labels.__param_target }} is high ({{ $value | humanizeDuration }}).'
            runbook_url: https://…/runbooks/probe-ttfb-high.md

    - name: tenant-cost-guards
      rules:
        - record: tenant:monthly_cost:sum
          expr: sum by (tenant)(maestro_cost_usd_total_monthly)

        - alert: TenantCostGuardBreaching80Percent
          expr: tenant:monthly_cost:sum / on(tenant) group_left() maestro_budget_limit{type="hard"} > 0.8
          for: 10m
          labels: { severity: warning, threshold: '80%' }
          annotations:
            summary: 'Tenant {{ $labels.tenant }} monthly cost is at 80% of budget'
            description: 'Tenant {{ $labels.tenant }} has spent {{ $value | humanizePercentage }} of their monthly budget of {{ $labels.budget_limit }}.'
            runbook_url: https://…/runbooks/tenant-cost-guard.md
            grafana_dashboard_url: '{{grafanaBase}}/d/maestro-cost?var-tenant={{ $labels.tenant }}'
            maestro_link: '{{maestroBase}}/maestro/tenants/costs?tenant={{ $labels.tenant }}'

        - alert: TenantCostGuardBreaching90Percent
          expr: tenant:monthly_cost:sum / on(tenant) group_left() maestro_budget_limit{type="hard"} > 0.9
          for: 5m
          labels: { severity: critical, threshold: '90%' }
          annotations:
            summary: 'Tenant {{ $labels.tenant }} monthly cost is at 90% of budget'
            description: 'Tenant {{ $labels.tenant }} has spent {{ $value | humanizePercentage }} of their monthly budget of {{ $labels.budget_limit }}. Immediate action may be required.'
            runbook_url: https://…/runbooks/tenant-cost-guard.md
            grafana_dashboard_url: '{{grafanaBase}}/d/maestro-cost?var-tenant={{ $labels.tenant }}'
            maestro_link: '{{maestroBase}}/maestro/tenants/costs?tenant={{ $labels.tenant }}'

        - alert: TenantCostGuardBreaching100Percent
          expr: tenant:monthly_cost:sum / on(tenant) group_left() maestro_budget_limit{type="hard"} > 1
          for: 1m
          labels: { severity: critical, threshold: '100%' }
          annotations:
            summary: 'Tenant {{ $labels.tenant }} monthly cost exceeded budget'
            description: 'Tenant {{ $labels.tenant }} has exceeded their monthly budget of {{ $labels.budget_limit }}. Workloads may be halted.'
            runbook_url: https://…/runbooks/tenant-cost-guard.md
            grafana_dashboard_url: '{{grafanaBase}}/d/maestro-cost?var-tenant={{ $labels.tenant }}'
            maestro_link: '{{maestroBase}}/maestro/tenants/costs?tenant={{ $labels.tenant }}'
