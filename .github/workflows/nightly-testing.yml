name: Nightly Testing

on:
  schedule:
    # Run nightly at 2:19 AM UTC (jittered from :00, avoids :07 health check)
    - cron: '19 2 * * *'
  workflow_dispatch:
    inputs:
      environment:
        description: 'Target environment'
        required: true
        default: 'stage'
        type: choice
        options:
          - stage
          - dev
      skip_soak:
        description: 'Skip k6 soak test (4h duration)'
        required: false
        default: false
        type: boolean

concurrency:
  group: nightly-testing-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read
  checks: write
  actions: read

env:
  STAGE_URL: https://stage.intelgraph.example
  DEV_URL: https://dev.intelgraph.example
  ACTIONS_QUEUE_THRESHOLD: ${{ vars.ACTIONS_QUEUE_THRESHOLD || '15' }}
  START_JITTER_MAX_SEC: ${{ vars.START_JITTER_MAX_SEC || '240' }}

jobs:
  guard:
    if: github.event_name == 'schedule'
    runs-on: ubuntu-latest
    outputs:
      saturated: ${{ steps.guard.outputs.saturated }}
    steps:
      - uses: actions/checkout@v4
      - id: guard
        uses: ./.github/actions/backlog-guard

      - name: Summarize guard decision
        if: steps.guard.outputs.saturated == 'true'
        run: |
          echo "⚠️ **Backlog Guard Active**" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "**Queue Status:** ${{ steps.guard.outputs.queued }} queued runs (threshold: ${{ steps.guard.outputs.threshold }})" >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "Skipping nightly tests to preserve runner capacity." >> "$GITHUB_STEP_SUMMARY"
          echo "" >> "$GITHUB_STEP_SUMMARY"
          echo "**Manual Override:** \`gh workflow run nightly-testing.yml\` (bypasses guard)" >> "$GITHUB_STEP_SUMMARY"

  nightly-e2e:
    if: github.event_name != 'schedule' || needs.guard.outputs.saturated != 'true'
    needs: [guard]
    runs-on: ubuntu-22.04
    timeout-minutes: 90
    strategy:
      fail-fast: false
      max-parallel: 4  # Cap matrix fanout (was 12 parallel jobs)
      matrix:
        browser: [chromium, firefox, safari]
        shard: [1, 2, 3, 4]
    env:
      TARGET_ENV: ${{ inputs.environment || 'stage' }}
    steps:
      - name: Start jitter
        if: github.event_name == 'schedule'
        run: sleep $((RANDOM%${START_JITTER_MAX_SEC:-240}+30))

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Install pnpm
        uses: pnpm/action-setup@v3
        with:
          version: 9

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Install Playwright browsers
        run: pnpm dlx playwright install --with-deps ${{ matrix.browser }}

      - name: Set target URL
        run: |
          if [ "$TARGET_ENV" = "stage" ]; then
            echo "BASE_URL=$STAGE_URL" >> $GITHUB_ENV
          else
            echo "BASE_URL=$DEV_URL" >> $GITHUB_ENV
          fi

      - name: Run comprehensive E2E tests
        run: |
          cd tests/e2e
          pnpm test \
            --project=${{ matrix.browser }}-desktop \
            --shard=${{ matrix.shard }}/4 \
            --reporter=html,junit \
            --output-dir=playwright-results-${{ matrix.browser }}-shard${{ matrix.shard }}
        env:
          BASE_URL: ${{ env.BASE_URL }}
          PLAYWRIGHT_HTML_REPORT: playwright-results-${{ matrix.browser }}-shard${{ matrix.shard }}/html-report

      - name: Upload E2E test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-results-${{ matrix.browser }}-shard${{ matrix.shard }}
          path: |
            tests/e2e/playwright-results-${{ matrix.browser }}-shard${{ matrix.shard }}/
            tests/e2e/test-results/
          retention-days: 30

      - name: Upload E2E test videos
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: e2e-videos-${{ matrix.browser }}-shard${{ matrix.shard }}
          path: tests/e2e/test-results/**/video.webm
          retention-days: 7

      - name: Publish E2E test results
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: E2E Tests (${{ matrix.browser }} - shard ${{ matrix.shard }})
          path: tests/e2e/playwright-results-${{ matrix.browser }}-shard${{ matrix.shard }}/junit.xml
          reporter: java-junit

  nightly-integration:
    if: github.event_name != 'schedule' || needs.guard.outputs.saturated != 'true'
    needs: [guard]
    runs-on: ubuntu-22.04
    timeout-minutes: 45
    env:
      TARGET_ENV: ${{ inputs.environment || 'stage' }}
    steps:
      - name: Start jitter
        if: github.event_name == 'schedule'
        run: sleep $((RANDOM%${START_JITTER_MAX_SEC:-240}+30))

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Install pnpm
        uses: pnpm/action-setup@v3
        with:
          version: 9

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run comprehensive integration tests
        run: |
          echo "🧪 Running full integration test suite..."
          npm run itest

      - name: Generate integration test report
        if: always()
        run: |
          echo "📊 Generating integration test report..."
          node scripts/coverage-aggregate.js

      - name: Upload integration test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-test-results
          path: |
            coverage/**
            test-results/**
            *.xml
          retention-days: 30

      - name: Publish integration test results
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: Integration Tests
          path: '**/*junit*.xml'
          reporter: java-junit

  nightly-performance:
    if: ${{ !inputs.skip_soak && (github.event_name != 'schedule' || needs.guard.outputs.saturated != 'true') }}
    needs: [guard]
    runs-on: ubuntu-22.04
    timeout-minutes: 300  # 5 hours for soak test
    env:
      TARGET_ENV: ${{ inputs.environment || 'stage' }}
    steps:
      - name: Start jitter
        if: github.event_name == 'schedule'
        run: sleep $((RANDOM%${START_JITTER_MAX_SEC:-240}+30))

      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install k6
        run: |
          sudo gpg -k
          sudo gpg --no-default-keyring --keyring /usr/share/keyrings/k6-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys C5AD17C747E3415A3642D57D77C6C491D6AC1D69
          echo "deb [signed-by=/usr/share/keyrings/k6-archive-keyring.gpg] https://dl.k6.io/deb stable main" | sudo tee /etc/apt/sources.list.d/k6.list
          sudo apt-get update
          sudo apt-get install k6

      - name: Set target URL
        run: |
          if [ "$TARGET_ENV" = "stage" ]; then
            echo "BASE_URL=$STAGE_URL" >> $GITHUB_ENV
          else
            echo "BASE_URL=$DEV_URL" >> $GITHUB_ENV
          fi

      - name: Run k6 soak test
        run: |
          echo "🔥 Starting 4-hour k6 soak test against $BASE_URL..."
          cd tests/load
          k6 run \
            --duration 14400s \
            --out json=soak-test-results.json \
            --out junit=soak-test-junit.xml \
            soak-test.js
        env:
          BASE_URL: ${{ env.BASE_URL }}
          STAGE: ${{ env.TARGET_ENV }}

      - name: Generate performance regression report
        if: always()
        run: |
          cd tests/load
          node scripts/performance-analysis.js soak-test-results.json > performance-report.md

      - name: Upload performance test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-test-results
          path: |
            tests/load/soak-test-results.json
            tests/load/soak-test-junit.xml
            tests/load/performance-report.md
          retention-days: 90

      - name: Publish performance test results
        if: always()
        uses: dorny/test-reporter@v1
        with:
          name: Performance Soak Tests
          path: tests/load/soak-test-junit.xml
          reporter: java-junit

      - name: Performance regression check
        if: always()
        run: |
          cd tests/load
          if [ -f performance-report.md ]; then
            if grep -q "❌" performance-report.md; then
              echo "❌ Performance regression detected!"
              cat performance-report.md
              exit 1
            else
              echo "✅ Performance within acceptable thresholds"
            fi
          fi

  nightly-summary:
    needs: [nightly-e2e, nightly-integration, nightly-performance]
    if: always()
    runs-on: ubuntu-22.04
    steps:
      - name: Generate nightly test summary
        run: |
          echo "## 🌙 Nightly Test Summary - $(date -u +"%Y-%m-%d")" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Test Type | Status |" >> $GITHUB_STEP_SUMMARY
          echo "|-----------|--------|" >> $GITHUB_STEP_SUMMARY
          echo "| E2E Tests | ${{ needs.nightly-e2e.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.nightly-integration.result == 'success' && '✅ Passed' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Performance Tests | ${{ needs.nightly-performance.result == 'success' && '✅ Passed' || needs.nightly-performance.result == 'skipped' && '⏭️ Skipped' || '❌ Failed' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Environment" >> $GITHUB_STEP_SUMMARY
          echo "- **Target**: ${{ inputs.environment || 'stage' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Commit**: \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY

      - name: Create GitHub issue on failure
        if: ${{ failure() }}
        uses: actions/github-script@v7
        with:
          script: |
            const title = `🚨 Nightly Test Failures - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            # Nightly Test Failures

            One or more nightly tests failed. Please investigate:

            ## Failed Jobs
            - E2E Tests: ${{ needs.nightly-e2e.result }}
            - Integration Tests: ${{ needs.nightly-integration.result }}
            - Performance Tests: ${{ needs.nightly-performance.result }}

            ## Details
            - **Environment**: ${{ inputs.environment || 'stage' }}
            - **Workflow Run**: [View Details](${context.payload.repository.html_url}/actions/runs/${context.runId})
            - **Commit**: ${context.sha}

            ## Next Steps
            1. Review test artifacts and logs
            2. Identify root cause
            3. Create fix PR if needed
            4. Re-run nightly tests to verify fix

            ---
            *Auto-generated by nightly testing workflow*
            `;

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: body,
              labels: ['bug', 'nightly-tests', 'high-priority']
            });