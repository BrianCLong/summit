name: Deploy to Prod (Canary + Auto-rollback)

on:
  workflow_dispatch:
    inputs:
      image_tag:
        description: 'Image Tag to deploy (SHA)'
        required: true
      application:
        description: 'Target application (Maestro/IntelGraph/CompanyOS)'
        required: true
        type: choice
        options:
          - maestro
          - intelgraph
          - companyos

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

concurrency:
  group: deploy-prod-canary-${{ inputs.application }}
  cancel-in-progress: false

jobs:
  deploy-prod:
    runs-on: ubuntu-latest
    environment: prod

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Load canary configuration
        id: canary-config
        run: |
          set -euo pipefail
          CONFIG_PATH="summit_release_env_pack/canary/canary-traffic.json"
          APP="${{ inputs.application }}"

          if ! jq -e --arg app "$APP" '.[$app]' "$CONFIG_PATH" >/dev/null; then
            echo "âŒ Application '$APP' not found in $CONFIG_PATH"
            exit 1
          fi

          HOST=$(jq -r --arg app "$APP" '.[$app].host' "$CONFIG_PATH")
          NAMESPACE=$(jq -r --arg app "$APP" '.[$app].namespaces.production' "$CONFIG_PATH")
          RELEASE_NAME=$(jq -r --arg app "$APP" '.[$app].releaseName' "$CONFIG_PATH")
          CHART_PATH=$(jq -r --arg app "$APP" '.[$app].chartPath' "$CONFIG_PATH")
          FEATURE_FLAG=$(jq -r --arg app "$APP" '.[$app].featureFlag' "$CONFIG_PATH")
          TRAFFIC_STAGES=$(jq -r --arg app "$APP" '.[$app].canaryStages | join(",")' "$CONFIG_PATH")

          echo "host=$HOST" >> "$GITHUB_OUTPUT"
          echo "namespace=$NAMESPACE" >> "$GITHUB_OUTPUT"
          echo "release_name=$RELEASE_NAME" >> "$GITHUB_OUTPUT"
          echo "chart_path=$CHART_PATH" >> "$GITHUB_OUTPUT"
          echo "feature_flag=$FEATURE_FLAG" >> "$GITHUB_OUTPUT"
          echo "traffic_stages=$TRAFFIC_STAGES" >> "$GITHUB_OUTPUT"

      - name: Set up Helm
        uses: azure/setup-helm@v4
        with:
          version: 'v3.11.1'

      - name: Create Kubeconfig
        run: |
          set -euo pipefail
          mkdir -p ~/.kube
          echo "${{ secrets.KUBECONFIG_PROD_B64 }}" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config

      - name: Deploy to Prod
        env:
          NAMESPACE: ${{ steps.canary-config.outputs.namespace }}
          HOST: ${{ steps.canary-config.outputs.host }}
          RELEASE_NAME: ${{ steps.canary-config.outputs.release_name }}
          CHART_PATH: ${{ steps.canary-config.outputs.chart_path }}
          FEATURE_FLAG: ${{ steps.canary-config.outputs.feature_flag }}
          TRAFFIC_STAGES: ${{ steps.canary-config.outputs.traffic_stages }}
        run: |
          set -euo pipefail
          # The chart has Argo Rollouts enabled, so 'helm upgrade' applies the Rollout object.
          # Canary steps are sourced from summit_release_env_pack/canary/canary-traffic.json.
          helm upgrade --install "$RELEASE_NAME" "$CHART_PATH" \
            --namespace $NAMESPACE \
            --set image.repository=${{ env.REGISTRY }}/${{ env.IMAGE_NAME }} \
            --set image.tag=${{ inputs.image_tag }} \
            --set ingress.hosts[0].host=$HOST \
            --set ingress.tls[0].hosts[0]=$HOST \
            --set-string canary.featureFlag=$FEATURE_FLAG \
            --set "canary.trafficStages={${TRAFFIC_STAGES}}" \
            --atomic \
            --timeout 10m \
            --wait

      - name: Verify rollout health
        env:
          NAMESPACE: ${{ steps.canary-config.outputs.namespace }}
          RELEASE_NAME: ${{ steps.canary-config.outputs.release_name }}
        run: |
          set -euo pipefail
          release=$RELEASE_NAME
          if kubectl -n "$NAMESPACE" get deployment "$release" >/dev/null 2>&1; then
            kubectl -n "$NAMESPACE" rollout status deployment "$release" --timeout=5m
          elif kubectl -n "$NAMESPACE" get statefulset "$release" >/dev/null 2>&1; then
            kubectl -n "$NAMESPACE" rollout status statefulset "$release" --timeout=5m
          else
            echo "::warning::No deployment or statefulset named $release; checking pods by label"
            kubectl -n "$NAMESPACE" wait --for=condition=Ready pod -l app.kubernetes.io/name=$release --timeout=5m
          fi
