name: Bench & Comment
on: { pull_request: { types: [opened, synchronize, reopened] } }
jobs:
  bench:
    runs-on: ubuntu-latest
    env:
      BENCH_URL: http://localhost:4000/health
      NEO4J_URL: bolt://localhost:7687
      NEO4J_USER: neo4j
      NEO4J_PASS: password
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      - uses: actions/setup-node@v4
        with:
          node-version: '20'
      - name: Run harness
        run: |
          make -f sprint/impl/Makefile run || true
          python3 sprint/experiments/harness/run.py --config sprint/experiments/configs.yaml || true
      - name: Evaluate SLOs (non-blocking here; main workflow enforces)
        run: |
          python3 -m pip install pyyaml >/dev/null 2>&1 || true
          python3 sprint/experiments/evaluate.py > eval.json || true
      - name: Build PR comment
        run: |
          echo "### Bench (smoke)" > bench.md
          echo "" >> bench.md
          echo "| target | p95 (ms) | error rate |" >> bench.md
          echo "|---|---:|---:|" >> bench.md
          jq -r 'to_entries[] | "| \(.key) | \(.value.current.p95 // "n/a") | \(.value.current.error_rate // "n/a") |"' eval.json >> bench.md || true
          echo "" >> bench.md
          echo "_Artifacts: \`sprint/benchmark/metrics/*\`_" >> bench.md
      - name: Label on SLO failure
        if: failure()
        uses: actions-ecosystem/action-add-labels@v1
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          labels: performance-regression
      - uses: thollander/actions-comment-pull-request@v2
        with:
          filePath: bench.md
      - uses: actions/upload-artifact@v4
        with:
          name: bench-metrics
          path: sprint/benchmark/metrics/**
