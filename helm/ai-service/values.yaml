image:
  repository: ghcr.io/BrianCLong/intelgraph/ai-service
  tag: ""
  pullPolicy: IfNotPresent

replicaCount: 1

service:
  type: ClusterIP
  port: 8080

env: []

resources:
  requests:
    cpu: 200m
    memory: 512Mi
  limits:
    cpu: 2000m
    memory: 4Gi

ingress:
  enabled: false

hpa:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80
  targetGPUUtilizationPercentage: null

networkPolicy:
  enabled: true
  allowNamespaces: []

keda:
  enabled: false
  redisAddress: redis-master.redis.svc:6379
  queueName: intelgraph
  queueLength: 50

istio:
  enabled: true

serviceMonitor:
  enabled: true
  interval: 30s
  portName: http

pdb:
  enabled: true
  minAvailable: 1

# Example GPU scheduling configuration
# nodeSelector:
#   accelerator: nvidia-tesla-k80
# tolerations:
#   - key: nvidia.com/gpu
#     operator: Exists
#     effect: NoSchedule
# affinity:
#   nodeAffinity:
#     requiredDuringSchedulingIgnoredDuringExecution:
#       nodeSelectorTerms:
#         - matchExpressions:
#             - key: accelerator
#               operator: In
#               values:
#                 - nvidia-tesla-k80
nodeSelector: {}
tolerations: []
affinity: {}
