#!/usr/bin/env python3
"""
MC Platform v0.3+ Expansion Suite
+2 Tenants A/A GA and Tier-3 Scoped Autonomy Pilot Implementation
Comprehensive automation for scaling from 3 ‚Üí 5 tenants with controlled autonomy
"""

import os
import json
import yaml
import asyncio
import hashlib
import logging
import subprocess
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Union, Any, Tuple
from dataclasses import dataclass, field, asdict
from enum import Enum
from pathlib import Path
import statistics
import numpy as np

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] MC-v0.3+: %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class TenantReadinessStatus(Enum):
    """Tenant readiness assessment status"""
    NOT_ASSESSED = "not_assessed"
    READY = "ready"
    NEEDS_WORK = "needs_work"
    BLOCKED = "blocked"

class AutonomyTier(Enum):
    """Autonomy tier levels"""
    T1_MANUAL = "T1_manual"
    T2_ASSISTED = "T2_assisted"
    T3_SCOPED = "T3_scoped"
    T4_FULL = "T4_full"

class ExpansionStage(Enum):
    """Expansion rollout stages"""
    STAGING = "staging"
    CANARY_20 = "canary_20"
    CANARY_50 = "canary_50"
    PRODUCTION = "production"

@dataclass
class TenantReadiness:
    """Tenant readiness assessment"""
    tenant_id: str
    traffic_daily: int
    data_volume_gb: float
    residency_coverage: float
    persisted_query_compliance: float
    slo_baseline_p95: float
    status: TenantReadinessStatus
    readiness_score: float
    blockers: List[str] = field(default_factory=list)

@dataclass
class AutonomyPilotConfig:
    """Tier-3 autonomy pilot configuration"""
    tenant_id: str
    tier: AutonomyTier
    scope: List[str]
    hitl_override: bool
    simulation_enabled: bool
    approval_required: bool
    compensation_enabled: bool
    success_rate_target: float
    compensation_rate_max: float
    false_negative_max: float

@dataclass
class TripwireConfig:
    """Tripwire configuration for automated responses"""
    name: str
    condition: str
    threshold: float
    duration_minutes: int
    action: str
    escalation_channel: str

class MCv03ExpansionSuite:
    """MC v0.3+ expansion implementation suite"""

    def __init__(self, config_path: Optional[str] = None):
        self.version = "v0.3.1-mc"
        self.generated_at = datetime.now().isoformat()
        self.config = self._load_config(config_path)
        self.output_dir = Path("out/v0.3-expansion")
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def _load_config(self, config_path: Optional[str]) -> Dict[str, Any]:
        """Load configuration with expansion defaults"""
        default_config = {
            "current_tenants": ["TENANT_001", "TENANT_002", "TENANT_003"],
            "expansion_tenants": ["TENANT_004", "TENANT_005"],
            "pilot_tenant": "TENANT_001",
            "prerequisites": {
                "green_days_required": 14,
                "slo_compliance_min": 0.994,
                "cost_budget_max": 0.80,
                "privacy_violations_max": 0
            },
            "tripwires": {
                "error_budget_threshold": 0.60,
                "replication_lag_max_ms": 60000,
                "conflict_rate_max": 0.001,
                "residency_violation_max": 0
            }
        }

        if config_path and os.path.exists(config_path):
            with open(config_path, 'r') as f:
                user_config = yaml.safe_load(f)
                default_config.update(user_config)

        return default_config

    def assess_tenant_readiness(self, tenant_id: str) -> TenantReadiness:
        """Assess tenant readiness for A/A GA expansion"""
        logger.info(f"üìã Assessing readiness for {tenant_id}...")

        # Simulate realistic tenant assessment data
        tenant_data = {
            "TENANT_004": {
                "traffic_daily": 1_450_000,
                "data_volume_gb": 28.7,
                "residency_coverage": 97.3,
                "persisted_query_compliance": 99.2,
                "slo_baseline_p95": 380.0,
                "blockers": ["cache_warming_incomplete"]
            },
            "TENANT_005": {
                "traffic_daily": 2_100_000,
                "data_volume_gb": 41.2,
                "residency_coverage": 99.1,
                "persisted_query_compliance": 99.8,
                "slo_baseline_p95": 290.0,
                "blockers": []
            }
        }

        data = tenant_data.get(tenant_id, {
            "traffic_daily": 1_000_000,
            "data_volume_gb": 20.0,
            "residency_coverage": 95.0,
            "persisted_query_compliance": 98.0,
            "slo_baseline_p95": 400.0,
            "blockers": ["assessment_pending"]
        })

        # Calculate readiness score
        score = 0.0
        score += min(data["residency_coverage"] / 100.0, 1.0) * 0.3
        score += min(data["persisted_query_compliance"] / 100.0, 1.0) * 0.3
        score += max(0, (500 - data["slo_baseline_p95"]) / 500) * 0.2
        score += min(data["traffic_daily"] / 3_000_000, 1.0) * 0.2

        # Determine status
        if len(data["blockers"]) > 0:
            status = TenantReadinessStatus.NEEDS_WORK if score > 0.7 else TenantReadinessStatus.BLOCKED
        else:
            status = TenantReadinessStatus.READY if score > 0.8 else TenantReadinessStatus.NEEDS_WORK

        return TenantReadiness(
            tenant_id=tenant_id,
            traffic_daily=data["traffic_daily"],
            data_volume_gb=data["data_volume_gb"],
            residency_coverage=data["residency_coverage"],
            persisted_query_compliance=data["persisted_query_compliance"],
            slo_baseline_p95=data["slo_baseline_p95"],
            status=status,
            readiness_score=score,
            blockers=data["blockers"]
        )

    def generate_expansion_plan(self) -> Dict[str, Any]:
        """Generate comprehensive expansion plan for +2 tenants"""
        logger.info("üìä Generating +2 tenant expansion plan...")

        # Assess new tenants
        tenant_assessments = {}
        for tenant in self.config["expansion_tenants"]:
            assessment = self.assess_tenant_readiness(tenant)
            assessment_dict = asdict(assessment)
            # Convert enum to string for JSON serialization
            assessment_dict['status'] = assessment.status.value
            tenant_assessments[tenant] = assessment_dict

        # Generate rollout waves
        wave_a = ["TENANT_004"]
        wave_b = ["TENANT_005"]

        expansion_plan = {
            "expansion_metadata": {
                "version": self.version,
                "generated_at": self.generated_at,
                "expansion_type": "aa_ga_plus_2_tenants",
                "prerequisite_validation": "14_day_green_required"
            },
            "tenant_assessments": tenant_assessments,
            "rollout_waves": {
                "wave_a": {
                    "tenants": wave_a,
                    "timeline": "Weeks 1-2",
                    "stages": ["staging_24h", "canary_20_8h", "canary_50_8h", "production_24h"]
                },
                "wave_b": {
                    "tenants": wave_b,
                    "timeline": "Weeks 3-4",
                    "stages": ["staging_24h", "canary_20_8h", "canary_50_8h", "production_24h"]
                }
            },
            "prerequisites": {
                "current_tenant_green_days": 14,
                "slo_compliance_min": self.config["prerequisites"]["slo_compliance_min"],
                "cost_budget_utilization_max": self.config["prerequisites"]["cost_budget_max"],
                "privacy_violations_tolerance": self.config["prerequisites"]["privacy_violations_max"]
            },
            "validation_criteria": {
                "replication_lag_max_ms": 60000,
                "conflict_rate_max": 0.0005,
                "rpo_target_minutes": 5,
                "rto_target_minutes": 30,
                "privacy_violation_tolerance": 0,
                "budget_utilization_max": 0.80
            },
            "tripwires": self._generate_tripwire_configs(),
            "backout_procedures": {
                "glb_bias_single_region": "immediate",
                "disable_ttl_autotune": "preserve_cache_state",
                "persisted_only_enforcement": "maintain_enabled",
                "replay_idempotent_ops": "preserve_provenance"
            }
        }

        # Write expansion plan
        plan_path = self.output_dir / "aa-expansion-plan-plus2.json"
        with open(plan_path, 'w') as f:
            json.dump(expansion_plan, f, indent=2)

        logger.info(f"‚úÖ A/A Expansion Plan: {plan_path}")
        return expansion_plan

    def _generate_tripwire_configs(self) -> List[Dict[str, Any]]:
        """Generate tripwire configurations for automated responses"""
        tripwires = [
            TripwireConfig(
                name="error_budget_burn_fast",
                condition="error_budget < 60%",
                threshold=0.60,
                duration_minutes=60,
                action="pause_rollout",
                escalation_channel="#mc-alerts"
            ),
            TripwireConfig(
                name="replication_lag_spike",
                condition="replication_lag > 60s",
                threshold=60.0,
                duration_minutes=10,
                action="bias_glb_healthy_region",
                escalation_channel="#mc-alerts"
            ),
            TripwireConfig(
                name="conflict_rate_spike",
                condition="conflict_rate > 0.1%",
                threshold=0.001,
                duration_minutes=5,
                action="rollback_to_ap",
                escalation_channel="#mc-critical"
            ),
            TripwireConfig(
                name="residency_violation",
                condition="residency_violations > 0",
                threshold=0.0,
                duration_minutes=1,
                action="immediate_rollback_page_dpo",
                escalation_channel="#privacy-emergency"
            ),
            TripwireConfig(
                name="non_persisted_query_spike",
                condition="non_persisted_rate > 0.1%",
                threshold=0.001,
                duration_minutes=15,
                action="rollback_tenant_to_ap",
                escalation_channel="#mc-alerts"
            )
        ]

        return [asdict(tw) for tw in tripwires]

    def _serialize_pilot_config(self, pilot_config: AutonomyPilotConfig) -> Dict[str, Any]:
        """Serialize pilot config with enum conversion"""
        config_dict = asdict(pilot_config)
        config_dict['tier'] = pilot_config.tier.value
        return config_dict

    def generate_autonomy_pilot_config(self) -> Dict[str, Any]:
        """Generate Tier-3 scoped autonomy pilot configuration"""
        logger.info("ü§ñ Generating Tier-3 autonomy pilot configuration...")

        pilot_config = AutonomyPilotConfig(
            tenant_id=self.config["pilot_tenant"],
            tier=AutonomyTier.T3_SCOPED,
            scope=[
                "read_only_derived_updates",
                "cache_materialized_views",
                "computed_aggregations"
            ],
            hitl_override=True,
            simulation_enabled=True,
            approval_required=True,
            compensation_enabled=True,
            success_rate_target=0.999,
            compensation_rate_max=0.005,
            false_negative_max=0.001
        )

        autonomy_pilot = {
            "pilot_metadata": {
                "version": self.version,
                "generated_at": self.generated_at,
                "pilot_type": "tier_3_scoped_autonomy",
                "pilot_tenant": self.config["pilot_tenant"]
            },
            "pilot_configuration": self._serialize_pilot_config(pilot_config),
            "scope_controls": {
                "allowed_operations": [
                    "update_derived_entity_cache",
                    "refresh_materialized_view",
                    "recompute_aggregation_index"
                ],
                "forbidden_operations": [
                    "export_data",
                    "retention_policy_changes",
                    "cross_tenant_operations",
                    "direct_data_modification"
                ],
                "hitl_override_required": [
                    "any_export_operation",
                    "retention_modification",
                    "policy_change",
                    "cross_tenant_access"
                ]
            },
            "simulation_framework": {
                "shadow_environment": "enabled",
                "counterfactual_validation": "mandatory",
                "approval_token_required": True,
                "evidence_collection": "comprehensive"
            },
            "success_criteria": {
                "autonomy_success_rate_min": 99.9,
                "compensation_rate_max": 0.5,
                "false_negative_rate_max": 0.1,
                "slo_regression_tolerance": 0.0,
                "privacy_incident_tolerance": 0
            },
            "monitoring_framework": {
                "real_time_metrics": [
                    "autonomy_decision_rate",
                    "compensation_trigger_rate",
                    "simulation_accuracy",
                    "hitl_override_frequency"
                ],
                "alert_thresholds": {
                    "error_budget_burn_fast": "2%/1h",
                    "error_budget_burn_slow": "10%/6h",
                    "risk_score_anomaly": "threshold_deviation",
                    "residency_denial_spike": "immediate_abort"
                }
            },
            "operational_runbook": {
                "enable_pilot": "mc autonomy set --tenant TENANT_001 --tier T3 --scope read-only --require-hitl true",
                "run_simulation": "mc autonomy simulate --tenant TENANT_001 --op-set derived_updates --evidence out/sim.json",
                "enact_with_approval": "mc autonomy enact --tenant TENANT_001 --approval-token $TOKEN --from-sim out/sim.json --evidence out/enact.json",
                "compensate_if_needed": "mc autonomy compensate --tenant TENANT_001 --from-evidence out/enact.json",
                "emergency_downgrade": "mc autonomy set --tenant TENANT_001 --tier T2"
            }
        }

        # Write autonomy pilot config
        pilot_path = self.output_dir / "tier3-autonomy-pilot-config.json"
        with open(pilot_path, 'w') as f:
            json.dump(autonomy_pilot, f, indent=2)

        logger.info(f"‚úÖ Tier-3 Autonomy Pilot Config: {pilot_path}")
        return autonomy_pilot

    def generate_evidence_integration_plan(self) -> Dict[str, Any]:
        """Generate evidence integration plan for v0.3+ artifacts"""
        logger.info("üìã Generating evidence integration plan...")

        evidence_integration = {
            "integration_metadata": {
                "version": self.version,
                "generated_at": self.generated_at,
                "integration_scope": "v0.3_plus_expansion_evidence"
            },
            "artifact_integration": {
                "ga_delta_report": {
                    "source": "out/v0.3-capitalization/ga-delta-report-v0.3.json",
                    "integration_target": "dist/evidence-v0.3.1-mc.json",
                    "section": "cost_slo_deltas",
                    "append_mode": True
                },
                "qi_catalog_v1": {
                    "source": ["out/v0.3-capitalization/qi-catalog-v1.json", "out/v0.3-capitalization/qi-catalog-v1.yaml"],
                    "integration_target": "dist/evidence-v0.3.1-mc.json",
                    "section": "privacy_governance",
                    "status": "FROZEN_v1.0.0",
                    "review_schedule": "90_day_cycle"
                },
                "dr_drill_schedule": {
                    "source": "out/v0.3-capitalization/dr-drill-schedule-monthly.json",
                    "integration_target": "runbooks/dr-automation.json",
                    "calendar_integration": "required",
                    "k6_chaos_scenarios": "referenced_artifacts"
                },
                "privacy_dashboard_tiles": {
                    "source": "out/v0.3-capitalization/privacy-dashboard-tiles.json",
                    "integration_target": "monitoring/grafana-dashboards/",
                    "visibility": "INTERNAL_ADMIN_ONLY",
                    "import_method": "grafana_api_provisioning"
                }
            },
            "evidence_bundle_updates": {
                "new_tenant_sections": {
                    "TENANT_004": {
                        "readiness_assessment": "linked",
                        "rollout_evidence": "pending_wave_a",
                        "validation_artifacts": "generated_per_stage"
                    },
                    "TENANT_005": {
                        "readiness_assessment": "linked",
                        "rollout_evidence": "pending_wave_b",
                        "validation_artifacts": "generated_per_stage"
                    }
                },
                "autonomy_pilot_evidence": {
                    "pilot_tenant": "TENANT_001",
                    "simulation_results": "continuous_collection",
                    "approval_audit_trail": "comprehensive_logging",
                    "compensation_events": "detailed_analysis"
                }
            },
            "compliance_attestations": {
                "dpo_sign_off": "required_for_qi_catalog_freeze",
                "cto_approval": "required_for_autonomy_pilot",
                "security_review": "completed_for_expansion_plan",
                "external_audit_notification": "30_day_advance_notice"
            }
        }

        # Write evidence integration plan
        integration_path = self.output_dir / "evidence-integration-plan.json"
        with open(integration_path, 'w') as f:
            json.dump(evidence_integration, f, indent=2)

        logger.info(f"‚úÖ Evidence Integration Plan: {integration_path}")
        return evidence_integration

    def generate_expansion_automation_scripts(self) -> Dict[str, str]:
        """Generate automation scripts for expansion execution"""
        logger.info("‚öôÔ∏è Generating expansion automation scripts...")

        scripts = {}

        # Tenant readiness validation script
        readiness_script = """#!/bin/bash
# MC v0.3+ Tenant Readiness Validation Script
set -euo pipefail

TENANT_ID="$1"
PREREQUISITES_DAYS="${2:-14}"

echo "üîç Validating tenant readiness: $TENANT_ID"

# Check 14-day green health
echo "Checking $PREREQUISITES_DAYS-day green health..."
HEALTH_SCORE=$(mc health check --tenant "$TENANT_ID" --days "$PREREQUISITES_DAYS" --json | jq -r '.overall_score')
if (( $(echo "$HEALTH_SCORE < 0.994" | bc -l) )); then
    echo "‚ùå Health score $HEALTH_SCORE below 99.4% threshold"
    exit 1
fi

# Check persisted query compliance
PERSISTED_COMPLIANCE=$(mc query compliance --tenant "$TENANT_ID" --json | jq -r '.persisted_rate')
if (( $(echo "$PERSISTED_COMPLIANCE < 0.999" | bc -l) )); then
    echo "‚ùå Persisted query compliance $PERSISTED_COMPLIANCE below 99.9%"
    exit 1
fi

# Check residency coverage
RESIDENCY_COVERAGE=$(mc residency check --tenant "$TENANT_ID" --json | jq -r '.coverage_percent')
if (( $(echo "$RESIDENCY_COVERAGE < 95.0" | bc -l) )); then
    echo "‚ùå Residency coverage $RESIDENCY_COVERAGE below 95%"
    exit 1
fi

echo "‚úÖ Tenant $TENANT_ID ready for A/A GA expansion"
"""

        scripts["tenant_readiness_check.sh"] = readiness_script

        # A/A expansion rollout script
        rollout_script = """#!/bin/bash
# MC v0.3+ A/A Expansion Rollout Script
set -euo pipefail

TENANT_ID="$1"
STAGE="${2:-staging}"
DURATION="${3:-24h}"

echo "üöÄ Rolling out A/A GA for $TENANT_ID at stage $STAGE"

# Pre-flight checks
echo "Running pre-flight validation..."
./tenant_readiness_check.sh "$TENANT_ID" 14

# Enable A/A for tenant at specified stage
case "$STAGE" in
    "staging")
        echo "üìã Enabling staging A/A..."
        mc aa enable --tenant "$TENANT_ID" --stage staging --duration "$DURATION"
        ;;
    "canary_20")
        echo "üìã Enabling 20% canary..."
        mc aa enable --tenant "$TENANT_ID" --stage canary --percentage 20 --duration "$DURATION"
        ;;
    "canary_50")
        echo "üìã Enabling 50% canary..."
        mc aa enable --tenant "$TENANT_ID" --stage canary --percentage 50 --duration "$DURATION"
        ;;
    "production")
        echo "üìã Enabling full production A/A..."
        mc aa enable --tenant "$TENANT_ID" --stage production --duration "$DURATION"
        ;;
    *)
        echo "‚ùå Unknown stage: $STAGE"
        exit 1
        ;;
esac

# Monitor for duration
echo "‚è±Ô∏è Monitoring for $DURATION..."
timeout "$DURATION" mc aa monitor --tenant "$TENANT_ID" --stage "$STAGE" || {
    echo "‚ùå Monitoring failed or timeout reached"
    mc aa rollback --tenant "$TENANT_ID"
    exit 1
}

echo "‚úÖ Stage $STAGE completed successfully for $TENANT_ID"
"""

        scripts["aa_expansion_rollout.sh"] = rollout_script

        # Autonomy pilot script
        autonomy_script = """#!/bin/bash
# MC v0.3+ Tier-3 Autonomy Pilot Script
set -euo pipefail

TENANT_ID="${1:-TENANT_001}"
ACTION="${2:-simulate}"
OP_SET="${3:-derived_updates}"

echo "ü§ñ Autonomy pilot $ACTION for $TENANT_ID"

case "$ACTION" in
    "enable")
        echo "üîß Enabling Tier-3 scoped autonomy..."
        mc autonomy set --tenant "$TENANT_ID" --tier T3 --scope read-only --require-hitl true
        echo "‚úÖ Autonomy enabled with HITL override"
        ;;
    "simulate")
        echo "üß™ Running counterfactual simulation..."
        mc autonomy simulate \\
            --tenant "$TENANT_ID" \\
            --op-set "$OP_SET" \\
            --evidence "out/autonomy-sim-$(date +%s).json"
        ;;
    "enact")
        APPROVAL_TOKEN="${APPROVAL_TOKEN:?APPROVAL_TOKEN required for enactment}"
        SIM_FILE="${4:?Simulation file required}"
        echo "‚ö° Enacting with approval token..."
        mc autonomy enact \\
            --tenant "$TENANT_ID" \\
            --approval-token "$APPROVAL_TOKEN" \\
            --from-sim "$SIM_FILE" \\
            --evidence "out/autonomy-enact-$(date +%s).json"
        ;;
    "compensate")
        EVIDENCE_FILE="${4:?Evidence file required}"
        echo "üîÑ Running compensation procedure..."
        mc autonomy compensate \\
            --tenant "$TENANT_ID" \\
            --from-evidence "$EVIDENCE_FILE"
        ;;
    "downgrade")
        echo "‚¨áÔ∏è Downgrading to Tier-2..."
        mc autonomy set --tenant "$TENANT_ID" --tier T2
        echo "‚úÖ Downgraded to manual assistance mode"
        ;;
    *)
        echo "‚ùå Unknown action: $ACTION"
        echo "Usage: $0 TENANT_ID [enable|simulate|enact|compensate|downgrade] [OP_SET] [FILE]"
        exit 1
        ;;
esac
"""

        scripts["autonomy_pilot.sh"] = autonomy_script

        # Write automation scripts
        for script_name, script_content in scripts.items():
            script_path = self.output_dir / script_name
            with open(script_path, 'w') as f:
                f.write(script_content)
            os.chmod(script_path, 0o755)

        logger.info(f"‚úÖ Generated {len(scripts)} automation scripts")
        return scripts

    def generate_comprehensive_expansion_plan(self) -> Dict[str, Any]:
        """Generate comprehensive v0.3+ expansion plan"""
        logger.info("üöÄ Generating comprehensive v0.3+ expansion plan...")

        # Generate all components
        expansion_plan = self.generate_expansion_plan()
        autonomy_pilot = self.generate_autonomy_pilot_config()
        evidence_integration = self.generate_evidence_integration_plan()
        automation_scripts = self.generate_expansion_automation_scripts()

        # Create master expansion plan
        master_plan = {
            "expansion_metadata": {
                "version": self.version,
                "generated_at": self.generated_at,
                "expansion_scope": "plus_2_tenants_tier3_autonomy",
                "timeline": "5_weeks_phased_rollout"
            },
            "executive_summary": {
                "objective": "Scale multi-region resilience and trial scoped autonomy",
                "scope": "3 ‚Üí 5 tenants A/A GA + Tier-3 autonomy pilot",
                "constraints": "SLO/cost/privacy guardrails + 14-day green prerequisite",
                "success_criteria": [
                    "+2 tenants at A/A GA with zero P1 incidents",
                    "Autonomy success rate ‚â•99.9%",
                    "Compensation rate ‚â§0.5%",
                    "Evidence bundle v0.3.1-mc generated"
                ]
            },
            "expansion_components": {
                "aa_expansion": "aa-expansion-plan-plus2.json",
                "autonomy_pilot": "tier3-autonomy-pilot-config.json",
                "evidence_integration": "evidence-integration-plan.json",
                "automation_scripts": list(automation_scripts.keys())
            },
            "timeline_milestones": {
                "week_0": "Readiness gates + flags preparation + evidence integration",
                "weeks_1_2": "Wave A rollout (TENANT_004) + autonomy pilot start",
                "weeks_3_4": "Wave B rollout (TENANT_005) + autonomy pilot weekly review",
                "week_5": "Decision point + evidence bundle v0.3.1-mc publication"
            },
            "risk_mitigations": {
                "replication_skew": "per_tenant_flags + tripwires + GLB bias",
                "conflict_spikes": "automated_rollback + provenance_preservation",
                "autonomy_drift": "counterfactual_simulation + compensation",
                "privacy_regressions": "QI_catalog_v1_frozen + audit_trail"
            },
            "decision_gates": {
                "expand_aa_approved": "YES with 14-day green prerequisite",
                "tier3_pilot_approved": "YES with TENANT_001 limited scope",
                "success_criteria_defined": "comprehensive_kpis_established",
                "backout_procedures_tested": "validated_rollback_playbooks"
            }
        }

        # Write master expansion plan
        master_path = self.output_dir / "mc-v03-plus-expansion-plan.json"
        with open(master_path, 'w') as f:
            json.dump(master_plan, f, indent=2)

        logger.info(f"‚úÖ Master Expansion Plan: {master_path}")
        logger.info("üéâ MC v0.3+ expansion plan generation completed!")

        return master_plan

def main():
    """Main execution function"""
    import argparse

    parser = argparse.ArgumentParser(description="MC Platform v0.3+ Expansion Suite")
    parser.add_argument("--config", help="Configuration file path")
    parser.add_argument("--component", choices=["expansion", "autonomy", "evidence", "scripts", "all"],
                       default="all", help="Generate specific component")

    args = parser.parse_args()

    logger.info("üöÄ Starting MC v0.3+ Expansion Suite...")
    suite = MCv03ExpansionSuite(args.config)

    if args.component == "expansion":
        suite.generate_expansion_plan()
    elif args.component == "autonomy":
        suite.generate_autonomy_pilot_config()
    elif args.component == "evidence":
        suite.generate_evidence_integration_plan()
    elif args.component == "scripts":
        suite.generate_expansion_automation_scripts()
    else:
        suite.generate_comprehensive_expansion_plan()

    logger.info("‚úÖ MC v0.3+ Expansion Suite completed!")

if __name__ == "__main__":
    main()