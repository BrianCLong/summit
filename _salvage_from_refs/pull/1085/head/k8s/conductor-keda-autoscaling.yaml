# Conductor Omniversal - KEDA Autoscaling Configuration
# Event-driven autoscaling for dynamic workload management

apiVersion: v1
kind: Namespace
metadata:
  name: conductor-system
  labels:
    name: conductor-system
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: orchestration

---
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: conductor-router-scaler
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: router
spec:
  scaleTargetRef:
    name: conductor-router
  pollingInterval: 10  # Check every 10 seconds
  cooldownPeriod: 60   # Wait 60 seconds before scaling down
  minReplicaCount: 2   # Always keep minimum 2 replicas
  maxReplicaCount: 50  # Maximum 50 replicas for high load
  triggers:
  # Redis queue depth trigger
  - type: redis
    metadata:
      address: redis-conductor.conductor-system.svc.cluster.local:6379
      listName: "queue:routing_requests"
      listLength: "10"  # Scale when queue > 10 items
    authenticationRef:
      name: redis-auth

  # Prometheus metrics trigger
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: conductor_request_rate
      query: rate(conductor_requests_total[1m])
      threshold: "5"  # Scale when > 5 requests per second
      
  # Custom HTTP requests trigger
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: conductor_pending_requests
      query: conductor_router_queue_depth
      threshold: "20"  # Scale when > 20 pending requests

---
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: conductor-experts-scaler
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: experts
spec:
  scaleTargetRef:
    name: conductor-experts
  pollingInterval: 15
  cooldownPeriod: 120  # Longer cooldown for expert workers
  minReplicaCount: 1
  maxReplicaCount: 20
  triggers:
  # Redis work queue trigger
  - type: redis
    metadata:
      address: redis-conductor.conductor-system.svc.cluster.local:6379
      listName: "queue:expert_tasks"
      listLength: "5"   # Scale when > 5 expert tasks queued
    authenticationRef:
      name: redis-auth

  # CPU-based scaling for compute-heavy tasks
  - type: cpu
    metadata:
      type: Utilization
      value: "70"  # Scale when CPU > 70%
      
  # Memory-based scaling
  - type: memory
    metadata:
      type: Utilization
      value: "80"  # Scale when memory > 80%

---
apiVersion: keda.sh/v1alpha1 
kind: ScaledObject
metadata:
  name: conductor-web-orchestrator-scaler
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: web-orchestrator
spec:
  scaleTargetRef:
    name: conductor-web-orchestrator
  pollingInterval: 20
  cooldownPeriod: 180  # Web scraping needs longer cooldown
  minReplicaCount: 1
  maxReplicaCount: 10  # Limited scaling for web scraping compliance
  triggers:
  # Web scraping queue trigger
  - type: redis
    metadata:
      address: redis-conductor.conductor-system.svc.cluster.local:6379
      listName: "queue:web_tasks"
      listLength: "3"   # Conservative scaling for web tasks
    authenticationRef:
      name: redis-auth
      
  # Rate limiting aware scaling
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: conductor_web_rate_limit_headroom
      query: conductor_web_scraping_rate_limit_remaining
      threshold: "50"  # Scale down when rate limit headroom < 50%

---
apiVersion: keda.sh/v1alpha1
kind: ScaledObject  
metadata:
  name: conductor-compliance-scanner-scaler
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: compliance
spec:
  scaleTargetRef:
    name: conductor-compliance-scanner
  pollingInterval: 60  # Less frequent polling for compliance tasks
  cooldownPeriod: 300  # 5 minute cooldown
  minReplicaCount: 1
  maxReplicaCount: 5
  triggers:
  # Compliance scan queue
  - type: redis
    metadata:
      address: redis-conductor.conductor-system.svc.cluster.local:6379
      listName: "queue:compliance_scans"
      listLength: "2"
    authenticationRef:
      name: redis-auth

---
apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: conductor-crdt-resolver-scaler  
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: crdt-resolver
spec:
  scaleTargetRef:
    name: conductor-crdt-resolver
  pollingInterval: 30
  cooldownPeriod: 180
  minReplicaCount: 1
  maxReplicaCount: 8
  triggers:
  # CRDT conflict resolution queue
  - type: redis
    metadata:
      address: redis-conductor.conductor-system.svc.cluster.local:6379
      listName: "queue:crdt_conflicts"
      listLength: "5"
    authenticationRef:
      name: redis-auth

  # High-priority conflict escalation
  - type: prometheus
    metadata:
      serverAddress: http://prometheus.monitoring.svc.cluster.local:9090
      metricName: conductor_critical_conflicts
      query: conductor_crdt_conflicts{severity="critical"}
      threshold: "1"  # Scale immediately on critical conflicts

---
# Redis authentication secret reference
apiVersion: keda.sh/v1alpha1
kind: TriggerAuthentication
metadata:
  name: redis-auth
  namespace: conductor-system
spec:
  secretTargetRef:
  - parameter: password
    name: redis-secret
    key: password

---
# HPA for baseline scaling (works alongside KEDA)
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: conductor-baseline-hpa
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: baseline-scaling
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: conductor-api-gateway
  minReplicas: 3
  maxReplicas: 20
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300  # 5 minutes
      policies:
      - type: Percent
        value: 10    # Scale down by 10% of current replicas
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60   # 1 minute
      policies:
      - type: Pods
        value: 2     # Add 2 pods at a time
        periodSeconds: 60
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 70
  # Custom metrics from Prometheus
  - type: Pods
    pods:
      metric:
        name: conductor_requests_per_second
      target:
        type: AverageValue
        averageValue: "10"

---
# Vertical Pod Autoscaler for resource optimization
apiVersion: autoscaling.k8s.io/v1
kind: VerticalPodAutoscaler
metadata:
  name: conductor-vpa
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal
    app.kubernetes.io/component: resource-optimization
spec:
  targetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: conductor-router
  updatePolicy:
    updateMode: "Auto"  # Automatically apply recommendations
  resourcePolicy:
    containerPolicies:
    - containerName: conductor-router
      minAllowed:
        cpu: 100m
        memory: 128Mi
      maxAllowed:
        cpu: 4
        memory: 8Gi
      controlledResources: ["cpu", "memory"]
      controlledValues: RequestsAndLimits

---
# KEDA ScaledJob for batch processing
apiVersion: keda.sh/v1alpha1
kind: ScaledJob
metadata:
  name: conductor-batch-processor
  namespace: conductor-system
  labels:
    app.kubernetes.io/name: conductor-omniversal  
    app.kubernetes.io/component: batch-processing
spec:
  jobTargetRef:
    template:
      metadata:
        labels:
          app: conductor-batch-processor
      spec:
        restartPolicy: Never
        containers:
        - name: batch-processor
          image: conductor/batch-processor:latest
          env:
          - name: BATCH_SIZE
            value: "100"
          - name: REDIS_URL
            value: "redis://redis-conductor.conductor-system.svc.cluster.local:6379"
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: 2
              memory: 4Gi
  pollingInterval: 30
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 1
  maxReplicaCount: 10
  triggers:
  # Large batch processing queue
  - type: redis
    metadata:
      address: redis-conductor.conductor-system.svc.cluster.local:6379
      listName: "queue:batch_jobs"
      listLength: "20"  # Process batches when > 20 items queued
    authenticationRef:
      name: redis-auth

---
# Network policies for autoscaling components
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: conductor-autoscaling-netpol
  namespace: conductor-system
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/name: conductor-omniversal
  policyTypes:
  - Ingress
  - Egress
  ingress:
  - from:
    # Allow KEDA metrics server
    - namespaceSelector:
        matchLabels:
          name: keda-system
    ports:
    - protocol: TCP
      port: 8080
  - from:
    # Allow Prometheus scraping
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 8080
  egress:
  # Allow Redis access
  - to:
    - podSelector:
        matchLabels:
          app: redis-conductor
    ports:
    - protocol: TCP
      port: 6379
  # Allow Prometheus access
  - to:
    - namespaceSelector:
        matchLabels:
          name: monitoring
    ports:
    - protocol: TCP
      port: 9090

---
# PodDisruptionBudget for high availability during scaling
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: conductor-pdb
  namespace: conductor-system
spec:
  minAvailable: 50%
  selector:
    matchLabels:
      app.kubernetes.io/name: conductor-omniversal
      app.kubernetes.io/component: router