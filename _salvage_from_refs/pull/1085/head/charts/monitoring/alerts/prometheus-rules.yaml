apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: intelgraph-alert-rules
  namespace: monitoring
  labels:
    app.kubernetes.io/name: intelgraph
    app.kubernetes.io/component: monitoring
    prometheus: kube-prometheus
    role: alert-rules
spec:
  groups:
    # === CRITICAL SYSTEM ALERTS ===
    - name: intelgraph.critical
      interval: 30s
      rules:
        - alert: MaestroServiceDown
          expr: up{job="maestro-orchestrator"} == 0
          for: 1m
          labels:
            severity: critical
            service: maestro
            team: platform
          annotations:
            summary: "Maestro orchestrator service is down"
            description: "The Maestro orchestrator service has been down for more than 1 minute. This affects all AI orchestration capabilities."
            runbook_url: "https://runbooks.intelgraph.ai/maestro-service-down"
            dashboard_url: "https://grafana.intelgraph.ai/d/maestro-overview"

        - alert: Neo4jDatabaseDown
          expr: up{job="neo4j"} == 0
          for: 2m
          labels:
            severity: critical
            service: neo4j
            team: data
          annotations:
            summary: "Neo4j graph database is down"
            description: "Neo4j database has been unreachable for {{ $labels.instance }} for more than 2 minutes."
            runbook_url: "https://runbooks.intelgraph.ai/neo4j-down"

        - alert: HighErrorRate
          expr: |
            (
              rate(maestro_orchestration_errors_total[5m]) / 
              rate(maestro_orchestration_requests_total[5m])
            ) * 100 > 10
          for: 3m
          labels:
            severity: critical
            service: maestro
            team: platform
          annotations:
            summary: "High error rate detected"
            description: "Error rate is {{ $value }}% for endpoint {{ $labels.endpoint }}"
            runbook_url: "https://runbooks.intelgraph.ai/high-error-rate"

        - alert: ExtremeLatency
          expr: |
            histogram_quantile(0.95, 
              rate(maestro_orchestration_duration_seconds_bucket[5m])
            ) > 60
          for: 5m
          labels:
            severity: critical
            service: maestro
            team: platform
          annotations:
            summary: "Extreme latency detected"
            description: "95th percentile latency is {{ $value }}s for {{ $labels.endpoint }}"
            runbook_url: "https://runbooks.intelgraph.ai/extreme-latency"

        - alert: PodCrashLooping
          expr: |
            rate(kube_pod_container_status_restarts_total[15m]) * 60 * 15 > 0
          for: 5m
          labels:
            severity: critical
            service: kubernetes
            team: platform
          annotations:
            summary: "Pod is crash looping"
            description: "Pod {{ $labels.pod }} in {{ $labels.namespace }} is crash looping"
            runbook_url: "https://runbooks.intelgraph.ai/pod-crash-loop"

    # === HIGH PRIORITY ALERTS ===
    - name: intelgraph.high
      interval: 60s
      rules:
        - alert: HighMemoryUsage
          expr: |
            (
              container_memory_working_set_bytes{container!="POD",container!=""} / 
              container_spec_memory_limit_bytes{container!="POD",container!=""} * 100
            ) > 85
          for: 10m
          labels:
            severity: high
            service: kubernetes
            team: platform
          annotations:
            summary: "High memory usage"
            description: "Container {{ $labels.container }} memory usage is {{ $value }}%"
            runbook_url: "https://runbooks.intelgraph.ai/high-memory"

        - alert: HighCPUUsage
          expr: |
            (
              rate(container_cpu_usage_seconds_total{container!="POD",container!=""}[5m]) / 
              container_spec_cpu_quota{container!="POD",container!=""} * 100
            ) > 80
          for: 15m
          labels:
            severity: high
            service: kubernetes
            team: platform
          annotations:
            summary: "High CPU usage"
            description: "Container {{ $labels.container }} CPU usage is {{ $value }}%"

        - alert: GraphQueryLatencyHigh
          expr: |
            histogram_quantile(0.95, 
              rate(maestro_graph_query_duration_seconds_bucket[5m])
            ) > 5
          for: 10m
          labels:
            severity: high
            service: neo4j
            team: data
          annotations:
            summary: "Graph query latency is high"
            description: "95th percentile graph query latency is {{ $value }}s"
            runbook_url: "https://runbooks.intelgraph.ai/slow-graph-queries"

        - alert: AIModelLatencyHigh
          expr: |
            histogram_quantile(0.95, 
              rate(maestro_ai_model_response_time_seconds_bucket[10m])
            ) > 30
          for: 5m
          labels:
            severity: high
            service: ai-models
            team: ai
          annotations:
            summary: "AI model response time is high"
            description: "AI model {{ $labels.model }} 95th percentile latency is {{ $value }}s"
            runbook_url: "https://runbooks.intelgraph.ai/slow-ai-models"

        - alert: DiskSpaceLow
          expr: |
            (
              node_filesystem_avail_bytes{fstype!="tmpfs"} / 
              node_filesystem_size_bytes{fstype!="tmpfs"} * 100
            ) < 15
          for: 5m
          labels:
            severity: high
            service: infrastructure
            team: platform
          annotations:
            summary: "Disk space is running low"
            description: "Disk space on {{ $labels.instance }} at {{ $labels.mountpoint }} is {{ $value }}%"

        - alert: PremiumBudgetExhausted
          expr: maestro_premium_budget_utilization_percent > 95
          for: 2m
          labels:
            severity: high
            service: premium-routing
            team: ai
          annotations:
            summary: "Premium AI model budget nearly exhausted"
            description: "Premium budget utilization is {{ $value }}%"
            runbook_url: "https://runbooks.intelgraph.ai/budget-exhausted"

    # === MEDIUM PRIORITY ALERTS ===
    - name: intelgraph.medium
      interval: 120s
      rules:
        - alert: ModerateLatencyIncrease
          expr: |
            histogram_quantile(0.95, 
              rate(maestro_orchestration_duration_seconds_bucket[5m])
            ) > 10
          for: 10m
          labels:
            severity: medium
            service: maestro
            team: platform
          annotations:
            summary: "Moderate latency increase detected"
            description: "95th percentile latency is {{ $value }}s for {{ $labels.endpoint }}"

        - alert: ErrorRateElevated
          expr: |
            (
              rate(maestro_orchestration_errors_total[10m]) / 
              rate(maestro_orchestration_requests_total[10m])
            ) * 100 > 2
          for: 10m
          labels:
            severity: medium
            service: maestro
            team: platform
          annotations:
            summary: "Error rate is elevated"
            description: "Error rate is {{ $value }}% for {{ $labels.endpoint }}"

        - alert: WebScrapingFailureRate
          expr: |
            (
              rate(maestro_web_scraping_requests_total{status!="success"}[10m]) / 
              rate(maestro_web_scraping_requests_total[10m])
            ) * 100 > 25
          for: 15m
          labels:
            severity: medium
            service: web-scraping
            team: data
          annotations:
            summary: "Web scraping failure rate is high"
            description: "Web scraping failure rate is {{ $value }}%"

        - alert: AIModelErrorRateHigh
          expr: |
            (
              rate(maestro_ai_model_errors_total[10m]) / 
              rate(maestro_ai_model_requests_total[10m])
            ) * 100 > 5
          for: 10m
          labels:
            severity: medium
            service: ai-models
            team: ai
          annotations:
            summary: "AI model error rate is high"
            description: "AI model {{ $labels.model }} error rate is {{ $value }}%"

    # === SECURITY ALERTS ===
    - name: intelgraph.security
      interval: 30s
      rules:
        - alert: SecurityEventSpike
          expr: |
            rate(maestro_security_events_total[5m]) > 10
          for: 2m
          labels:
            severity: high
            service: security
            team: security
          annotations:
            summary: "Security event spike detected"
            description: "Security events of type {{ $labels.event_type }} spiking at {{ $value }} events/sec"
            runbook_url: "https://runbooks.intelgraph.ai/security-event-spike"

        - alert: FailedAuthenticationSpike
          expr: |
            rate(maestro_authentication_attempts_total{status="failed"}[5m]) > 5
          for: 3m
          labels:
            severity: high
            service: authentication
            team: security
          annotations:
            summary: "Failed authentication attempts spike"
            description: "Failed authentication rate is {{ $value }} attempts/sec"
            runbook_url: "https://runbooks.intelgraph.ai/auth-spike"

        - alert: ComplianceViolation
          expr: |
            rate(maestro_compliance_gate_decisions_total{decision="deny"}[10m]) > 1
          for: 1m
          labels:
            severity: high
            service: compliance
            team: security
          annotations:
            summary: "Compliance violations detected"
            description: "Compliance violations for policy {{ $labels.policy }}: {{ $value }} denials"
            runbook_url: "https://runbooks.intelgraph.ai/compliance-violation"

        - alert: UnauthorizedAccessAttempt
          expr: |
            rate(maestro_authorization_decisions_total{decision="deny"}[5m]) > 2
          for: 2m
          labels:
            severity: medium
            service: authorization
            team: security
          annotations:
            summary: "Unauthorized access attempts"
            description: "Authorization denials at {{ $value }} attempts/sec"

    # === BUSINESS METRICS ALERTS ===
    - name: intelgraph.business
      interval: 300s
      rules:
        - alert: InvestigationCreationDrop
          expr: |
            (
              rate(maestro_investigations_created_total[1h]) < 
              rate(maestro_investigations_created_total[1h] offset 24h) * 0.5
            )
          for: 30m
          labels:
            severity: medium
            service: investigations
            team: product
          annotations:
            summary: "Investigation creation rate has dropped significantly"
            description: "Investigation creation is 50% below yesterday's rate"

        - alert: DataSourcesOffline
          expr: |
            maestro_data_sources_active_total < 5
          for: 10m
          labels:
            severity: medium
            service: data-sources
            team: data
          annotations:
            summary: "Too few active data sources"
            description: "Only {{ $value }} data sources are active"

        - alert: AICostSpike
          expr: |
            rate(maestro_ai_model_cost_usd[1h]) > 
            rate(maestro_ai_model_cost_usd[1h] offset 24h) * 2
          for: 15m
          labels:
            severity: medium
            service: ai-cost-optimization
            team: ai
          annotations:
            summary: "AI costs are spiking"
            description: "AI costs are 2x higher than yesterday"
            runbook_url: "https://runbooks.intelgraph.ai/ai-cost-spike"

    # === INFRASTRUCTURE ALERTS ===
    - name: intelgraph.infrastructure
      interval: 60s
      rules:
        - alert: KubernetesNodeNotReady
          expr: kube_node_status_condition{condition="Ready",status="true"} == 0
          for: 5m
          labels:
            severity: high
            service: kubernetes
            team: platform
          annotations:
            summary: "Kubernetes node is not ready"
            description: "Node {{ $labels.node }} has been not ready for more than 5 minutes"

        - alert: EtcdClusterUnhealthy
          expr: |
            (
              up{job="etcd"} == 0 or 
              etcd_server_has_leader == 0
            )
          for: 3m
          labels:
            severity: critical
            service: etcd
            team: platform
          annotations:
            summary: "etcd cluster is unhealthy"
            description: "etcd cluster health issue detected on {{ $labels.instance }}"

        - alert: IngressControllerDown
          expr: up{job="nginx-ingress"} == 0
          for: 2m
          labels:
            severity: critical
            service: ingress
            team: platform
          annotations:
            summary: "Ingress controller is down"
            description: "Nginx ingress controller is not responding"

        - alert: NetworkPolicyViolation
          expr: |
            rate(cilium_drop_count_total[5m]) > 50
          for: 5m
          labels:
            severity: medium
            service: network-policy
            team: security
          annotations:
            summary: "High network policy drop rate"
            description: "Network policy drops at {{ $value }} drops/sec"

    # === PERFORMANCE DEGRADATION ALERTS ===
    - name: intelgraph.performance
      interval: 120s
      rules:
        - alert: ThompsonSamplingPerformanceDrop
          expr: |
            maestro_thompson_sampling_reward_rate < 0.7
          for: 15m
          labels:
            severity: medium
            service: thompson-sampling
            team: ai
          annotations:
            summary: "Thompson sampling performance has dropped"
            description: "Model {{ $labels.model }} reward rate is {{ $value }}"

        - alert: GraphTraversalSlowdown
          expr: |
            histogram_quantile(0.90, 
              rate(maestro_graph_query_duration_seconds_bucket{operation="traverse"}[10m])
            ) > 2
          for: 10m
          labels:
            severity: medium
            service: graph-traversal
            team: data
          annotations:
            summary: "Graph traversal queries are slow"
            description: "90th percentile graph traversal time is {{ $value }}s"

        - alert: SynthesisLatencyIncrease
          expr: |
            histogram_quantile(0.95, 
              rate(maestro_synthesis_duration_seconds_bucket[10m])
            ) > 15
          for: 10m
          labels:
            severity: medium
            service: synthesis
            team: ai
          annotations:
            summary: "Data synthesis latency has increased"
            description: "95th percentile synthesis time is {{ $value }}s"