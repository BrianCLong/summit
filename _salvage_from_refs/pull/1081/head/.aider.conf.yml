# IntelGraph AI Symphony - Agent-Centric Aider Config
# Default to your Qwen route (fast, low-VRAM coder)
model: openai/local/llama

# Aider reads these dashed keys (not an "openai:" block)  
openai-api-base: http://127.0.0.1:4000/v1
openai-api-key: sk-anything

# Quality & performance settings
pretty: true
stream: true
auto-commits: false
git: true
edit-format: diff
show-diffs: true
max-chat-history-tokens: 8192

# Agent role quick-switch examples:
# aider --model openai/local/llama       # guy (architect/coder)
# aider --model openai/local/llama-cpu   # aegis (security review)
# aider --model openai/local/llama-small # hermes (quick CI/PR tasks)
# aider --model openai/gemini/1.5-pro   # elara (research - requires GOOGLE_API_KEY)
# aider --model openai/xai/grok-code-fast-1 # power burst (requires XAI_API_KEY)

# Performance tuning for M2 16GB
cache-prompts: true
restore-chat-history: false

# File handling
encoding: utf-8
ignore-globs: |
  *.log
  *.tmp  
  **/node_modules/**
  **/dist/**
  **/build/**
  **/.vite/**
  **/.next/**
  **/coverage/**
  rag/index/*.duckdb*
  **/*.pyc
  **/__pycache__/**
