# WarGamed Decision Support Dashboard

**WAR-GAMED SIMULATION - FOR DECISION SUPPORT ONLY**

This document provides instructions for setting up and using the WarGamed Decision Support Dashboard, an extension for the IntelGraph platform. This dashboard is designed for hypothetical scenario simulation and training purposes, focusing on defensive/reputational management in global crisis response.

**Ethics Compliance:** All simulations and outputs are flagged as hypothetical/test-only. No real Psychological Operations (PsyOps) content is generated. The focus is strictly on enhancing blue-team defenses by simulating Information Operations (IO) threats and responses based on established military doctrine.

## Overview

The WarGamed Decision Support Dashboard provides executive leadership with a simulated interface for managing reputational PsyOps during global crisis response. It integrates:
*   Live Social Media Telemetry (simulated and processed by AI/ML)
*   Adversary Intent Estimation (simulated via LLM with caching)
*   Narrative Heatmaps (simulated)
*   Strategic Response Playbooks (modeled on military IO doctrine, generated by LLM with caching)
*   Conceptual "what-if" simulation propagation through the graph.
*   Conceptual real-time scenario triggering via Kafka.

## Setup Instructions

This module integrates with the existing IntelGraph backend (Node.js/TypeScript) and frontend (React), and introduces a new Python AI/ML service.

### Prerequisites

Ensure you have the IntelGraph development environment set up, including:
*   Node.js 20+
*   Python 3.9+
*   Neo4j 5+
*   Redis (for AI/ML caching)
*   Kafka (for conceptual real-time triggers)
*   Docker and Docker Compose (for containerized setup)
*   All existing IntelGraph dependencies installed.

### Backend Setup (IntelGraph Server)

The backend changes involve new GraphQL schema definitions, resolvers, and conceptual Kafka integration.

1.  **Navigate to the server directory:**
    ```bash
    cd intelgraph/server
    ```
2.  **Install dependencies (if not already done):**
    ```bash
    npm install
    ```
3.  **Build the TypeScript code:**
    ```bash
    npm run build
    ```
4.  **Start the IntelGraph server:**
    ```bash
    # Ensure environment variables are set if running outside Docker Compose
    # export PYTHON_API_URL=http://localhost:8000
    # export PYTHON_API_KEY=supersecretapikey
    # export KAFKA_BROKERS=localhost:9092 # For conceptual Kafka consumer
    npm run dev # For development with hot-reloading
    # or
    npm start # For production build
    ```
    The server should now expose the new GraphQL queries and mutations for the WarGame Dashboard. It will also attempt to connect to Kafka if `KAFKA_BROKERS` is set.

### Python AI/ML Service Setup

This service provides NLP and LLM functionalities, now with OpenTelemetry and Redis caching.

1.  **Navigate to the API directory:**
    ```bash
    cd intelgraph/api
    ```
2.  **Install Python dependencies:**
    You will need to install `fastapi`, `uvicorn`, `spacy`, `sentence-transformers`, and OpenTelemetry packages.

    **Example `api/requirements.txt` (updated):**
    ```
    fastapi==0.111.0
    uvicorn==0.30.1
    neo4j==5.21.0
    redis==5.0.1
    spacy==3.7.5
    sentence-transformers==2.7.0
    # OpenTelemetry
    opentelemetry-api==1.24.0
    opentelemetry-sdk==1.24.0
    opentelemetry-instrumentation-fastapi==0.45b0
    opentelemetry-exporter-otlp-proto-grpc==1.24.0
    # For LLM, if using Hugging Face transformers directly:
    # transformers==4.42.3
    # torch # or tensorflow, depending on your setup
    ```
    Then install:
    ```bash
    pip install -r requirements.txt
    ```
3.  **Download spaCy model:**
    ```bash
    python -m spacy download en_core_web_sm
    ```
4.  **Start the FastAPI application:**
    ```bash
    # Ensure API_KEY is set if running outside Docker Compose
    # export API_KEY=supersecretapikey
    uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ```
    The Python API will be available at `http://localhost:8000`. It will also attempt to connect to Redis for caching and send traces to an OpenTelemetry collector (default `localhost:4317`).

### Frontend Setup (IntelGraph Client)

The frontend changes involve new React components and routing.

1.  **Navigate to the client directory:**
    ```bash
    cd intelgraph/client
    ```
2.  **Install dependencies (if not already done):**
    ```bash
    npm install
    ```
3.  **Start the IntelGraph client:**
    ```bash
    npm run dev
    ```
    The client application should now be running, and you should see a new "WarGame Dashboard" item in the navigation menu.

### Docker Compose Setup (Recommended for Dev)

For a fully containerized development environment, you will need to update your `docker-compose.dev.yml` or `docker-compose.yml` to include the new Python API service, Redis, and Kafka.

**Example `docker-compose.dev.yml` snippet (updated):**

```yaml
version: '3.8'
services:
  neo4j:
    image: neo4j:5.17.0-community
    hostname: neo4j
    ports:
      - "7474:7474"
      - "7687:7687"
    environment:
      NEO4J_AUTH: neo4j/${NEO4J_PASSWORD:-password}
      NEO4J_db_tx__log_rotation__size: 100M
      NEO4J_ACCEPT_LICENSE_AGREEMENT: "yes"
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider localhost:7474 || exit 1"]
      interval: 5s
      timeout: 3s
      retries: 5

  redis:
    image: redis:7.0-alpine
    hostname: redis
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    hostname: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    healthcheck:
      test: ["CMD-SHELL", "echo stat | nc localhost 2181"]
      interval: 5s
      timeout: 3s
      retries: 5

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    ports:
      - "9092:9092"
      - "9093:9093" # For internal communication
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    depends_on:
      - zookeeper
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 5s
      retries: 5

  api:
    build:
      context: ./api
      dockerfile: Dockerfile.api # Assuming you create this Dockerfile
    ports:
      - "8000:8000"
    environment:
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: ${NEO4J_USER:-neo4j}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-password}
      REDIS_URL: redis://redis:6379
      API_KEY: ${API_KEY:-supersecretapikey} # For FastAPI authentication
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./api:/app
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  server:
    build:
      context: ./server
      dockerfile: Dockerfile.server # Assuming you create this Dockerfile
    ports:
      - "4000:4000"
    environment:
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: ${NEO4J_USER:-neo4j}
      NEO4J_PASSWORD: ${NEO4J_PASSWORD:-password}
      REDIS_URL: redis://redis:6379
      PYTHON_API_URL: http://api:8000 # Point to the new API service
      PYTHON_API_KEY: ${API_KEY:-supersecretapikey} # Pass API key to Node.js server
      KAFKA_BROKERS: kafka:9092 # For conceptual Kafka consumer
    depends_on:
      neo4j:
        condition: service_healthy
      redis:
        condition: service_healthy
      api:
        condition: service_healthy
      kafka:
        condition: service_healthy
    volumes:
      - ./server:/app
    command: npm run dev
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 10s
      timeout: 5s
      retries: 5

  client:
    build:
      context: ./client
      dockerfile: Dockerfile.client # Assuming you create this Dockerfile
    ports:
      - "3000:3000"
    environment:
      VITE_GRAPHQL_URI: http://localhost:4000/graphql
    depends_on:
      server:
        condition: service_healthy
    volumes:
      - ./client:/app
    command: npm run dev
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  neo4j_data:
  neo4j_logs:
