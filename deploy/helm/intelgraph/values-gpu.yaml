# GPU-enabled Helm values for IntelGraph
ml:
  image:
    repository: intelgraph/ml
    tag: 'latest-gpu'
    pullPolicy: IfNotPresent

  replicaCount: 1

  resources:
    requests:
      memory: '2Gi'
      cpu: '1'
      nvidia.com/gpu: 1
    limits:
      memory: '8Gi'
      cpu: '4'
      nvidia.com/gpu: 1

  nodeSelector:
    accelerator: nvidia-tesla-k80

  tolerations:
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule

  env:
    USE_SPACY: 'true'
    UVICORN_HOST: '0.0.0.0'
    UVICORN_PORT: '8081'

mlWorker:
  image:
    repository: intelgraph/ml
    tag: 'latest-gpu'
    pullPolicy: IfNotPresent

  replicaCount: 2

  resources:
    requests:
      memory: '1Gi'
      cpu: '0.5'
      nvidia.com/gpu: 1
    limits:
      memory: '4Gi'
      cpu: '2'
      nvidia.com/gpu: 1

  nodeSelector:
    accelerator: nvidia-tesla-k80

  tolerations:
    - key: nvidia.com/gpu
      operator: Exists
      effect: NoSchedule

# Enhanced infrastructure for GPU workloads
redis:
  resources:
    requests:
      memory: '512Mi'
      cpu: '0.5'
    limits:
      memory: '2Gi'
      cpu: '1'

neo4j:
  resources:
    requests:
      memory: '2Gi'
      cpu: '1'
    limits:
      memory: '8Gi'
      cpu: '4'

  config:
    dbms.memory.heap.initial_size: '2G'
    dbms.memory.heap.max_size: '6G'
    dbms.memory.pagecache.size: '2G'

postgres:
  resources:
    requests:
      memory: '1Gi'
      cpu: '0.5'
    limits:
      memory: '4Gi'
      cpu: '2'

# Autoscaling for ML services
autoscaling:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 70
  targetMemoryUtilizationPercentage: 80

# Monitoring and observability
monitoring:
  enabled: true
  prometheus:
    enabled: true
  grafana:
    enabled: true
    dashboards:
      gpu: true
      ml: true
