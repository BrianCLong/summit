# Service Level Objectives Configuration
# Sprint 27E: Performance targets with 30% headroom

apiVersion: monitoring.intelgraph.io/v1
kind: SLOConfig
metadata:
  name: intelgraph-slos
  version: "27.0.0"

spec:
  # Global SLO configuration
  global:
    evaluation_window: "5m"
    alert_window: "2h"
    burn_rate_threshold: 14.4  # 2% budget burn in 1 hour

  # Service Level Indicators (SLIs)
  slis:
    nlq_latency:
      name: "NL→Cypher Query Latency"
      description: "Time from NL query to Cypher response"
      metric: "histogram_quantile(0.95, nlq_duration_seconds_bucket)"
      unit: "seconds"

    api_error_rate:
      name: "API Error Rate"
      description: "Percentage of HTTP 5xx responses"
      metric: "rate(http_requests_total{status=~'5..'}[5m]) / rate(http_requests_total[5m])"
      unit: "percentage"

    ingest_latency:
      name: "Data Ingest Latency"
      description: "Time to process incoming data"
      metric: "histogram_quantile(0.95, ingest_duration_seconds_bucket)"
      unit: "seconds"

    export_latency:
      name: "Data Export Latency"
      description: "Time to generate export files"
      metric: "histogram_quantile(0.95, export_duration_seconds_bucket)"
      unit: "seconds"

    chaos_recovery_time_node:
      name: "Node.js Chaos Recovery Time"
      description: "Time for the Node.js backend to recover after chaos experiments"
      metric: "histogram_quantile(0.99, chaos_experiment_recovery_seconds_bucket{service=\"intelgraph\"})"
      unit: "seconds"

    chaos_recovery_time_python:
      name: "Python API Chaos Recovery Time"
      description: "Time for the Python analytics API to recover after chaos experiments"
      metric: "histogram_quantile(0.95, chaos_experiment_recovery_seconds_bucket{service=\"analytics-api\"})"
      unit: "seconds"

    chaos_recovery_time_postgres:
      name: "PostgreSQL Chaos Recovery Time"
      description: "Time for PostgreSQL primary to recover after chaos experiments"
      metric: "histogram_quantile(0.99, chaos_experiment_recovery_seconds_bucket{service=\"postgres\",role=\"primary\"})"
      unit: "seconds"

    chaos_error_rate_node:
      name: "Node.js Chaos Error Rate"
      description: "HTTP 5xx ratio observed on the Node.js backend during chaos windows"
      metric: "rate(http_requests_total{service=\"intelgraph\",status=~\"5..\"}[5m]) / rate(http_requests_total{service=\"intelgraph\"}[5m])"
      unit: "percentage"

    chaos_error_rate_python:
      name: "Python API Chaos Error Rate"
      description: "HTTP 5xx ratio observed on the Python analytics API during chaos windows"
      metric: "rate(http_requests_total{service=\"analytics-api\",status=~\"5..\"}[5m]) / rate(http_requests_total{service=\"analytics-api\"}[5m])"
      unit: "percentage"

    chaos_error_rate_postgres:
      name: "PostgreSQL Chaos Error Rate"
      description: "Database error ratio observed during chaos windows"
      metric: "rate(sql_error_total{cluster=\"postgres\"}[5m]) / rate(sql_query_total{cluster=\"postgres\"}[5m])"
      unit: "percentage"

    model_cost_per_1k:
      name: "Model Cost Per 1K Queries"
      description: "Average cost per 1000 NL queries"
      metric: "rate(model_budget_spent_dollars[1h]) / rate(nlq_requests_total[1h]) * 1000"
      unit: "dollars"

  # Service Level Objectives (SLOs)
  slos:
    nlq_latency_slo:
      sli: "nlq_latency"
      target: 0.9   # 90ms target with 30% headroom from 1.3s
      threshold: 0.9  # 900ms actual threshold
      description: "95% of NL→Cypher queries complete within 900ms"
      priority: "P0"

    api_availability_slo:
      sli: "api_error_rate"
      target: 0.999  # 99.9% availability
      threshold: 0.001  # 0.1% error rate threshold
      description: "API error rate below 0.1%"
      priority: "P0"

    ingest_latency_slo:
      sli: "ingest_latency"
      target: 0.95   # 95% within threshold
      threshold: 1.05  # 1.05s (30% headroom from 1.5s)
      description: "95% of data ingestion completes within 1.05s"
      priority: "P1"

    export_latency_slo:
      sli: "export_latency"
      target: 0.95   # 95% within threshold
      threshold: 0.84  # 840ms (30% headroom from 1.2s)
      description: "95% of exports complete within 840ms"
      priority: "P1"

    cost_efficiency_slo:
      sli: "model_cost_per_1k"
      target: 0.95   # 95% under budget
      threshold: 0.05  # $0.05 per 1K queries
      description: "Model costs stay under $0.05 per 1K queries"
      priority: "P2"

    node_chaos_recovery_slo:
      sli: "chaos_recovery_time_node"
      target: 0.99   # 99% of chaos experiments recover within threshold
      threshold: 60   # seconds
      description: "Node.js backend recovers from chaos experiments within 60 seconds"
      priority: "P0"

    node_chaos_error_rate_slo:
      sli: "chaos_error_rate_node"
      target: 0.995  # 0.5% max error rate
      threshold: 0.005
      description: "Node.js backend error rate stays below 0.5% during chaos"
      priority: "P0"

    python_chaos_recovery_slo:
      sli: "chaos_recovery_time_python"
      target: 0.95   # 95% recover within threshold
      threshold: 90   # seconds
      description: "Python analytics API recovers from chaos experiments within 90 seconds"
      priority: "P1"

    python_chaos_error_rate_slo:
      sli: "chaos_error_rate_python"
      target: 0.985  # 1.5% max error rate
      threshold: 0.015
      description: "Python analytics API error rate stays below 1.5% during chaos"
      priority: "P1"

    postgres_chaos_recovery_slo:
      sli: "chaos_recovery_time_postgres"
      target: 0.99   # 99% recover within threshold
      threshold: 120  # seconds
      description: "PostgreSQL primary recovers within 120 seconds after chaos experiments"
      priority: "P0"

    postgres_chaos_error_rate_slo:
      sli: "chaos_error_rate_postgres"
      target: 0.99   # 1% max error rate
      threshold: 0.01
      description: "PostgreSQL error rate stays below 1% during chaos"
      priority: "P0"

  # Environment-specific targets
  environments:
    dev:
      slo_multiplier: 2.0  # Relaxed targets for dev
      budget_multiplier: 0.5  # Smaller budget

    staging:
      slo_multiplier: 1.2  # Slightly relaxed
      budget_multiplier: 0.8

    prod:
      slo_multiplier: 1.0  # Full targets
      budget_multiplier: 1.0

  # Alert policies
  alerting:
    burn_rate_alerts:
      - name: "fast_burn"
        severity: "critical"
        burn_rate: 14.4  # 2% budget in 1 hour
        duration: "2m"

      - name: "slow_burn"
        severity: "warning"
        burn_rate: 6.0   # 1% budget in 1 hour
        duration: "15m"

    threshold_alerts:
      - name: "slo_breach"
        severity: "critical"
        threshold_multiplier: 1.0
        duration: "5m"

      - name: "slo_warning"
        severity: "warning"
        threshold_multiplier: 0.8
        duration: "10m"

  # Error budgets
  error_budgets:
    calculation_window: "30d"  # 30-day rolling window

    budgets:
      nlq_latency:
        budget_percentage: 1.0  # 1% of requests can exceed SLO
        alert_thresholds:
          - percentage: 75
            severity: "warning"
          - percentage: 90
            severity: "critical"

      api_availability:
        budget_percentage: 0.1  # 0.1% error budget
        alert_thresholds:
          - percentage: 50
            severity: "warning"
          - percentage: 75
            severity: "critical"

  # SLO reporting
  reporting:
    enabled: true
    dashboard_refresh: "1m"
    export_metrics: true

    dashboards:
      - name: "SLO Overview"
        path: "/grafana/d/slo-overview"
        panels:
          - sli_current_values
          - slo_compliance_status
          - error_budget_remaining
          - burn_rate_trends

      - name: "Performance Deep Dive"
        path: "/grafana/d/perf-deepdive"
        panels:
          - latency_percentiles
          - throughput_trends
          - resource_utilization
          - cost_efficiency

  # Compliance tracking
  compliance:
    track_slo_violations: true
    violation_ticket_integration: true
    monthly_slo_report: true

    remediation:
      auto_scale_on_breach: true
      circuit_breaker_integration: true
      cost_throttling: true

# Baseline measurements (captured during Sprint 27E)
baseline:
  measurement_period: "2025-09-19T00:00:00Z to 2025-09-21T00:00:00Z"
  workload: "k6_mixed_profile_sustained_50_vus"

  measurements:
    nlq_latency_p95: 1.247  # seconds
    nlq_latency_p99: 2.891  # seconds
    api_error_rate: 0.0008  # 0.08%
    ingest_latency_p95: 1.423  # seconds
    export_latency_p95: 1.156  # seconds
    cost_per_1k_queries: 0.067  # dollars

  targets_with_headroom:
    nlq_latency_target: 0.900    # 28% improvement from baseline
    api_error_target: 0.001      # 25% improvement from baseline
    ingest_latency_target: 1.050  # 26% improvement from baseline
    export_latency_target: 0.840  # 27% improvement from baseline
    cost_target: 0.050           # 25% cost reduction