# Prometheus recording + alerting rules for SLO error-budget burn
# NOTE: Replace metric names/labels to match your exporters.

groups:
  - name: slo-burn
    interval: 30s
    rules:
      # Define error ratio over rolling windows for each expert/tier
      - record: slo:error_ratio:rate5m
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[5m]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[5m])))

      - record: slo:error_ratio:rate30m
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[30m]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[30m])))

      - record: slo:error_ratio:rate1h
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[1h]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[1h])))

      - record: slo:error_ratio:rate6h
        expr: |
          1 - (sum by (expert, tenant_tier) (rate(conductor_request_success_total[6h]))
               /
               sum by (expert, tenant_tier) (rate(conductor_request_total[6h])))

  - name: slo-burn-alerts
    interval: 30s
    rules:
      # Fast burn (page) — 2% budget in 1h or 5% in 6h equivalent
      - alert: SLOErrorBudgetBurnFast
        expr: |
          (slo:error_ratio:rate5m > on(expert, tenant_tier) group_left slo:target_error_ratio)
          and
          (slo:error_ratio:rate1h > on(expert, tenant_tier) group_left slo:target_error_ratio)
        for: 10m
        labels:
          severity: page
        annotations:
          summary: "Fast SLO burn for {{ $labels.expert }} ({{ $labels.tenant_tier }})"
          description: |
            Error ratio breaching target over 5m and 1h. Investigate acute incidents, rollbacks, or hot tenants.
          runbook_url: "https://docs.example.com/runbooks/slo-fast-burn.html"

      # Slow burn (ticket) — 1% budget in 24h equivalent
      - alert: SLOErrorBudgetBurnSlow
        expr: |
          (slo:error_ratio:rate30m > on(expert, tenant_tier) group_left slo:target_error_ratio)
          and
          (slo:error_ratio:rate6h > on(expert, tenant_tier) group_left slo:target_error_ratio)
        for: 2h
        labels:
          severity: ticket
        annotations:
          summary: "Slow SLO burn for {{ $labels.expert }} ({{ $labels.tenant_tier }})"
          description: |
            Sustained burn above target. Plan remediation; consider feature freeze for affected scope.
          runbook_url: "https://docs.example.com/runbooks/slo-slow-burn.html"

  - name: slo-targets
    rules:
      # Target error ratios per expert/tier derived from SLOs
      # For example, rag_retrieval with 99% SLO => target_error_ratio=0.01
      # Provision these as static metrics via the pushgateway or sidecar exporter if desired.
      # This is a placeholder vector to enable rule wiring; replace with your target source.
      - record: slo:target_error_ratio
        expr: |
          0.01
        labels:
          expert: "rag_retrieval"
          tenant_tier: "gold"

  - name: tenant-cost-guards
    interval: 1m
    rules:
      - record: tenant_cost_rate
        expr: |
          sum by (tenant_id) (rate(maestro_cost_total_usd[1h])) # Assuming a metric for total cost
        labels:
          unit: usd_per_hour

      - alert: TenantCostExceedsBudget
        expr: |
          tenant_cost_rate > (0.8 * tenant_budget_usd) # Assuming tenant_budget_usd is a metric
        for: 2h
        labels:
          severity: critical
          alert_type: cost_guard
        annotations:
          summary: "Tenant {{ $labels.tenant_id }} cost exceeds 80% of budget"
          description: "Current cost rate for tenant {{ $labels.tenant_id }} is {{ $value }} USD/hour, exceeding 80% of their allocated budget."
          runbook_url: "https://docs.example.com/runbooks/tenant-cost-exceeds-budget.html"
          grafana_deep_link: "https://grafana.example.com/d/budget-panel?var-tenant={{ $labels.tenant_id }}"
