# Advanced Analytics Pipeline Configuration
# Stream processing, metrics aggregation, and real-time analytics for IntelGraph

analytics:
  enabled: true

  # Stream Processing Configuration
  stream_processing:
    engine: 'kafka' # kafka, pulsar, redis_streams

    kafka:
      brokers:
        - '${KAFKA_BROKER_1}'
        - '${KAFKA_BROKER_2}'
        - '${KAFKA_BROKER_3}'
      client_id: 'intelgraph-analytics'
      group_id: 'analytics-processors'
      security:
        protocol: 'SASL_SSL'
        mechanism: 'PLAIN'
        username: '${KAFKA_USERNAME}'
        password: '${KAFKA_PASSWORD}'

    processors:
      max_concurrent: 10
      default_parallelism: 4
      checkpoint_interval: 60000 # 1 minute
      restart_strategy: 'exponential-backoff'
      max_restart_attempts: 3
      timeout: 30000
      buffer_size: 10000
      batch_size: 500

    topics:
      # Input topics
      raw_events: 'intelgraph.events.raw'
      user_activities: 'intelgraph.activities.user'
      system_metrics: 'intelgraph.metrics.system'
      audit_logs: 'intelgraph.audit.logs'
      collaboration_events: 'intelgraph.collaboration.events'

      # Output topics
      processed_events: 'intelgraph.events.processed'
      aggregated_metrics: 'intelgraph.metrics.aggregated'
      anomalies: 'intelgraph.anomalies.detected'
      patterns: 'intelgraph.patterns.recognized'
      alerts: 'intelgraph.alerts.generated'

  # Time Series Database Configuration
  timeseries:
    provider: 'influxdb' # influxdb, prometheus, timescaledb

    influxdb:
      host: '${INFLUX_HOST}'
      port: '${INFLUX_PORT}'
      database: 'intelgraph_metrics'
      username: '${INFLUX_USERNAME}'
      password: '${INFLUX_PASSWORD}'
      retention_policy: 'autogen'
      precision: 'ms'

    # Data retention and downsampling
    retention:
      raw_data: '7d' # 7 days of raw data
      hourly_avg: '30d' # 30 days of hourly averages
      daily_avg: '365d' # 1 year of daily averages
      monthly_avg: '5y' # 5 years of monthly averages

    downsampling:
      enabled: true
      rules:
        - name: 'hourly_metrics'
          source_retention: 'raw_data'
          dest_retention: 'hourly_avg'
          every: '1h'
          aggregations: ['mean', 'max', 'min', 'sum', 'count']
        - name: 'daily_metrics'
          source_retention: 'hourly_avg'
          dest_retention: 'daily_avg'
          every: '1d'
          aggregations: ['mean', 'max', 'min', 'sum']
        - name: 'monthly_metrics'
          source_retention: 'daily_avg'
          dest_retention: 'monthly_avg'
          every: '30d'
          aggregations: ['mean', 'max', 'min']

  # Metrics Collection and Aggregation
  metrics:
    collection_interval: 10000 # 10 seconds
    batch_size: 1000
    buffer_timeout: 5000 # 5 seconds

    # Built-in metric collectors
    collectors:
      system:
        enabled: true
        interval: 30000 # 30 seconds
        metrics:
          - 'cpu_usage'
          - 'memory_usage'
          - 'disk_usage'
          - 'network_io'
          - 'load_average'

      application:
        enabled: true
        interval: 10000 # 10 seconds
        metrics:
          - 'request_count'
          - 'response_time'
          - 'error_rate'
          - 'active_users'
          - 'session_count'

      database:
        enabled: true
        interval: 30000 # 30 seconds
        metrics:
          - 'query_count'
          - 'query_duration'
          - 'connection_count'
          - 'cache_hit_rate'
          - 'replication_lag'

      collaboration:
        enabled: true
        interval: 5000 # 5 seconds
        metrics:
          - 'active_sessions'
          - 'concurrent_users'
          - 'operations_per_second'
          - 'conflict_rate'
          - 'message_latency'

    # Real-time aggregations
    aggregations:
      - name: 'request_rate_1m'
        metric: 'request_count'
        time_window: 60000 # 1 minute
        type: 'rate'

      - name: 'error_rate_5m'
        metric: 'error_count'
        time_window: 300000 # 5 minutes
        type: 'rate'

      - name: 'response_time_p95'
        metric: 'response_time'
        time_window: 300000 # 5 minutes
        type: 'percentile'
        percentile: 95

      - name: 'active_users_by_region'
        metric: 'active_users'
        time_window: 60000 # 1 minute
        type: 'sum'
        group_by: ['region']

  # Machine Learning Pipeline
  ml:
    enabled: true
    model_path: '/app/models'
    enable_gpu: false

    # Anomaly Detection
    anomaly_detection:
      enabled: true
      algorithms:
        statistical:
          enabled: true
          threshold: 3.0 # Standard deviations
          window_size: 100

        isolation_forest:
          enabled: true
          contamination: 0.1
          n_estimators: 100

        autoencoder:
          enabled: false
          hidden_layers: [64, 32, 16, 32, 64]
          epochs: 100

    # Pattern Recognition
    pattern_recognition:
      enabled: true
      algorithms:
        sequence_mining:
          enabled: true
          min_support: 0.1
          max_pattern_length: 10

        clustering:
          enabled: true
          algorithm: 'kmeans'
          n_clusters: 5

    # Model Training
    training:
      auto_retrain: true
      retrain_interval: '7d'
      min_training_samples: 1000
      validation_split: 0.2

  # Dashboard and Visualization
  dashboards:
    default_refresh: 30 # seconds
    max_data_points: 2000

    # Pre-built dashboards
    system_overview:
      enabled: true
      panels:
        - type: 'graph'
          title: 'CPU Usage'
          metrics: ['cpu_usage']
          time_range: '1h'
        - type: 'graph'
          title: 'Memory Usage'
          metrics: ['memory_usage']
          time_range: '1h'
        - type: 'stat'
          title: 'Active Users'
          metrics: ['active_users']
        - type: 'graph'
          title: 'Request Rate'
          metrics: ['request_rate_1m']
          time_range: '1h'

    collaboration_metrics:
      enabled: true
      panels:
        - type: 'graph'
          title: 'Active Sessions'
          metrics: ['active_sessions']
          time_range: '4h'
        - type: 'graph'
          title: 'Operations/sec'
          metrics: ['operations_per_second']
          time_range: '1h'
        - type: 'heatmap'
          title: 'User Activity'
          metrics: ['user_activity_by_hour']
          time_range: '24h'

    security_overview:
      enabled: true
      panels:
        - type: 'stat'
          title: 'Failed Logins'
          metrics: ['failed_login_count']
        - type: 'graph'
          title: 'Anomalies Detected'
          metrics: ['anomalies_per_hour']
          time_range: '24h'
        - type: 'table'
          title: 'Top Security Events'
          metrics: ['security_events']

  # Alerting Configuration
  alerting:
    enabled: true
    evaluation_interval: 30 # seconds

    rules:
      # System alerts
      - name: 'high_cpu_usage'
        condition: 'cpu_usage > 90'
        for: '5m'
        severity: 'warning'
        message: 'CPU usage is above 90% for 5 minutes'
        channels: ['slack', 'email']

      - name: 'high_memory_usage'
        condition: 'memory_usage > 85'
        for: '10m'
        severity: 'warning'
        message: 'Memory usage is above 85% for 10 minutes'
        channels: ['slack', 'email']

      - name: 'high_error_rate'
        condition: 'error_rate_5m > 5'
        for: '2m'
        severity: 'critical'
        message: 'Error rate is above 5% for 2 minutes'
        channels: ['pagerduty', 'slack', 'email']

      # Application alerts
      - name: 'low_active_users'
        condition: 'active_users < 10'
        for: '15m'
        severity: 'info'
        message: 'Active user count is below normal levels'
        channels: ['slack']

      - name: 'high_response_time'
        condition: 'response_time_p95 > 2000'
        for: '5m'
        severity: 'warning'
        message: '95th percentile response time is above 2 seconds'
        channels: ['slack', 'email']

      # Security alerts
      - name: 'anomaly_spike'
        condition: 'anomalies_per_hour > 10'
        for: '1m'
        severity: 'critical'
        message: 'High number of anomalies detected'
        channels: ['security_team', 'pagerduty']

    channels:
      slack:
        enabled: true
        webhook_url: '${SLACK_WEBHOOK_URL}'
        channel: '#alerts'
        username: 'IntelGraph Alerts'

      email:
        enabled: true
        smtp_server: '${SMTP_SERVER}'
        smtp_port: 587
        username: '${SMTP_USERNAME}'
        password: '${SMTP_PASSWORD}'
        from: 'alerts@intelgraph.com'
        to: ['ops@company.com', 'alerts@company.com']

      pagerduty:
        enabled: true
        integration_key: '${PAGERDUTY_INTEGRATION_KEY}'

      security_team:
        enabled: true
        webhook_url: '${SECURITY_WEBHOOK_URL}'

  # Query Engine Configuration
  query_engine:
    timeout: 30000 # 30 seconds
    max_concurrent_queries: 100
    result_cache_ttl: 300 # 5 minutes
    max_result_size: '100MB'

    # Query language features
    features:
      functions: true
      aggregations: true
      joins: true
      subqueries: true
      regex: true
      math_operations: true

  # API Configuration
  api:
    enabled: true
    port: 8081
    rate_limiting:
      enabled: true
      requests_per_minute: 1000
      burst_size: 100

    authentication:
      required: true
      methods: ['jwt', 'api_key']

    endpoints:
      metrics: '/api/v1/metrics'
      query: '/api/v1/query'
      dashboards: '/api/v1/dashboards'
      alerts: '/api/v1/alerts'

  # Performance Optimization
  performance:
    # Memory management
    memory:
      max_heap_size: '2GB'
      gc_optimization: true

    # Caching
    caching:
      query_cache:
        enabled: true
        size: '512MB'
        ttl: 300 # 5 minutes

      metric_cache:
        enabled: true
        size: '1GB'
        ttl: 60 # 1 minute

    # Parallelization
    parallelization:
      query_workers: 8
      aggregation_workers: 4
      ml_workers: 2

  # Storage Configuration
  storage:
    # Local storage for temporary data
    local:
      path: '/app/data/analytics'
      max_size: '10GB'
      cleanup_interval: '1h'

    # S3 for long-term archival
    s3:
      enabled: true
      bucket: '${ANALYTICS_S3_BUCKET}'
      region: '${AWS_REGION}'
      prefix: 'analytics-archive'
      storage_class: 'STANDARD_IA'
      lifecycle:
        transition_to_glacier: '90d'
        expiration: '7y'

  # Integration Configuration
  integrations:
    # Grafana integration
    grafana:
      enabled: true
      url: '${GRAFANA_URL}'
      api_key: '${GRAFANA_API_KEY}'
      datasource_name: 'IntelGraph Analytics'

    # Prometheus integration
    prometheus:
      enabled: true
      scrape_interval: '15s'
      metrics_path: '/metrics'

    # Elastic Stack integration
    elasticsearch:
      enabled: false
      hosts: ['${ELASTIC_HOST}']
      index_pattern: 'intelgraph-analytics-*'

    # External APIs
    external_apis:
      enabled: true
      timeout: 10000
      retry_attempts: 3

  # Development and Testing
  development:
    mock_data: false
    debug_logging: false
    performance_profiling: false

    testing:
      load_testing: false
      synthetic_metrics: false
      chaos_engineering: false

# Environment-specific overrides
environments:
  development:
    analytics:
      stream_processing:
        processors:
          max_concurrent: 2
      metrics:
        collection_interval: 30000
      development:
        mock_data: true
        debug_logging: true

  staging:
    analytics:
      stream_processing:
        processors:
          max_concurrent: 5
      alerting:
        rules:
          - name: 'staging_test_alert'
            condition: 'always_false'
            severity: 'info'

  production:
    analytics:
      stream_processing:
        processors:
          max_concurrent: 10
          default_parallelism: 8
      performance:
        memory:
          max_heap_size: '4GB'
        parallelization:
          query_workers: 16
          aggregation_workers: 8
      storage:
        s3:
          enabled: true
